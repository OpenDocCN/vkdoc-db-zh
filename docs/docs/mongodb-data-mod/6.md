# 六、数据管理

规划数据库操作是数据模型维护的最重要阶段之一。在 MongoDB 中，根据数据的性质，我们可以按功能或地理组分离应用程序的操作。

在本章中，我们将回顾[第 5 章](5.html "Chapter 5. Optimizing Queries")、*优化查询*中已经介绍的一些概念，如读首选项和写关注点。但这次我们将重点了解这些功能如何帮助我们通过 MongoDB 部署拆分操作，例如，分离读写操作，或者考虑到应用程序的特点，通过副本集节点使用写传播确保信息一致性。

您还将看到，通过探索特殊属性，如何拥有支持高读/写吞吐量的集合，这对于某些应用程序至关重要。

因此，在本章中，您将了解：

*   操作隔离
*   封顶收藏
*   数据自过期

# 操作隔离

到目前为止，我们已经了解了应用程序的查询通常会如何影响我们关于文档设计的决策。然而，阅读偏好和写作关注点的概念比我们已经探讨的更多。

MongoDB 为我们提供了一系列功能，允许我们按功能或地理组分离应用程序操作。在使用功能分离时，我们可以指示负责生成报告的应用程序仅使用某个 MongoDB 部署。地理隔离意味着，考虑到与 MongoDB 部署的地理距离，我们可以针对作战行动。

## 优先读取操作

不难想象一旦构建了一个应用程序，营销人员或商业人员就会要求提供一份新的应用程序数据报告，顺便说一句，这将是最基本的报告。我们知道，在我们的主数据库中构建和插入这样的应用程序仅仅是为了报告的目的是多么危险。除了与其他应用程序的数据并发之外，我们知道，这种类型的应用程序可以通过进行复杂的查询和操作大量数据来过载我们的数据库。

这就是为什么我们必须将专用 MongoDB 部署定位于处理大量数据并需要从数据库进行更繁重处理的操作的原因。我们将通过读取首选项使应用程序针对正确的 MongoDB 部署，正如您在[第 5 章](5.html "Chapter 5. Optimizing Queries")、*优化查询*中所看到的。

默认情况下，应用程序将始终从副本集中读取第一个节点。此行为保证应用程序始终读取最新的数据，从而确保数据的一致性。虽然，如果目的是降低第一个节点中的吞吐量，并且我们可以接受最终的一致性，则可以通过启用`secondary`或`secondaryPreferred`模式将读取操作从副本集中重定向到辅助节点。

除了在主节点上减少吞吐量的功能外，当我们的应用程序分布在多个数据中心中，并且因此我们的副本集分布在地理位置上时，优先考虑辅助节点中的读取操作也是至关重要的。这是因为我们可以通过设置最近的模式来选择最近的节点或延迟最低的节点来执行读取操作。

最后，通过允许使用`primaryPreferred`模式在任何副本集节点中执行读取操作，我们可以显著提高数据库的可用性。

但是，如果除了读取首选项规范（主要或次要）之外，我们还可以指定操作的目标实例，该怎么办？例如，假设一个副本集分布在两个不同的位置，并且每个实例具有不同类型的物理存储。除此之外，我们希望确保写入操作将在具有**ssd**磁盘的每个数据中心的至少一个实例中执行。这可能吗？答案是*是*！

由于**标签集**，这是可能的。标记集是一种配置属性，可用于控制副本集的写入关注点和读取首选项。它们由一个包含零个或多个标记的文档组成。我们将在`members[n].tags`字段的副本集配置文档中存储此配置。

在读取首选项的情况下，标记集为您授予副本集特定成员的目标读取操作。选择读取进程的副本集成员时，将应用标记集值。

标签集将仅影响一种读取首选模式，即`primaryPreferred`、`secondary`、`secondaryPreferred`和`nearest`。标记集将对`primary`模式没有影响，这意味着只会影响副本集次要成员的选择，除非与`nearest`模式结合使用，其中最近的节点或延迟较小的节点可以是主节点。

在我们了解如何进行配置之前，您需要了解副本集成员是如何选择的。将执行该操作的客户端驱动程序进行选择，或者在分片集群的情况下，由**mongos**实例进行选择。

因此，选择过程按以下方式进行：

1.  将创建一个成员列表，包括主成员和辅助成员。
2.  如果指定了标记集，将跳过与规范不匹配的成员。
3.  确定离应用程序最近的客户端。
4.  A list of the other replica set members is created considering the latency among the other members. This latency can be defined as soon as the write operation is performed through the `secondaryAcceptableLatencyMS` property. In the case of a sharded cluster, it is set through the `--localThreshold` or `localPingThresholdMs` options. If none of these configurations are set, the default value will be 15 milliseconds.

    ### 提示

    您可以在[的 MongoDB 手册参考中找到有关此配置的更多信息 http://docs.mongodb.org/manual/reference/configuration-options/#replication.localPingThresholdMs](http://docs.mongodb.org/manual/reference/configuration-options/#replication.localPingThresholdMs) 。

5.  随机选择将被选择来执行操作的主机，并执行读取操作。

标记集配置与任何其他 MongoDB 配置一样简单。一如既往，我们使用文档创建配置，如前所述，标记集是副本集配置文档的一个字段。可以通过在副本集成员上运行`conf()`方法来检索此配置文档。

### 提示

您可以在[的 MongoDB 文档中找到更多关于`conf()`方法的信息 http://docs.mongodb.org/manual/reference/method/rs.conf/#rs.conf](http://docs.mongodb.org/manual/reference/method/rs.conf/#rs.conf) 。

以下文档显示了在复制集的主节点`rs1`的 mongod 外壳上执行`rs.conf()`命令后，读取操作的标记集示例：

```js
rs1:PRIMARY> rs.conf()
{ // This is the replica set configuration document

 "_id" : "rs1",
 "version" : 4,
 "members" : [
 {
 "_id" : 0,
 "host" : "172.17.0.2:27017"
 },
 {
 "_id" : 1,
 "host" : "172.17.0.3:27017"
 },
 {
 "_id" : 2,
 "host" : "172.17.0.4:27017"
 }
 ]
}

```

为了为副本集的每个节点创建标记集配置，我们必须在主 mongod shell 中执行以下命令序列：

首先，我们将获取副本集配置文档并将其存储在`cfg`变量中：

```js
rs1:PRIMARY> cfg = rs.conf()
{
 "_id" : "rs1",
 "version" : 4,
 "members" : [
 {
 "_id" : 0,
 "host" : "172.17.0.7:27017"
 },
 {
 "_id" : 1,
 "host" : "172.17.0.5:27017"
 },
 {
 "_id" : 2,
 "host" : "172.17.0.6:27017"
 }
 ]
}

```

然后，通过使用`cfg`变量，我们将为三个副本集成员中的每一个在`members[n].tags`字段中设置一个文档作为新值：

```js
rs1:PRIMARY> cfg.members[0].tags = {"media": "ssd", "application": "main"}
rs1:PRIMARY> cfg.members[1].tags = {"media": "ssd", "application": "main"}
rs1:PRIMARY> cfg.members[2].tags = {"media": "ssd", "application": "report"}

```

最后，我们调用`reconfig()`方法，传入存储在`cfg`变量中的新配置文档，以重新配置副本集：

```js
rs1:PRIMARY> rs.reconfig(cfg)

```

如果一切都正确，那么我们必须在 mongod shell 中看到以下输出：

```js
{ "ok" : 1 }

```

为了检查配置，我们可以重新执行命令`rs.conf()`。这将返回以下内容：

```js
rs1:PRIMARY> cfg = rs.conf()
{
 "_id" : "rs1",
 "version" : 5,
 "members" : [
 {
 "_id" : 0,
 "host" : "172.17.0.7:27017",
 "tags" : {
 "application" : "main",
 "media" : "ssd"
 }
 },
 {
 "_id" : 1,
 "host" : "172.17.0.5:27017",
 "tags" : {
 "application" : "main",
 "media" : "ssd"
 }
 },
 {
 "_id" : 2,
 "host" : "172.17.0.6:27017",
 "tags" : {
 "application" : "report",
 "media" : "ssd"
 }
 }
 ]
}

```

现在，考虑 A1 T1。

```js
{
 "_id": ObjectId("54bf0d719a5bc523007bb78f"),
 "username": "customer1",
 "email": "customer1@customer.com",
 "password": "1185031ff57bfdaae7812dd705383c74",
 "followedSellers": [
 "seller3",
 "seller1"
 ]
}
{
 "_id": ObjectId("54bf0d719a5bc523007bb790"),
 "username": "customer2",
 "email": "customer2@customer.com",
 "password": "6362e1832398e7d8e83d3582a3b0c1ef",
 "followedSellers": [
 "seller2",
 "seller4"
 ]
}
{
 "_id": ObjectId("54bf0d719a5bc523007bb791"),
 "username": "customer3",
 "email": "customer3@customer.com",
 "password": "f2394e387b49e2fdda1b4c8a6c58ae4b",
 "followedSellers": [
 "seller2",
 "seller4"
 ]
}
{
 "_id": ObjectId("54bf0d719a5bc523007bb792"),
 "username": "customer4",
 "email": "customer4@customer.com",
 "password": "10619c6751a0169653355bb92119822a",
 "followedSellers": [
 "seller1",
 "seller2"
 ]
}
{
 "_id": ObjectId("54bf0d719a5bc523007bb793"),
 "username": "customer5",
 "email": "customer5@customer.com",
 "password": "30c25cf1d31cbccbd2d7f2100ffbc6b5",
 "followedSellers": [
 "seller2",
 "seller4"
 ]
}

```

以下读取操作将使用在复制集实例中创建的标记：

```js
db.customers.find(
 {username: "customer5"}
).readPref(
 {
 tags: [{application: "report", media: "ssd"}]
 }
)
db.customers.find(
 {username: "customer5"}
).readPref(
 {
 tags: [{application: "main", media: "ssd"}]
 }
)

```

前面的配置是通过应用程序操作进行*隔离的示例。我们创建了标记集，标记应用程序的性质以及将读取的媒体类型。*

正如我们前面所看到的，当我们需要在地理上分离应用程序时，标记集非常有用。假设我们在两个不同的数据中心拥有 MongoDB 应用程序和副本集的实例。让我们通过在副本集主节点 mongod shell 上运行以下序列来创建标记，以指示我们的实例存在于哪个数据中心中。首先，我们将获取副本集配置文档并将其存储在`cfg`变量中：

```js
rs1:PRIMARY> cfg = rs.conf()

```

然后，通过使用`cfg`变量，我们将为三个副本集成员中的每一个在`members[n].tags`字段中设置一个文档作为新值：

```js
rs1:PRIMARY> cfg.members[0].tags = {"media": "ssd", "application": "main", "datacenter": "A"}
rs1:PRIMARY> cfg.members[1].tags = {"media": "ssd", "application": "main", "datacenter": "B"}
rs1:PRIMARY> cfg.members[2].tags = {"media": "ssd", "application": "report", "datacenter": "A"}

```

最后，我们调用`reconfig()`方法，传递存储在`cfg`变量中的新配置文档来重新配置副本集：

```js
rs1:PRIMARY> rs.reconfig(cfg)

```

如果一切都正确，那么我们将在 mongod shell 中看到以下输出：

```js
{ "ok" : 1 }

```

我们的配置结果可以通过执行命令`rs.conf()`来检查：

```js
rs1:PRIMARY> rs.conf()
{
 "_id" : "rs1",
 "version" : 6,
 "members" : [
 {
 "_id" : 0,
 "host" : "172.17.0.7:27017",
 "tags" : {
 "application" : "main",
 "datacenter" : "A",
 "media" : "ssd"
 }
 },
 {
 "_id" : 1,
 "host" : "172.17.0.5:27017",
 "tags" : {
 "application" : "main",
 "datacenter" : "B",
 "media" : "ssd"
 }
 },
 {
 "_id" : 2,
 "host" : "172.17.0.6:27017",
 "tags" : {
 "application" : "report",
 "datacenter" : "A",
 "media" : "ssd"
 }
 }
 ]
}

```

在中，为了将读取操作指向给定的数据中心，我们必须在查询中的新标记中指定它。以下查询将使用标记，每个查询将在其自己的数据中心中执行：

```js
db.customers.find(
 {username: "customer5"}
).readPref(
 {tags: [{application: "main", media: "ssd", datacenter: "A"}]}
) // It will be executed in the replica set' instance 0 
db.customers.find(
 {username: "customer5"}
).readPref(
 {tags: [{application: "report", media: "ssd", datacenter: "A"}]}
) //It will be executed in the replica set's instance 2 
db.customers.find(
 {username: "customer5"}
).readPref(
 {tags: [{application: "main", media: "ssd", datacenter: "B"}]}
) //It will be executed in the replica set's instance 1

```

在写操作中，标记集不用于选择可用于写的副本集成员。尽管如此，通过创建自定义写关注点，在写操作中使用标记集是可能的。

让我们回到本节开头提出的要求。我们如何确保写入操作将分布在一个地理区域的至少两个实例上？通过在副本集主节点 mongod shell 上运行以下命令序列，我们将使用五个实例配置副本集：

```js
rs1:PRIMARY> cfg = rs.conf()
rs1:PRIMARY> cfg.members[0].tags = {"riodc": "rack1"}
rs1:PRIMARY> cfg.members[1].tags = {"riodc": "rack2"}
rs1:PRIMARY> cfg.members[2].tags = {"riodc": "rack3"}
rs1:PRIMARY> cfg.members[3].tags = {"spdc": "rack1"}
rs1:PRIMARY> cfg.members[4].tags = {"spdc": "rack2"}
rs1:PRIMARY> rs.reconfig(cfg)

```

标记`riodc`和`spdc`表示我们的实例实际存在于哪些地方。

现在，让我们使用属性`getLastErrorModes`创建一个自定义`writeConcern`MultipleDC。这将确保写入操作将扩展到至少一个位置成员。

为此，我们将执行前面的顺序，在复制集配置文档的`settings`字段上设置一个表示自定义写入关注点的文档：

```js
rs1:PRIMARY> cfg = rs.conf()
rs1:PRIMARY> cfg.settings = {getLastErrorModes: {MultipleDC: {"riodc": 1, "spdc":1}}}

```

mongod shell 中的输出应如下所示：

```js
{
 "getLastErrorModes" : {
 "MultipleDC" : {
 "riodc" : 1,
 "spdc" : 1
 }
 }
}

```

然后调用`reconfig()`方法，传递新配置：

```js
rs1:PRIMARY> rs.reconfig(cfg)

```

如果执行成功，mongod shell 中的输出将是如下文档：

```js
{ "ok" : 1 }

```

从现在开始，我们可以使用`writeConcern`MultipleDC，以确保写入操作将在每个数据中心的至少一个节点上执行，如下所示：

```js
db.customers.insert(
 {
 username: "customer6", 
 email: "customer6@customer.com",
 password: "1185031ff57bfdaae7812dd705383c74", 
 followedSellers: ["seller1", "seller3"]
 }, 
 {
 writeConcern: {w: "MultipleDC"} 
 }
)

```

回到我们的需求，如果我们希望在每个数据中心的至少两个实例中执行写操作，我们必须按照以下方式进行配置：

```js
rs1:PRIMARY> cfg = rs.conf()
rs1:PRIMARY> cfg.settings = {getLastErrorModes: {MultipleDC: {"riodc": 2, "spdc":2}}}
rs1:PRIMARY> rs.reconfig(cfg)

```

而且，为了满足我们的需求，我们可以创建一个名为`ssd`的`writeConcern`多路复用器。这将确保写入操作将在至少一个具有此类型磁盘的实例中发生：

```js
rs1:PRIMARY> cfg = rs.conf()
rs1:PRIMARY> cfg.members[0].tags = {"riodc": "rack1", "ssd": "ok"}
rs1:PRIMARY> cfg.members[3].tags = {"spdc": "rack1", "ssd": "ok"}
rs1:PRIMARY> rs.reconfig(cfg)
rs1:PRIMARY> cfg.settings = {getLastErrorModes: {MultipleDC: {"riodc": 2, "spdc":2}, ssd: {"ssd": 1}}}
rs1:PRIMARY> rs.reconfig(cfg)

```

在下面的查询中，我们看到使用`writeConcern`MultipleDC 如何要求写入操作至少出现在一个具有`ssd`的实例中：

```js
db.customers.insert(
 {
 username: "customer6", 
 email: "customer6@customer.com", 
 password: "1185031ff57bfdaae7812dd705383c74", 
 followedSellers: ["seller1", "seller3"]
 }, 
 {
 writeConcern: {w: "ssd"} 
 }
)

```

在我们的数据库中进行操作隔离并不是一项简单的任务。但是，它对于数据库的管理和维护非常有用。这类任务的早期实现需要对我们的数据模型有很好的了解，因为有关数据库所在存储的详细信息非常重要。

在下一节中，我们将看到如何为需要高吞吐量和快速响应时间的应用程序规划集合。

### 提示

如果您想了解更多关于如何配置副本集标记集的信息，可以访问位于[的 MongoDB 参考手册 http://docs.mongodb.org/manual/tutorial/configure-replica-set-tag-sets/#replica-设置配置标签设置](http://docs.mongodb.org/manual/tutorial/configure-replica-set-tag-sets/#replica-set-configuration-tag-sets)。

# 封顶收藏

非功能性需求通常与应用程序的响应时间有关。特别是现在，当我们一直连接到新闻源，我们希望在最短的响应时间内获得新的信息。

MongoDB 有一种特殊类型的集合，可以满足这种非功能性需求，即 capped 集合。Capped 集合是支持高读写吞吐量的固定大小集合。这是因为文档是按自然顺序插入的，不需要索引来执行写入操作。

MongoDB 保证了自然插入顺序，它像写入磁盘一样写入数据。因此，在文档的生命周期中，不允许进行增加文档大小的更新。一旦集合达到最大大小，MongoDB 就会自动清理旧文档，以便插入新文档。

一个非常常见的用例是应用程序日志的持久性。MongoDB 本身使用副本集操作日志`oplog.rs`作为封顶集合。在[第 8 章](8.html "Chapter 8. Logging and Real-time Analytics with MongoDB")中，*使用 MongoDB*进行日志记录和实时分析，您将看到这方面的另一个实际示例。

MongoDB 的另一个非常常见的用法是作为发布者/订阅者系统，特别是当我们使用可定制的游标时。可定制游标是即使在客户端读取所有返回的记录后仍保持打开状态的游标。因此，当新文档插入到集合中时，光标将其返回给客户机。

以下命令创建`ordersQueue`集合：

```js
db.createCollection("ordersQueue",{capped: true, size: 10000})

```

我们使用`util`命令`createCollection`来创建我们的 capped 集合，向它传递名称`ordersQueue`和一个集合，该集合的`capped`属性的值为`true`，而`size`的值为`10000`。如果`size`属性小于 4096，MongoDB 将其调整为 4096 字节。另一方面，如果大于 4096，MongoDB 将增大大小并将其调整为 256 的倍数。

或者，我们可以使用`max`属性设置集合可以拥有的最大文档编号：

```js
db.createCollection(
 "ordersQueue",
 {capped: true, size: 10000, max: 5000}
)

```

### 注

如果我们需要将一个集合转换为一个有上限的集合，我们应该使用如下的`convertToCapped`方法：

```js
db.runCommand(
 {"convertToCapped": " ordersQueue ", size: 100000}
)

```

正如我们已经看到的，MongoDB 以自然的顺序保存文档，换句话说，文档插入 MongoDB 的顺序。考虑下面的文档，插入到 AutoT0.集合中，如图所示：

```js
{
 "_id" : ObjectId("54d97db16840a9a7c089fa30"), 
 "orderId" : "order_1", 
 "time" : 1423539633910 
}
{
 "_id" : ObjectId("54d97db66840a9a7c089fa31"), 
 "orderId" : "order_2", 
 "time" : 1423539638006 
}
{
 "_id" : ObjectId("54d97dba6840a9a7c089fa32"), 
 "orderId" : "order_3", 
 "time" : 1423539642022 
}
{
 "_id" : ObjectId("54d97dbe6840a9a7c089fa33"), 
 "orderId" : "order_4", 
 "time" : 1423539646015 
}
{
 "_id" : ObjectId("54d97dcf6840a9a7c089fa34"), 
 "orderId" : "order_5", 
 "time" : 1423539663559 
}

```

查询`db.ordersQueue.find()`产生以下结果：

```js
{ 
 "_id" : ObjectId("54d97db16840a9a7c089fa30"), 
 "orderId" : "order_1", 
 "time" : 1423539633910 
}
{ 
 "_id" : ObjectId("54d97db66840a9a7c089fa31"), 
 "orderId" : "order_2", 
 "time" : 1423539638006 
}
{ 
 "_id" : ObjectId("54d97dba6840a9a7c089fa32"), 
 "orderId" : "order_3", 
 "time" : 1423539642022 
}
{ 
 "_id" : ObjectId("54d97dbe6840a9a7c089fa33"), 
 "orderId" : "order_4", 
 "time" : 1423539646015 
}
{ 
 "_id" : ObjectId("54d97dcf6840a9a7c089fa34"), 
 "orderId" : "order_5", 
 "time" : 1423539663559 
}

```

如果我们使用如下查询中所示的`$natural`运算符，我们将得到与前面输出相同的结果：

```js
db.ordersQueue.find().sort({$natural: 1})

```

但如果我们首先需要最后一次插入，则必须在`$natural`运算符上执行具有`-1`值的命令：

```js
db.ordersQueue.find().sort({$natural: -1})

```

在创建封顶集合时，我们必须谨慎，因为：

*   我们不能分割封顶集合。
*   我们无法更新封顶集合中的文档；否则，文档会变大。如果我们需要更新封顶集合中的文档，那么我们必须确保大小保持不变。为了获得更好的性能，我们应该创建一个索引，以避免在更新时进行集合扫描。
*   我们无法删除封顶集合中的文档。

Capped集合是一个很好的工具，当我们将高读/写吞吐量作为非功能需求时，或者我们需要以字节或文档编号限制集合大小时。

尽管如此，如果我们需要自动终止数据，基于时间框架，我们应该使用**生存时间**（**TTL**功能。

# 数据自失效

正如您已经在[第 4 章](4.html "Chapter 4. Indexing")、*索引*中看到的，MongoDB 为我们提供了一种索引类型，可以帮助我们在一定时间（以秒为单位）后或特定日期从集合中删除数据。

实际上，TTL 是一个后台线程，它在 mongod 实例上执行，mongod 实例在索引上查找带有日期类型字段的文档，并将其删除。

考虑一个带有以下文档的 Type T0 集合：

```js
{ 
 "_id" : ObjectId("5498da405d0ffdd8a07a87ba"), 
 "username" : "customer1", 
 "email" : "customer1@customer.com", 
 "password" : "b1c5098d0c6074db325b0b9dddb068e1", "accountConfirmationExpireAt" : ISODate("2015-01-11T20:27:02.138Z") 
}

```

要使此集合中的文档在 360 秒后过期，我们应创建以下索引：

```js
db.customers.createIndex(
 {accountConfirmationExpireAt: 1}, 
 {expireAfterSeconds: 3600}
)

```

为了使文件在 2015-01-11 20:27:02 到期，我们应创建以下索引：

```js
db.customers.createIndex(
 {accountConfirmationExpireAt: 1}, 
 {expireAfterSeconds: 0}
)

```

当使用 TTL 功能时，我们必须格外小心，并记住以下几点：

*   我们无法在封顶集合上创建 TTL 索引，因为 MongoDB 将无法从集合中删除文档。
*   TTL 索引不能包含属于另一个索引的字段。
*   索引字段应为日期或日期类型的数组。
*   尽管在每个副本集节点中都有后台线程（当我们有一个 TTL 索引时，它会删除文档），但它只会从主副本集中删除文档。复制过程将从副本集的辅助节点删除文档。

# 总结

在本章中，您看到，除了考虑基于查询的模式设计之外，还需要考虑创建集合的操作和维护计划。

您了解了如何使用标记集来处理数据中心感知的操作，以及为什么我们通过执行 capped collection 来限制集合中存储的文档数量。以同样的方式，您看到了 TTL 索引在实际用例中是如何有用的。

在下一章中，您将看到如何通过创建碎片来扩展 MongoDB 实例。