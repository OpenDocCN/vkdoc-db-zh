# 2. 通过数据库性能视角看您的项目

工作负载混合（读写比例）项目大小项目类型数据集大小吞吐量预期延迟预期并发性连接技术需求波动 ACID 事务一致性预期地理分布高可用性预期总结

您的团队将面临的具体数据库性能约束和优化机会，将根据您的具体负载、应用程序和业务预期而大幅变化。本章旨在让您和您的团队讨论您能实际优化性能的程度，突出一些与常见情况相关的具体教训，并帮助您设定现实的目标，如果您面临如大量负载大小和严格一致性要求等负担。本章首先从技术因素开始，例如您的工作负载的读写比例、项目大小/类型等。然后，它转向业务考虑因素，如一致性要求和高可用性预期。在整个过程中，本章讨论了在不同环境中已被证明是有益或有限的数据库属性。

注意

由于本章涵盖了广泛的应用场景，并非所有内容都适用于您的特定项目和负载。请随意浏览本章，并关注似乎最相关的部分。

## 工作负载混合（读写比例）

不论是读密集型、写密集型、均衡混合型、删除密集型等，理解和适应您的读写比例是数据库性能的关键但常被忽视的方面。一些数据库在处理读密集型负载时表现出色，其他数据库则针对写密集型情况进行了优化，还有一些数据库旨在同时适应这两种情况。选择或坚持使用与您当前和未来情况不匹配的数据库，将是一个重大的负担，无论您如何策略性地优化其他所有方面，都将难以克服。

成本也会产生重大影响。这可能看起来与性能没有直接关系，但如果您负担不起（或无法获得批准）支持您工作负载所需的基础设施，这将明显限制您的性能。1

小贴士

不确定您的工作负载是什么样的？这是许多情况下可观察性成为您朋友的一个例子。如果您的现有数据库无法帮助您分析工作负载，考虑是否可以在兼容的数据库上尝试您的负载，该数据库能够提供更深入的可见性。

### 写密集型工作负载

如果你有一个以写操作为主的负载，我们强烈推荐使用存储在不可变文件中的数据库（例如，Cassandra、ScyllaDB 以及其他使用 LSM 树的数据库）。^(2) 这些数据库通过以下方式优化写速度：1) 写操作是顺序的，这在磁盘 I/O 方面更快；2) 写操作立即执行，无需首先担心读取或更新现有值（如依赖于 B 树的数据库）。因此，你可以通常以非常低的延迟写入大量数据。

然而，如果你选择写入优化的数据库，请做好更高的存储需求和潜在较慢读取的准备。当你与不可变文件一起工作时，你需要足够的存储空间来保存所有积累到压缩运行之前的不可变文件。^(3) 通过仔细选择压缩策略，你可以在一定程度上减轻存储需求。此外，存储目前相对便宜。

读取放大潜力通常在写入优化的数据库中是一个更重大的担忧（考虑到需要搜索的所有文件，每个读取请求需要更多的磁盘读取）。

但读取性能不一定会受到影响。你通常可以通过实现自己的缓存子系统（而不是依赖于操作系统的内置缓存）的写入优化的数据库来最小化这种权衡，使快速读取与极快的写入共存。通过绕过底层操作系统并使用以性能为重点的内置缓存，应该可以很好地加快你的读取速度，使延迟几乎与读取优化的数据库相当。

对于以写操作为主的负载，如果你的峰值吞吐量很高，拥有极快的存储，如 NVMe 驱动器，也是至关重要的。如果磁盘本身无法跟上，理论上能够快速存储值的数据库最终也不会有帮助。

另一个考虑因素：请注意，以写操作为主的负载在扩展时可能会导致出人意料的成本增加。在某些供应商的定价模型下，写入的成本大约是读取的五倍。在你投入太多精力进行性能优化之前，最好对你的解决方案进行规模定价，并确保它是一个良好的长期解决方案。

### 读取密集型负载

对于以读操作为主的负载，情况略有不同。B 树数据库（如 DynamoDB）优化了读取操作（这是在写入路径上更新值所需额外时间的回报）。然而，对于读取优化的数据库在读取方面提供的优势通常不如写入优化的数据库在写入方面提供的优势显著，尤其是如果写入优化的数据库使用内部缓存来弥补差异（如前节所述）。

仔细的数据建模将为优化你的读取带来巨大的回报。同样，仔细选择读取一致性（最终一致性读取是否可接受，而不是强一致性读取？），将数据库放置在应用程序附近，以及彻底分析你的查询访问模式，都将大有裨益。思考你的访问模式对于成功处理大量读取的工作负载尤为重要。考虑以下方面：

+   应用程序将频繁查询的数据的性质是什么？它是否可以容忍可能过时的读取，还是需要立即一致性？

+   它被访问的频率如何（例如，是频繁访问的“热”数据，可能被缓存，还是很少访问的“冷”数据）？

+   是否需要聚合、JOIN 操作和/或对非主键组件字段进行查询的灵活性？

+   说到主键，基数是多少？

例如，假设你的用例需要动态查询功能（例如自动补全用例、报告构建解决方案等），在这种情况下，你经常需要从除了你的主键/哈希键组件之外的列中查询数据。在这种情况下，你可能发现自己过于频繁地进行全表扫描，或者依赖于过多的索引。这两种情况，以某种方式，最终可能会损害你的读取性能。

在基础设施方面，选择具有高内存占用率的服务器对于在主要提供频繁访问的数据时实现低读取延迟至关重要。另一方面，如果你的读取主要针对冷数据，你将需要在存储速度和内存之间找到一个良好的平衡。实际上，许多分布式数据库通常为缓存索引预留一些内存空间；这样，不可避免地需要访问磁盘的读取就不会通过扫描无关数据而浪费 I/O。

如果用例需要同时从热数据和冷数据中读取呢？如果你对每组数据有不同的延迟要求呢？或者如果你想在同一个数据集上混合实时工作负载和你的分析工作负载呢？这种情况相当常见。没有一刀切的方法，但以下是一些重要的提示：

+   一些数据库允许你在不污染你的缓存的情况下读取数据（例如，用不太可能再次请求的数据填满它）。在同时运行大扫描并实时提供数据时，使用这种机制尤为重要。如果允许大扫描覆盖实时工作负载所需的先前缓存的条目，那么这些读取将不得不通过磁盘进行，并再次填充到缓存中。这实际上会浪费宝贵的处理时间，并导致延迟增加。

+   对于需要区分热/冷数据存储（为了节省成本、不同的延迟要求或两者兼而有之）的用例，使用*分层存储*（一种基于一系列要求，如性能和成本对数据存储进行优先级排序的方法）的解决方案可能是一个不错的选择。

+   一些数据库允许你优先处理某些工作负载。如果这还不够，你可以进一步采取一步，逻辑上完全隔离这些工作负载。4

注意

你可能不需要所有的读取操作。在 ScyllaDB，我们遇到过许多案例，其中团队执行了他们实际上并不需要的读取操作。例如，通过使用先读后写的方法来避免多个客户端同时尝试用不同的更新更新相同值而产生的竞争条件。解决方案的细节在这里并不重要，但重要的是要注意，通过重新思考他们的方法，他们能够减少写入的延迟，并通过消除不必要的读取来加快整体响应速度。这里的教训是：用新的视角审视现有的方法可能会发现解锁意外性能优化的方法。

### 混合工作负载

更均匀的混合访问模式通常更复杂，更难以分析和适应。一般来说，混合工作负载之所以复杂，是因为从数据库的角度来看，存在两个相互竞争的工作负载。数据库本质上是为读取和写入这两件事而设计的。不同数据库处理各种竞争工作负载的方式，真正区分了不同的解决方案。当你测试和比较数据库时，尝试不同的读写比例，以便你能够充分准备应对访问模式可能发生变化的情况。

一定要考虑细微差别，比如你的读取操作是来自冷数据（不常访问的数据）还是热数据（经常访问且可能已缓存的）。分析用例通常需要频繁读取冷数据，因为它们需要处理大量数据。在这种情况下，磁盘速度对于整体性能非常重要。此外，你还需要一个足够大的内存量，以便数据库的缓存可以存储你需要处理的数据。另一方面，如果你经常访问热数据，大部分数据将来自缓存，这样磁盘速度变得不那么重要（尽管不是可以忽略不计的）。

小贴士

不确定你的读取操作是来自冷数据还是热数据？查看你的监控仪表板中缓存未命中的比率。有关监控的更多信息，请参阅第十章。

如果您的缓存未命中率高于命中率，这意味着读取需要频繁地访问磁盘以查找您的数据。这可能是因为您的数据库在内存空间上配置不足，或者简单地因为应用程序访问模式通常读取很少访问的数据。理解这里的性能影响很重要。如果您经常从冷数据中读取，存在 I/O 成为瓶颈的风险——对于写入和读取都一样。在这种情况下，如果您需要提高性能，增加更多节点或将您的存储介质切换到更快的解决方案可能会有所帮助。

如前所述，写入优化型数据库可以通过内部缓存提高读取延迟，因此对于有 60%读取和 40%写入的团队来说，选择写入优化型数据库并不罕见。另一个选择是使用写入优化型数据库提高读取延迟：如果您的数据库支持，为读取分配额外的“份额”资源，以便在资源竞争时优先处理读取工作负载。

### 删除密集型工作负载

对于像使用数据库作为持久队列（从生产者保存数据直到消费者访问它，删除它，然后重复此过程）这样的删除密集型工作负载怎么办？在这种情况下，您通常想要避免存储在不可变文件中并使用坟墓标记即将删除的行和列的数据库。最显著的例子是 Cassandra 和其他兼容 Cassandra 的数据库。

坟碑消耗缓存空间和磁盘资源，数据库需要搜索所有这些坟墓才能到达活数据。对于许多工作负载来说，这并不是问题。但对于删除密集型工作负载，随着时间的推移，生成过多的坟墓将显著降低您的读取延迟。有方法和机制可以减轻坟墓的影响。5 然而，总的来说，如果您有一个删除密集型工作负载，可能最好使用不同的数据库。

重要的是要注意，偶尔的删除在 Cassandra 和兼容 Cassandra 的数据库上通常是没问题的。只需注意，在只追加数据库上的删除会导致坟墓写入。因此，这可能会导致读取放大，提高您的读取延迟。这些类型数据库的坟墓和数据驱逐可能是长而复杂的话题，也许可以有自己的专门章节。然而，高级建议是，如果您有一个可能删除密集型模式，您可能稍后会读取，请务必谨慎行事，并确保将其与针对高效数据驱逐量身定制的压缩策略相结合。

话虽如此，值得注意的是，一些团队已经在 Cassandra 和类似 Cassandra 的数据库上成功实现了以删除为主的工作负载。由墓碑带来的性能开销通常通过数据建模、仔细研究删除操作的方式、避免读取可能扫描大量已删除数据的读取操作，以及仔细调整底层表的压缩策略来确保墓碑及时被清除来规避。例如，腾讯游戏使用了时间窗口压缩策略来积极过期墓碑，并将其作为时间序列分布式队列的基础。6

### 竞争工作负载（实时 vs 批量）

如果你正在处理两种不同类型的工作负载——其中一种比另一种更敏感于延迟——理想的解决方案是让数据库为更敏感于延迟的工作负载分配更多资源，以防止它们因资源不足而失败。这通常在你试图平衡 OLTP（实时）工作负载时发生，这些工作负载面向用户，需要低延迟响应，以及 OLAP（分析）工作负载，这些工作负载可以批量运行，更注重吞吐量（见图 2-1）。或者，你可以优先考虑分析。两者在技术上都是可行的；关键在于对你用例来说什么最重要。

![图片](img/541783_1_En_2_Fig1_HTML.jpg)

O L T P 和 OLAP 的框图。数据库集群向 O L T P 客户端和 O L A P 客户端发送和接收数据。

图 2-1

OLTP 与 OLAP 工作负载

例如，假设你有一个带有分析的 Web 服务器数据库。它必须支持两个工作负载：

+   主要工作负载由用户点击或导航网页某些区域触发的查询组成。在这里，用户期望高响应性，这通常转化为对低延迟的要求。你需要低超时时间，并使用负载削减作为你的过载响应，你希望在任何需要此工作负载时都有大量可用资源。

+   第二个工作负载驱动定期运行的分析，以收集一些应向用户展示的统计数据或汇总一些信息。这涉及一系列计算。它对延迟的敏感性远低于主要工作负载；它更注重吞吐量。你可以设置相当大的超时时间，以适应始终满载的队列。你希望在负载下调节请求，以便计算稳定且可控。最后，你希望工作负载拥有非常少的专用资源，并主要使用未使用的资源来实现更好的集群利用率。

在同一集群上运行，此类工作负载将竞争资源。随着系统利用率上升，数据库必须严格优先考虑哪些活动可以获得在争用中的哪些具体资源份额。有几种不同的方法可以处理这种情况。在适当的情况下，物理隔离、逻辑隔离和计划隔离都可以是可接受的选择。第八章涵盖了这些选项。

## 项目大小

你在数据库中存储的项目大小（平均有效负载大小）将决定你的工作负载是 CPU 受限还是存储受限。例如，以 90KB 的平均有效负载运行 100K OPS 与以 1KB 有效负载实现相同的吞吐量有很大不同。较大的有效负载比较小的有效负载需要更多的处理、I/O 和网络流量。

不深入探讨数据库内部结构，一个显著的影响是对页面缓存的影响。假设默认页面缓存大小为 4KB，数据库将不得不为最大的有效负载提供几个页面——这需要更多的 I/O 来发布、处理、合并并返回给应用程序客户端。在 1KB 的例子中，你可以从单个页面缓存条目中提供它，这从计算资源的角度来看压力较小。相反，拥有大量的小尺寸项目可能比拥有较少的大尺寸项目引入更多的 CPU 开销，因为数据库必须单独处理每个到达的项目。

通常，有效负载越大，缓存活动就越多。大多数写入优化的数据库会在将信息持久化到磁盘之前将其写入内存（实际上，这也是它们写入优化的原因之一）。较大的有效负载更频繁地耗尽可用的缓存空间，这需要更高的刷新活动来将信息持久化到磁盘，以便为更多的传入写入释放空间。因此，需要更多的磁盘 I/O 来持久化这些信息。如果你没有正确地调整大小，它可能会在整个重复过程中成为瓶颈。

当你处理极大规模的有效负载时，设定现实的延迟和吞吐量预期非常重要。如果你需要服务 200KB 的有效负载，任何数据库都不太可能让你实现个位数的毫秒延迟。即使整个数据集都从缓存中提供，你的客户端和数据库之间也存在一个物理障碍：网络。它们之间的网络最终会限制你的传输速度，即使客户端和数据库都极快。最终，这会影响吞吐量和延迟。随着延迟的增加，你的客户端最终会降低速度，你将无法实现与较小有效负载大小相同的吞吐量。请求将停滞，在网络中排队。7

通常来说，数据库不应用于存储大型 blob。我们见过有人试图在数据库中存储单个键内的数 GB 数据——这并不是一个好主意。如果您的项目大小达到这个规模，请考虑替代解决方案。一种解决方案是使用 CDN。另一种解决方案是将您负载大小的最大块存储在冷存储中，如 Amazon S3 存储桶、Google Cloud 存储或 Azure blob 存储。然后，将数据库用作元数据查找：它可以读取数据并获取一个标识符，这将有助于在冷存储中找到数据。例如，这是由一个游戏开发者采用的策略，将极大型（通常在 GB 范围内）内容转换为流行的游戏平台。他们存储带有 blob 的结构化对象，这些 blob 通过内容哈希进行引用。最大的负载存储在云供应商的对象存储解决方案中，而内容哈希存储在分布式 NoSQL 数据库中^(8)。

注意，一些数据库对项目大小设置了硬性限制。例如，DynamoDB 当前的最大项目大小为 400KB。这可能不符合您的需求。此外，如果您使用的是如 Redis 这样的内存解决方案，较大的键会迅速耗尽您的内存。在这种情况下，在存储之前对这样的大型对象进行哈希/压缩可能是有意义的。

无论您选择哪种数据库，您的负载越小，引入内存碎片化的可能性就越大。这可能会降低您的内存效率，进而可能提高成本，因为数据库无法充分利用其可用内存。

## 项目类型

项目类型对压缩有重大影响，这反过来又影响您的存储利用率。如果您经常存储文本，可以期待利用高压缩比。但对于随机和不常见的 blob 序列来说，情况并非如此。在这里，压缩不太可能显著减少您的存储占用。如果您担心您的用例的存储利用率，使用对压缩友好的项目类型可以带来很大的差异。

如果您的用例指定了某种项目类型，请考虑针对该类型优化的数据库。例如，如果您需要频繁处理无法轻松转换的 JSON 数据，那么与 Cassandra 兼容的数据库相比，MongoDB 这样的文档数据库可能是一个更好的选择。如果您有一些常见的字段和一些基于用户输入而变化的字段，那么在 Cassandra 中建模它们可能很复杂——尽管是可能的——您将在应用端承担序列化/反序列化开销的惩罚。

作为一般规则，选择存储所需数据类型所需的最小数据类型。例如，你不需要将年份存储为`bigint`。如果你将字段定义为`bigint`，大多数数据库都会为其分配相关的内存地址空间来存储它。如果你可以用较小的`int`类型来处理，那就这么做——你将节省内存字节，这在规模上可能会累积起来。即使你使用的数据库不会根据数据类型预先分配内存地址空间，选择正确的数据类型仍然是一种很好的方式来组织数据模型——并且还可以避免未来围绕为什么选择特定数据类型而不是另一个数据类型的问题。

许多数据库支持额外的项目类型，这些类型适用于各种用例。例如，集合允许你在宽列数据库的单个列下存储集合、列表和映射（键值对）。这些数据类型通常被误用，并导致严重的性能问题。实际上，我们遇到的大部分数据建模问题都涉及集合的误用。集合旨在存储少量信息（例如个人的电话号码或不同的家庭/商业地址）。然而，拥有数十万个条目的集合并不像你想象的那么罕见。它们最终会在数据库中引入严重的反序列化开销。最好的情况是，这会导致更高的延迟。最坏的情况是，由于扫描此类列下大量项目时涉及的延迟，数据变得完全不可读。

一些数据库也支持用户自定义字段，例如 Cassandra 中的用户定义类型（UDTs）。当将多个列合并为一个时，UDTs 可以成为减少反序列化开销的强大盟友。想想看：你是愿意单独反序列化四个布尔列，还是愿意反序列化一个包含四个布尔值的单列？UDTs 通常在将多个值作为单个列反序列化时表现出色，这可能会给你带来性能提升。9 就像集合一样，然而，UDTs 也不应该被误用——误用 UDTs 可能会导致与集合相同的严重后果。

注意

UDTs 在第六章 6 中得到了广泛的介绍。

## 数据集大小

了解你的数据集大小对于选择适当的基础设施选项很重要。例如，AWS 云实例提供了广泛的 NVMe 存储选项。了解你需要多少存储可以帮助你避免选择会导致性能下降的实例（如果你最终存储不足）或者从成本角度来看浪费的实例（如果你过度配置）。

重要的是要注意，你选择的存储大小不应等于你的总数据集大小。你还需要考虑复制和增长——并且避免 100%的存储利用率。

例如，假设你已经有了 3TB 的已压缩数据。支持工作负载的最低要求是你的当前数据集大小乘以你预期的复制因子。如果你有 3TB 的数据，并且复制因子为常见的三，那么总共是 9TB。如果你天真地将这些数据部署在三个节点上，每个节点支持 3TB 的数据，那么你会接近 100%的磁盘利用率，这当然不是最优的。

相反，如果你考虑一些空闲空间和最小的增长空间，你希望从至少六个这种大小的节点开始——每个节点只存储 1.5TB 的数据。这给你大约 50%的利用率。另一方面，如果你的数据库无法支持每个节点那么多的数据（每个数据库都有限制）或者如果你没有预见大量的未来数据增长，你可以有六个节点，每个节点支持 2TB，这样在 75%的利用率下，每个副本大约存储 1.5TB。记住：考虑到你的增长对于避免生产中的不愉快惊喜至关重要，无论是从运营还是预算的角度来看。

注意

我们非常有意地从压缩数据的角度讨论了数据集大小。请注意，一些数据库供应商根据未压缩数据来衡量你的存储利用率。这往往会导致混淆。如果你正在将数据从一个数据库解决方案迁移到另一个，并且你的数据未压缩（或者你不确定它是否已压缩），考虑在之前先加载你总数据集的一小部分，以便确定其压缩率。有效的压缩可以显著减少你的存储足迹。

如果你正在处理一个非常灵活的项目，无法定义或预测你的数据集大小，无服务器数据库部署模型可能是一个不错的选择，以提供易于灵活性和扩展。但请注意，整体数据集大小和/或 IOPS（取决于定价模型）的快速增加可能会导致价格呈指数级飙升。即使你没有明确为存储大量数据支付罚款，你也可能因为与该大量数据相关的大量操作而支付额外费用。无服务器数据库在第七章 7 中讨论得更多。

## 吞吐量预期

你预期的吞吐量和延迟应该是从数据库和基础设施选择到监控的“北极星”。让我们从吞吐量开始。

如果你认真对待数据库性能，了解你试图达到的吞吐量是至关重要的——而“高吞吐量”不是一个可接受的答案。具体来说，尽量争取所有相关利益相关者就每秒的目标峰值读操作数和每秒的目标峰值写操作数达成一致，并且是针对每个工作负载的。

让我们稍微解释一下。首先，确保区分读吞吐量和写吞吐量。数据库的读路径通常与其写路径截然不同。它对基础设施的不同部分施加压力，并触及不同的数据库内部。而且，客户端/用户的读体验通常与写体验大不相同。将它们合并成一个无意义的数值，对性能测量或优化帮助不大。平均吞吐量的主要用途在于应用 Little's Law（关于这一点，在本章稍后的“并发性”部分将详细介绍）。

另一个注意事项：同一个数据库过去或当前的吞吐量，对于另一个用例来说，并不能保证未来的结果——即使它是在相同的基础设施上运行的同一个数据库。影响因素太多（项目大小、访问模式、并发性……本章中提到的所有这些因素）。对某个用例非常适合的，可能对另一个用例来说完全不合适。

此外，请注意对每秒*峰值*操作的强调。如果你以平均值为出发点进行构建和优化，你很可能无法超出这个平均值的上限。关注你需要持续维持的峰值吞吐量，以覆盖你的核心需求和业务模式——包括高峰期。认识到数据库通常可以“提升”以维持短时间内的极高负载。然而，为了安全起见，最好为可能的峰值进行规划，并将提升保留用于非典型情况。

此外，务必不要将并发性与吞吐量混淆。*吞吐量*是数据库执行读或写操作的速度；它以每秒读或写操作的数量来衡量。*并发性*是客户端同时发送到数据库的请求数量（这反过来最终会转化为数据库执行时排队等待处理的并发请求数量）。并发性以一个硬数值表示，而不是一段时间内的速率。并不是同时产生的每个请求都能被数据库同时处理。你的客户端可能一次性向数据库发送 150K 个请求。如果数据库运行在 500K OPS，它可能会迅速处理所有这些并发请求。或者，如果数据库吞吐量达到 50K OPS，它可能需要一段时间来处理这些请求。

通常情况下，可以通过增加集群大小（和/或功率）来提高吞吐量。但是，你还需要特别注意并发性，这一点将在本章的后面以及第五章中更深入地讨论。在大多数情况下，高并发对于实现令人印象深刻的性能是必不可少的。但如果客户端最终以数据库无法处理的并发性压倒数据库，吞吐量将受到影响，延迟也将作为副作用上升。一个超越数据库世界的友好提醒：没有系统，无论是分布式的还是非分布式的，都支持无限的并发性。这就是了。

注意

尽管扩展集群可以提高数据库处理能力，但请记住，应用程序访问模式直接影响到最终会产生多少影响。在一种情况下，扩展集群可能不会提供期望的吞吐量增加，那就是在*热点分区*^(10)情况下，这会导致流量主要针对一组特定的副本。在这些情况下，限制对这类热点键的访问对于保持系统的整体性能至关重要。

## 延迟预期

延迟是一个比吞吐量更复杂的挑战：你可以通过添加更多节点来提高吞吐量，但降低延迟没有简单的解决方案。你需要达到的延迟越低，理解和探索数据库权衡以及内部数据库优化就越重要，这些优化可以帮助你从延迟中削减毫秒或微秒。数据库内部，驱动程序优化，高效的 CPU 利用率，足够的 RAM，高效的数据建模……所有这些都很重要。

与吞吐量一样，目标是让所有相关利益相关者就可接受的延迟达成一致。这通常表示为请求的某个百分比的延迟。对于对性能敏感的工作负载，跟踪第 99 百分位（P99）是常见的。一些团队甚至更高，比如 P9999，它指的是第 99.99 百分位。

与吞吐量一样，避免只关注*平均*（均值）或中位数（P50）的延迟测量。平均延迟是一个理论测量值，它与系统或用户在现实中体验到的任何东西都没有直接相关性。平均值掩盖了异常值：与正常值有极大偏差的情况，可能会对整体系统性能产生重大且意外的负面影响，从而影响用户体验。

例如，看看图 2-2 中平均延迟和 P99 延迟之间的差异（不同颜色代表不同的数据库节点）。P99 延迟通常比平均读取延迟高出一倍，对于写入来说情况更糟。

![图片](img/541783_1_En_2_Fig2_HTML.jpg)

六种数据库图显示了平均读写延迟与实例的关系。在第一张图中，平均读取延迟大多在 2 到 6 毫秒之间。

图 2-2

一个示例数据库监控仪表板。注意平均延迟和 P99 延迟之间的差异

注意，监控系统有时被配置成忽略异常值。例如，如果一个监控系统被校准为在 0 到 1000 毫秒的范围内测量延迟，它将忽略任何更大的测量值——从而未能检测到查询超时和重试的严重问题。

P99 及以上的百分位数并不完美。11 但对于对延迟敏感的使用案例，它们是在你选择基础设施、基准测试、监控等时需要记住的数字。

此外，要清楚你想要实现的 P99 具体包括什么。数据库延迟是数据库接收到请求、处理它并发送适当响应所花费的时间。客户端延迟更广泛：在这里，测量从客户端发送请求开始，到客户端接收到数据库的响应结束。它包括网络时间和客户端处理时间。数据库延迟和客户端延迟之间可能存在相当大的差异；十倍高的客户端延迟并不罕见（尽管显然是不希望的）。可能有许多原因可以解释客户端延迟比数据库延迟显著更高的情况：过度的并发、低效的应用程序架构、编码问题等。但这超出了本次讨论的范围——甚至超出了本书的范围。

这里关键点是，你的团队和所有利益相关者需要就你们要测量的内容达成一致。例如，假设你被分配了一个 15 毫秒的读取延迟要求。你努力工作以使数据库达到这个目标并报告你已经满足了预期——然后你得知利益相关者实际上期望的是完整的客户端延迟为 15 毫秒。回到起跑线。

最终，跟踪数据库延迟和客户端延迟都很重要。你可以尽可能优化数据库，但如果应用程序从客户端引入延迟问题，快速的数据库不会有太大影响。如果没有对数据库和客户端延迟的可见性，你实际上是在半盲状态下操作。

## 并发

你的数据库应该准备处理多少级别的并发？根据数据库集群期望的服务质量，并发必须谨慎平衡以达到适当的吞吐量和延迟值。否则，请求将堆积等待处理，导致延迟激增，超时增加，整体用户体验下降。

Little 定律确立了以下原则：

+   L=λW

其中λ是平均吞吐量，W 是平均延迟，L 代表在集群达到稳定状态时，任何给定时刻正在处理或排队等待处理的总请求数。鉴于你的吞吐量和延迟目标通常是固定的，你可以使用 Little 定律来估算一个现实的并发量。

例如，如果你希望系统每秒处理 500,000 个请求，平均延迟为 2.5 毫秒，最佳并发性约为 1,250 个正在进行的请求。当你接近系统的饱和限制——大约每秒 600,000 个读取请求时，并发性的增加将保持恒定，因为这是数据库的物理限制。每个新的正在进行的请求只会导致延迟增加。实际上，如果你将每秒 600,000 个请求近似为该数据库的物理容量，你可以计算出特定并发点的预期平均延迟。例如，在 6,120 个正在进行的请求时，预期平均延迟为 6120/600,000 = 10 毫秒。

超过最大吞吐量后，增加并发性会增加延迟。相反，减少并发性会减少延迟，前提是这种减少不会导致吞吐量下降。

在某些用例中，查询在客户端累积是可以接受的。但很多时候并不可以。在这些情况下，你可以扩展你的集群或在应用端增加并发性——至少要达到延迟不受影响的程度。这是一项微妙的平衡行为。^([12)]

## 连接技术

数据库无法超越你分布式数据系统中性能最慢的链路。即使你的数据库以极快的速度处理读写操作，如果它与一个未针对性能优化的流式事件平台交互，或者涉及到来自配置不当的 Apache Spark 实例的转换，例如，那么最终这并不会产生太大的影响。

这只是众多原因之一，说明采取全面和主动的监控方法（更多内容请见第十章）非常重要。鉴于数据库和分布式数据系统的复杂性，很难猜测出是哪个组件导致了问题。如果没有对整个系统状态的洞察，你可能会天真地浪费大量时间和资源去优化一些不会产生任何差别的部分。

如果你正在寻求优化现有的数据系统，不要忽视通过审查和调整其连接组件所能实现的性能提升。或者，如果你的监控工作表明某个组件是导致客户端性能问题的罪魁祸首，但你感觉已经对其达到了极限，那么探索替换为更高效的替代方案所需的内容。使用基准测试来确定性能影响程度。

此外，请注意，某些数据库产品可能存在生态系统限制。例如，如果你正在考虑无服务器部署模型，请注意，一些更改数据捕获（CDC）连接器、驱动程序等可能不受支持。

## 需求波动

数据库可能会经历各种不同的需求波动，从可预测的适度波动到不可预测的剧烈峰值。例如，世界上观看最多的体育赛事的需求波动与食品配送服务不同，食品配送服务的需求波动又与救护车跟踪服务不同——所有这些都需要不同的策略和基础设施。

首先，让我们看看可预测的波动。有了可预测性，提前解决问题就更容易了。如果你预计要支持事先已知的周期性大型活动（如黑色星期五、体育锦标赛、票务销售等），你应该有足够的时间为每个预期的峰值扩展你的集群。这意味着你可以在不承担不断产生更大规模拓扑结构成本和管理负担的情况下，为典型的一天调整你的正常拓扑结构。

在峰值特性的另一端，有一些应用程序的流量在每天中都有显著的峰值和低谷。例如，考虑食品配送业务，它们在午餐时间突然增加，然后是几小时的最低流量，然后在晚餐时间再次出现峰值（有时第二天早上早餐时也是如此）。即使有“自动扩展”（本章后面将详细介绍自动扩展），为每个峰值扩展集群也不太可能快速提供必要的性能提升。在这些情况下，你应该提供支持峰值流量的基础设施。

但并非所有峰值都是可预测的。某些行业——如紧急服务、新闻和社交媒体——容易受到突然的大规模峰值的影响。在这种情况下，一个良好的预防策略是在客户端控制并发，以免数据库过载。然而，对于具有严格端到端延迟要求的用例，控制并发可能不是一个选择。当峰值发生时，你也可以尽可能快地扩展你的集群。如果你在云上，这将会比在本地要简单得多。如果你可以立即添加节点，可以逐步增加容量——密切关注监控结果——并继续进行，直到你对结果满意，或者直到峰值下降。不幸的是，你可能会在峰值结束之前无法充分扩展。即使提升开始得立即，你也必须考虑到将数据传输到新节点、向它们流数据以及重新平衡集群所需的时间。

如果你正在选择一个新的数据库，并预计会有频繁且剧烈的峰值，请务必在实际条件下严格测试你的主要候选者如何响应。此外，还应考虑在整个峰值期间维持可接受性能的成本。

注意

“自动扩展”这个词暗示了您的数据库集群会根据接收到的流量自动扩展。并非如此。它只是一个机器人，根据您预定的目标表设置启用/禁用预配置的容量。即使您不使用这个容量，您可能也在为预留和准备就绪的便利性付费。此外，重要的是要认识到，这并不是瞬时的。从 0 rps 到 40k 需要 2.5 小时以上.^(13) 这对于意外或极端峰值来说并不理想。

自动扩展的最佳时机：

+   负载变化具有高振幅

+   变化率在小时量级

+   相对于基线，负载峰值较窄^(14)

## ACID 事务

您的使用案例是否需要您处理具有 ACID（原子性、一致性、隔离性和持久性）属性的逻辑工作单元？这些交易，历史上一直是关系数据库管理系统（RDBMS）的领域，会带来严重的性能影响。

确实，存在符合 ACID 规范的分布式数据库，并且过去几年在最小化性能影响方面取得了一些显著进展（例如，通过行级锁定或列级锁定以及更好的冲突解决算法）。然而，仍然会存在一定程度的惩罚。

作为一般指导原则，如果您有一个符合 ACID 规范的使用案例，请特别注意您的主节点；这些节点很容易成为瓶颈，因为它们通常将是您的首要查询协调器（更多内容请见附录 A）。此外，如果可能的话，尽量确保大多数交易都隔离在最小的资源量上。例如，跨越单行的交易可能涉及一组特定的副本，而涉及多个键的交易可能跨越整个集群——不可避免地增加您的延迟。因此，了解您的目标数据库支持哪些类型的交易非常重要。一些供应商可能支持多种方法，而其他供应商可能在特定方法上表现出色。例如，MongoDB 在其 4.2 版本中在分片集群上引入了多文档事务；在此之前，它只支持副本集上的多文档事务。

如果支持事务的性能至关重要，有时重新思考你的数据模型并以适合非 ACID 兼容数据库的方式重新实现用例是可能的。例如，一个最初为所有用例使用 Postgres 的团队在面临业务快速增长时遇到了这种情况。这种情况对于从小规模开始，然后突然发现自己无法以经济有效的方式处理增长激增的初创公司来说非常常见。他们通过进行仔细的数据模型分析，重新思考他们的用例、访问模式和真正需要 ACID 以及不需要 ACID 的真实业务需求，将他们的用例迁移到了 NoSQL。这当然不是快速修复，但在正确的情况下，它可能会带来很好的回报。

另一个可以考虑的选项：以性能为导向的 NoSQL 数据库，如 Cassandra，旨在通过具有轻量级事务等功能的隔离条件更新来支持。也就是说，数据库检查条件是否为真，如果是，则执行事务。如果条件不满足，则事务不会完成。它们被称为“轻量级”，因为它们实际上不会锁定数据库以进行事务。相反，它们使用共识协议来确保节点之间就提交更改达成一致。这种功能是由 Cassandra 引入的，并且在不同的 Cassandra 兼容数据库中以多种方式得到支持。如果你期望使用这项功能，探索文档以了解差异是值得的。15

然而，需要注意的是，轻量级事务有其局限性。它们无法支持像零售交易这样的复杂用例，这种交易只在销售完成后并成功支付后才更新库存。而且就像 ACID 兼容的数据库一样，轻量级事务也有它们自己的性能影响。因此，是否使用它们的选择将很大程度上取决于你的用例所需的 ACID 兼容程度。

DynamoDB 是需求对事务的需要将需要更多计算资源（即金钱）的一个主要例子。因此，高度依赖 ACID 的用例通常需要更多的基础设施能力来满足重用要求。在 DynamoDB 文档中，AWS 建议你确保数据库已配置为自动扩展，或者它有足够的读写能力来处理事务的额外开销。16

## 一致性期望

大多数 NoSQL 数据库选择最终一致性以获得性能。这与 RDBMS 模型形成鲜明对比，在 RDBMS 模型中，ACID 合规性是通过事务实现的，并且由于所有内容都在单个节点上，锁定和避免并发冲突的努力通常被最小化。在决定使用强一致性或最终一致性的数据库时，你必须做出艰难的选择。你愿意牺牲可扩展性和性能，还是可以接受有时提供陈旧数据的风险？

你的用例能否容忍最终一致性，或者强一致性确实是必需的？你的选择实际上取决于你的应用程序——以及你的业务——在一致性方面可以承受多少风险。例如，一个（可以理解地）需要一致定价的零售商可能愿意在每周目录更新期间提前支付一致写入的成本，以便他们可以在更宽松的一致性级别下后来服务数百万的低延迟读取请求。在其他情况下，快速摄取数据可能更重要，并且可以在以后（例如，在流媒体平台中常见的回放跟踪用例中）支付一致性的代价。或者，两者可能同样重要。例如，考虑一个提供实时聊天的社交媒体平台。在这里，你希望在读写上保持一致性，但你可能不需要最高的一致性（不一致性的影响可能远小于财务报告）。

在某些情况下，“可调一致性”可以帮助你在强一致性和性能之间取得平衡。这让你能够在查询级别调整一致性，以适应你想要实现的目标。你可以有一些查询依赖于副本的多数，然后有其他查询更加宽松。

无论你的一致性要求如何，你都需要意识到选择特定一致性级别时涉及的潜在影响。如果你不知道自己在做什么，提供可调一致性的数据库可能既是祝福也是诅咒。考虑一个跨越三个不同地区的 NoSQL 部署，每个地区有三个节点（总共九个节点）。一个 QUORUM 读取实际上必须跨越两个不同的地区才能被客户端认可。从这个意义上说，如果你的网络往返时间（RTT）为 50ms，那么查询被数据库认为是成功的至少需要这么长时间。同样，如果你要运行最高可能的一致性操作（涉及所有副本），那么单个节点的故障可能会使你的整个应用程序崩溃。

注意

NoSQL 数据库通常会提供方法来限制你的查询到特定区域，以防止昂贵的网络往返影响你的延迟。但同样，这所有的一切都归结于你的用例需求。

## 地理分布

你的业务在不久的将来是否需要支持区域或全球客户群？你的用户和你的应用程序在哪里？用户、应用程序和数据库之间的距离越远，他们就越可能面临由于数据通过网络传输所需的时间而产生的较高延迟。了解这一点将影响你放置数据库的位置以及你设计拓扑结构的方式——更多内容请参阅第六章和第八章。

从灾难恢复的角度来看，你的集群的地理分布可能也是一个要求。在这种情况下，集群通常会从特定区域主要提供数据，但在发生灾难（如整个区域中断）的情况下会切换到另一个区域。这类设置成本很高，因为它们将需要加倍你的基础设施支出。然而，根据你的用例性质，有时这是必需的。

一些组织投资于多区域部署的主要目的是为了灾难恢复，但最终却用它们来托管孤立的使用案例。正如本章“竞争工作负载”部分所解释的，公司通常更喜欢将 OLTP（在线事务处理）工作负载与 OLAP（在线分析处理）工作负载在物理上隔离。将一些孤立（不那么关键）的工作负载迁移到远程区域，可以防止这些服务器大部分时间处于“闲置”状态。

无论是什么强烈的理由驱使你选择地理分散部署，以下是从性能角度出发的一些重要的高层次建议（你将在第八章中学习更多技术性的小贴士）：

1.  考虑在区域完全中断的情况下，你的目标区域或区域将承受的增加的负载。例如，假设你在全球范围内运营三个区域，这三个区域都服务于你的最终用户。剩下的两个区域能否长时间承受这种负载？

1.  认识到仅仅拥有地理分散的数据库并不能在灾难恢复情况下完全保护你。你还需要将你的应用程序、Web 服务器、消息队列系统等地理上复制。如果唯一地理复制的只是你的数据库，那么当你的主要应用程序出现问题时，你将处于不利的位置。

1.  考虑到地理复制数据库通常需要非常好的网络连接。特别是当跨越较大距离时，复制你的数据所需的时间对于在灾难发生时最小化损失至关重要。如果你的工作负载有很高的写入吞吐量，慢速的网络连接可能会成为本地区域节点的瓶颈。这可能会导致队列积压，并最终降低你的写入速度。

## 高可用性期望

不可避免地，总会发生一些意外。为了应对最坏的情况，首先了解如果某个节点发生故障，你的用例和业务可以承受什么。你能接受如果存储未复制数据的节点发生故障可能发生的数据丢失吗？你是否需要在数据中心或可用区完全中断的情况下，继续运行而不受明显性能影响？或者，如果偶尔慢一点是可以接受的吗？这些都将会影响你如何设计拓扑结构以及如何配置诸如复制因子和一致性级别（你将在第八章中了解更多）等问题。

需要注意的是，复制和一致性都会对性能造成成本。了解你业务的风险承受能力，不要选择超出你业务实际需要的。

在考虑集群拓扑时，记住如果你处理不当，风险很大（你也不想在大半夜被惊醒）。例如，一个三节点集群中单个节点的故障可能会让你暂时失去 33%的处理能力。这种情况通常会造成重大打击，对业务有可察觉的影响。同样，一个六节点集群中节点的丢失会将影响范围缩小到只有 16%。但总有权衡。跨越数百个节点的庞大部署也不是理想的选择。节点越多，发生节点故障的可能性就越大。平衡是关键。

## 摘要

你遇到的特定数据库挑战以及解决它们的选项，很大程度上取决于你的情况。例如，一个需要为大量数据集中的小项目提供个位数毫秒 P99 延迟的 AdTech 用例，与一个优先考虑尽可能快速摄取大量数据的欺诈检测用例相比，需要不同的处理方式。影响这些工作负载处理方式的一个主要因素是数据库的架构。这就是下一章的重点，我们将深入探讨数据库内部结构。

![Creative Commons](https://creativecommons.org/licenses/by/4.0)

**开放获取**本章根据 Creative Commons Attribution 4.0 International License（[`creativecommons.org/licenses/by/4.0/`](http://creativecommons.org/licenses/by/4.0/)）的条款进行许可，允许在任何媒介或格式中使用、分享、改编、分发和复制，只要您适当引用原始作者和来源，提供 Creative Commons 许可的链接，并指出是否进行了更改。

本章中包含的图片或其他第三方材料均包含在章节的 Creative Commons 许可证中，除非在材料引用行中另有说明。如果材料未包含在章节的 Creative Commons 许可证中，且您的使用意图不受法定法规允许或超出允许的使用范围，您将需要直接从版权持有人处获得许可。
