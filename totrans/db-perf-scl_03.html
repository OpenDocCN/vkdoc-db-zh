<html><head></head><body><div epub:type="chapter" role="doc-chapter"><div class="ChapterContextInformation"><div class="ContextInformation" id="b978-1-4842-9711-7_4"><div class="ChapterCopyright">© The Author(s) 2023</div><span class="ContextInformationAuthorEditorNames">F. C. Mendes et al.</span><span class="ContextInformationBookTitles"><span class="BookTitle">Database Performance at Scale</span></span><span class="ChapterDOI"><a href="https://doi.org/10.1007/978-1-4842-9711-7_4">https://doi.org/10.1007/978-1-4842-9711-7_4</a></span></div></div><!--Begin Abstract--><div class="MainTitleSection"><h1 class="ChapterTitle" lang="en">4. Database Internals: Algorithmic Optimizations</h1></div><div class="AuthorGroup"><div class="AuthorNames"><span class="Author"><span class="AuthorName">Felipe Cardeneti Mendes</span><sup><a href="#Aff5">1</a> <span class="ContactIcon"> </span></sup>, </span><span class="Author"><span class="AuthorName">Piotr Sarna</span><sup><a href="#Aff6">2</a></sup>, </span><span class="Author"><span class="AuthorName">Pavel Emelyanov</span><sup><a href="#Aff7">3</a></sup> and </span><span class="Author"><span class="AuthorName">Cynthia Dunlop</span><sup><a href="#Aff8">4</a></sup></span></div><div class="Affiliations"><div class="Affiliation" id="Aff5"><span class="AffiliationNumber">(1)</span><div class="AffiliationText">São Paulo, São Paulo, Brazil</div></div><div class="Affiliation" id="Aff6"><span class="AffiliationNumber">(2)</span><div class="AffiliationText">Pruszków, Poland</div></div><div class="Affiliation" id="Aff7"><span class="AffiliationNumber">(3)</span><div class="AffiliationText">Moscow, Russia</div></div><div class="Affiliation" id="Aff8"><span class="AffiliationNumber">(4)</span><div class="AffiliationText">Carpinteria, CA, USA</div></div><div class="ClearBoth"> </div></div></div><div class="ArticleOrChapterToc"><div class="TocLine"><a href="#Sec1">Optimizing Collections</a></div><div class="TocLine"><a href="#Sec2">To B- or Not to B-Tree</a></div><div class="TocLine"><a href="#Sec3">Linear Search on Steroids</a></div><div class="TocLine"><a href="#Sec4">Scanning the Tree</a></div><div class="TocLine"><a href="#Sec5">When the Tree Size Matters</a></div><div class="TocLine"><a href="#Sec6">The Secret Life of Separation Keys</a></div><div class="TocLine"><a href="#Sec7">Summary</a></div></div><!--End Abstract--><div class="Fulltext">
        <p class="Para" id="Par2">In the performance world, the hardware is always the unbreakable limiting factor—one cannot squeeze more performing units from a system than the underlying chips may provide. As opposed to that, the software part of the system is often considered the most flexible thing in programming—in the sense that it can be changed at any time given enough developers’ brains and hands (and investors’ cash).</p>
        <p class="Para" id="Par3">However, that’s not always the case. Sometimes selecting an algorithm should be done as early as the architecting stage in the most careful manner possible because the chosen approach becomes so extremely fundamental that changing it would effectively mean rewriting the whole engine from scratch or requiring users to migrate exabytes of data from one instance to another.</p>
        <p class="Para" id="Par4">This chapter shares one detailed example of algorithmic optimization—from the perspective of the engineer who led this optimization. Specifically, this chapter looks at how the B-trees family can be used to store data in <span id="ITerm1">cache implementations</span> and other accessory and in-memory structures. This look into a representative engineering challenge should help you better understand what tradeoffs or optimizations various databases might be making under the hood—ideally, so you can take better advantage of its very deliberate design decisions.<sup><a epub:type="noteref" href="#Fn1" id="Fn1_source" role="doc-noteref">1</a></sup></p>
        <div class="FormalPara FormalParaRenderingStyle1 ParaTypeImportant" id="FPar1">
          <div class="Heading">Note</div>
          <p class="Para FirstParaInFormalPara" id="Par6">The goal of this chapter is <em class="EmphasisTypeItalic ">not</em> to convince database users that they need a database with any particular algorithmic optimization—or to educate infrastructure engineers on designing B-trees or the finer points of algorithmic optimization. Rather, it’s to help anyone selecting or working with a database understand the level of algorithmic optimization that might impact a database’s performance. Hopefully, it piques your curiosity in learning more about the engineering behind the database you’re using and/or alternative databases you’re considering.</p>
        </div>
        <section class="Section1 RenderAsSection1" id="Sec1">
          <h2 class="Heading">Optimizing Collections</h2>
          <p class="Para" id="Par7">Maintaining large <span id="ITerm2">sets</span> of objects in memory deserves the same level of attention as maintaining objects in external memory—say, spinning disks or network-attached storages. For a task as simple as looking up an object by a plain key, the acceptable solution is often a plain hash table (even with great attention to hash function selection) or a binary balanced tree (usually the red-black one due to its implementation simplicity). However, branchy trees like the B-trees family can significantly boost performance. They also have a lot of non-obvious pitfalls.</p>
        </section>

        <section class="Section1 RenderAsSection1" id="Sec2">
          <h2 class="Heading">To B- or Not to B-Tree</h2>
          <p class="Para" id="Par8">An important characteristic of a tree is <em class="EmphasisTypeItalic ">cardinality</em>. This is the maximum number of child nodes that another node may have. In the corner case of cardinality of two, the tree is called a <em class="EmphasisTypeItalic ">binary</em> <span id="ITerm3">tree</span>. For other cases, there’s a wide class of so-called B-trees. The common belief about binary vs <span id="ITerm4">B-trees</span> is that the former ones should be used when the data is stored in the RAM, while the latter trees should live in the disk. The justification for this split is that RAM access speed is much higher than disk. Also, disk I/O is performed in blocks, so it’s much better and faster to fetch several “adjacent” keys in one request. RAM, unlike disks, allows random access with almost any granularity, so it’s okay to have a dispersed set of keys pointing to each other.</p>
          <div class="Para" id="Par9">However, there are many reasons that B-trees are often a good choice for in-memory collections. The first reason is cache <em class="EmphasisTypeItalic ">locality</em>. When searching for a key in a binary tree, the algorithm would visit up to <em class="EmphasisTypeItalic ">logN</em> elements that are very likely dispersed in memory. On a B-tree, this search will consist of two <em class="EmphasisTypeItalic ">phases</em>—an intra-node search and descending the tree—executed one after another. And while descending the tree doesn’t differ much from the binary tree in the aforementioned sense, intra-node searching will access keys that are located next to each other, thus making much better use of CPU caches. Figure <span class="InternalRef"><a href="#Fig1">4-1</a></span> exemplifies the process of walking down a binary tree. Compare it along with Figure <span class="InternalRef"><a href="#Fig2">4-2</a></span>, which demonstrates a search in a B-tree <span id="ITerm5">set</span>.<figure class="Figure" id="Fig1"><div class="MediaObject" id="MO1">
              <img alt="" aria-describedby="d65e534" src="../images/541783_1_En_4_Chapter/541783_1_En_4_Fig1_HTML.jpg" style="width:35.45em"/><div class="TextObject" id="d65e534">
                <p class="Para" id="Par31">A block diagram, 1. A block named 15, If less than 16, go to the right subtree, else go to left subtree, block 10 divides into blocks 8 and 12, 2. A block named 20, if more than 16, go to the left subtree, else go to right subtree, block 25 leads to block 30, 3. The left subtree, Block 18 divides into 16 and 19.</p>
              </div>
              
            </div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Figure 4-1</span>
                <p class="SimplePara">Searching in a binary tree root</p>
              </div></figcaption></figure><figure class="Figure" id="Fig2"><div class="MediaObject" id="MO2">
              <img alt="" aria-describedby="d65e557" src="../images/541783_1_En_4_Chapter/541783_1_En_4_Fig2_HTML.jpg" style="width:42.82em"/><div class="TextObject" id="d65e557">
                <p class="Para" id="Par32">An illustration demonstrates the search in a B-tree set for M equals 6. C P U cores split the processing of each instruction into stages.</p>
              </div>
              
            </div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Figure 4-2</span>
                <p class="SimplePara">Searching in a B-tree set</p>
              </div></figcaption></figure></div>
          <p class="Para" id="Par10">The second reason that <span id="ITerm6">B-trees</span> are often a good choice for in-memory collections also comes from the dispersed nature of binary trees and from how modern CPUs are designed. It’s well known that when executing a stream of instructions, CPU cores split the processing of each instruction into stages (loading instructions, decoding them, preparing arguments, and doing the execution itself) and the stages are run in parallel in a unit called a <span id="ITerm7"><em class="EmphasisTypeItalic ">conveyor</em></span>. When a conditional branching instruction appears in this stream, the conveyor needs to guess which of two potential branches it will have to execute next and start loading it into the conveyor pipeline. If this guess fails, the conveyor is flushed and starts to work from scratch. Such failures are called <span id="ITerm8"><em class="EmphasisTypeItalic ">branch mispredictions</em></span><em class="EmphasisTypeItalic ">.</em> They are harmful from a performance point of view<sup><a epub:type="noteref" href="#Fn2" id="Fn2_source" role="doc-noteref">2</a></sup> and have direct implications on the binary search algorithm. When searching for a key in such a tree, the algorithm jumps left and right depending on the key comparison result without giving the CPU a chance to learn which direction is “preferred.” In many cases, the CPU conveyer is flushed.</p>
          <p class="Para" id="Par12">The two-phased B-tree search can be made better with respect to branch predictions. The trick is in making the intra-node search linear (i.e., walking the array of keys forward key-by-key). In this case, there will be only a “should you move forward” condition that’s much more predictable. There’s even a nice trick of turning binary search into linear without sacrificing the number of comparisons,<sup><a epub:type="noteref" href="#Fn3" id="Fn3_source" role="doc-noteref">3</a></sup> but this approach is good for read-mostly collections because insertion into this layout is tricky and has worse complexity than for sorted arrays. This approach has proven itself in ScyllaDB’s implementation and is also widely used in the Tarantool in-memory database.<sup><a epub:type="noteref" href="#Fn4" id="Fn4_source" role="doc-noteref">4</a></sup></p>
        </section>

        <section class="Section1 RenderAsSection1" id="Sec3">
          <h2 class="Heading">Linear Search on Steroids</h2>
          <p class="Para" id="Par15">That linear <span id="ITerm9">search</span> can be improved a bit more. Let’s carefully count the number of key comparisons that it may take to find a single key in a tree. For a binary tree, it’s well known that it takes <em class="EmphasisTypeItalic ">log</em><sub><em class="EmphasisTypeItalic ">2</em></sub><em class="EmphasisTypeItalic ">N</em> comparisons (on average) where <em class="EmphasisTypeItalic ">N</em> is the number of elements. We put the logarithm base here for a reason. Next, consider a <em class="EmphasisTypeItalic ">k</em>-ary tree with <em class="EmphasisTypeItalic ">k</em> children per node. Does it take fewer comparisons? (Spoiler: no). To find the element, you have to do the same search—get a node, find in which branch it sits, then proceed to it. You have <em class="EmphasisTypeItalic ">log</em><sub><em class="EmphasisTypeItalic ">k</em></sub><em class="EmphasisTypeItalic ">N</em> levels in the tree, so you have to do that many descending steps. However on each step, you need to do the search within <em class="EmphasisTypeItalic ">k</em> elements, which is, again, <em class="EmphasisTypeItalic ">log</em><sub><em class="EmphasisTypeItalic ">2</em></sub><em class="EmphasisTypeItalic ">k</em> if you’re doing a binary search. Multiplying both, you still need at least <em class="EmphasisTypeItalic ">log</em><sub><em class="EmphasisTypeItalic ">2</em></sub><em class="EmphasisTypeItalic ">N</em> comparisons.</p>
          <div class="Para" id="Par16">The way to reduce this number is to compare more than one key at a time when doing intra-node searches. In case the keys are small enough, SIMD instructions can compare up to 64 keys in one go. Although a SIMD compare instruction may be slower than a classic cmp one and requires additional instructions to process the comparison mask, linear SIMD-powered search wins on short enough arrays (and B-tree nodes can be short enough). For example, Figure <span class="InternalRef"><a href="#Fig3">4-3</a></span> shows the times of looking up an integer in a sorted array using three techniques—linear search, binary search, and <span id="ITerm10">SIMD-optimized linear search</span> such as the x86 <span id="ITerm11">Advanced Vector Extensions (AVX)</span>.<figure class="Figure" id="Fig3"><div class="MediaObject" id="MO3">
              <img alt="" aria-describedby="d65e735" src="../images/541783_1_En_4_Chapter/541783_1_En_4_Fig3_HTML.jpg" style="width:35.38em"/><div class="TextObject" id="d65e735">
                <p class="Para" id="Par33">A horizontal grouped bar chart that plots the time to find 4, 16 and 64 keys for linear, binary and A V X. For 4 keys, that values are 9, 10.5, and 3, for Linear, Binary and A V X, respectively. For 16 keys, that values are 5.5, 7, and 2.5, for Linear, Binary and A V X, respectively. For 64 keys, that values are 3.5, 3, and 2.5, for Linear, Binary and A V X, respectively.</p>
              </div>
              
            </div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Figure 4-3</span>
                <p class="SimplePara">The test used a large amount of randomly generated arrays of values dispersed in memory to eliminate differences in cache usage and a large amount of random search keys to blur branch predictions. These are the average times of finding a key in an array normalized by the array <span id="ITerm12">length</span>. Smaller results are faster (better)</p>
              </div></figcaption></figure></div>
        </section>

        <section class="Section1 RenderAsSection1" id="Sec4">
          <h2 class="Heading">Scanning the Tree</h2>
          <p class="Para" id="Par17">One interesting flavor of B-trees is called a <span id="ITerm13">B+-tree</span><span id="ITerm14"/>. In this tree, there are two kinds of keys—<em class="EmphasisTypeItalic ">real</em> keys and <em class="EmphasisTypeItalic ">separation</em> keys. The real keys live on leaf nodes (i.e., on those that don’t have children), while separation keys sit on inner nodes and are used to select which branch to go next when descending the tree. This difference has an obvious consequence that it takes more memory to keep the same amount of keys in a B+-tree as compared to B-tree. But it’s not only that.</p>
          <div class="Para" id="Par18">A great implicit feature of a tree is the ability to iterate over elements in a sorted manner (called a <em class="EmphasisTypeItalic ">scan</em>). To scan a classical B-tree, there are both recursive and state-machine algorithms that process the keys in a very non-uniform manner—the algorithm walks up-and-down the tree while it moves. Despite B-trees being described as cache-friendly, scanning them requires visiting every single node and inner nodes are visited in a cache unfriendly manner. Figure <span class="InternalRef"><a href="#Fig4">4-4</a></span> illustrates this phenomenon.<figure class="Figure" id="Fig4"><div class="MediaObject" id="MO4">
              <img alt="" aria-describedby="d65e794" src="../images/541783_1_En_4_Chapter/541783_1_En_4_Fig4_HTML.jpg" style="width:26.6em"/><div class="TextObject" id="d65e794">
                <p class="Para" id="Par34">A box with four divisions, with 11 in the first part, splits into two boxes, each with four divisions. The first box has 3 and 8 in the first two parts. The second box has 12, 13, 14 in the first three parts. The first box splits into three boxes, each with four divisions, again. The first has 0, 1, 2, the second has 4, 5, 6, 7, the third has 9, 10.</p>
              </div>
              
            </div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Figure 4-4</span>
                <p class="SimplePara">Scanning a classical B-tree involves walking up and down the tree; every node and inner <span id="ITerm15">node</span> is visited</p>
              </div></figcaption></figure></div>
          <div class="Para" id="Par19">As opposed to this, <span id="ITerm16">B+-trees</span>’ scan only needs to loop through its leaf nodes, which, with some additional effort, can be implemented as a linear scan over a linked list of arrays, as demonstrated in Figure <span class="InternalRef"><a href="#Fig5">4-5</a></span>.<figure class="Figure" id="Fig5"><div class="MediaObject" id="MO5">
              <img alt="" aria-describedby="d65e827" src="../images/541783_1_En_4_Chapter/541783_1_En_4_Fig5_HTML.jpg" style="width:26.55em"/><div class="TextObject" id="d65e827">
                <p class="Para" id="Par35">A box with four divisions, with 7 in the first part, splits into two boxes, each with four divisions. The first box has 4 in the first part. The second box has 11 in the first part. The first box splits into two boxes, each with four divisions, again, of which one has 0, 1, 2, 3, while the other has 4, 5, 6. The second box splits into two boxes, each with four divisions, again, of which one has 7, 8, 9, 10 while the other has 11, 12, 13, 14.</p>
              </div>
              
            </div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Figure 4-5</span>
                <p class="SimplePara">B+ tree scans only need to cover leaf nodes</p>
              </div></figcaption></figure></div>
        </section>

        <section class="Section1 RenderAsSection1" id="Sec5">
          <h2 class="Heading">When the Tree Size Matters</h2>
          <p class="Para" id="Par20">Talking about memory, B-trees don’t provide all these benefits for free (neither do <span id="ITerm17">B+-trees</span>). As the tree grows, so does the number of nodes in it and it’s useful to consider the overhead needed to store a single key. For a binary tree, the overhead is three pointers—to both left and right children as well as to the parent node. For a B-tree, it will differ for inner and leaf nodes. For both types, the overhead is one parent pointer and <em class="EmphasisTypeItalic ">k</em> pointers to <span id="ITerm18">keys</span>, even if they are not inserted in the tree. For inner nodes there will additionally be <em class="EmphasisTypeItalic ">k+1</em> pointers to child nodes.</p>
          <p class="Para" id="Par21">The number of nodes in a B-tree is easy to estimate for a large number of keys. As the number of nodes grows, the per-key overhead blurs as keys “share” parent and children pointers. However, there’s a very interesting point at the beginning of a tree’s growth. When the number of keys becomes <em class="EmphasisTypeItalic ">k+1</em> (i.e., the tree overgrows its first leaf node), the number of nodes jumps three times because, in this case, it’s needed to allocate one more leaf node and one inner node to link those two.</p>
          <div class="Para" id="Par22">There is a good and pretty cheap optimization to mitigate this spike, called “<span id="ITerm19">linear root</span>.” The leaf root node grows on demand, doubling each step like a <span class="EmphasisFontCategoryNonProportional ">std::vector</span> in C++, and can overgrow the capacity of <em class="EmphasisTypeItalic ">k</em> up to some extent. Figure <span class="InternalRef"><a href="#Fig6">4-6</a></span> shows the per-key overhead for a 4-ary B-tree with 50 percent initial overgrowth. Note the first split spike of a classical algorithm at five keys.<figure class="Figure" id="Fig6"><div class="MediaObject" id="MO6">
              <img alt="" aria-describedby="d65e895" src="../images/541783_1_En_4_Chapter/541783_1_En_4_Fig6_HTML.jpg" style="width:35.43em"/><div class="TextObject" id="d65e895">
                <p class="Para" id="Par36">A graph between Per key overhead and number of keys in tree, for Binary, B tree and Linear root. The binary line is flat at y-axis value of 3. The B-tree line begins at (0, 5), drops to (4, 1.2), rises to (5, 4), and ends at (7, 2.8). The linear root line begins at (0, 2), rises to (7, 2.8), then drops to (25, 1.4). Values are estimated.</p>
              </div>
              
            </div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Figure 4-6</span>
                <p class="SimplePara">The per-key overhead for a 4-ary B-tree with 50 percent initial overgrowth</p>
              </div></figcaption></figure></div>
          <p class="Para" id="Par23">When discussing how B-trees work with small amounts of keys, it’s worth mentioning the corner case of one key. In ScyllaDB, a B-tree is used to store sorted rows inside a block of rows called a <span id="ITerm20">partition</span>. Since it’s possible to have a schema where each partition always has a single row, this corner case is not that “corner” for us. In the case of a binary tree, the single-element tree is equivalent to having a direct pointer from the tree owner to this element (plus the cost of two nil pointers to the left and right children). In case of a B-tree, the cost of keeping the single key is always in having a root node that implies extra pointer fetching to access this key. Even the linear root optimization is helpless here. Fixing this corner case was possible by reusing the pointer to the root node to point directly to the single key.</p>
        </section>

        <section class="Section1 RenderAsSection1" id="Sec6">
          <h2 class="Heading">The Secret Life of Separation Keys</h2>
          <p class="Para" id="Par24">This section dives into technical details of <span id="ITerm21">B+-tree</span> implementation.</p>
          <p class="Para" id="Par25">There are two ways of managing separation keys in a B+-tree. The <span id="ITerm22">separation key</span> at any level must be less than or equal to <em class="EmphasisTypeItalic ">all</em> the keys from its right subtree and greater than or equal to all the keys from its left subtree. Mind the “or” condition—the exact value of the separation key <em class="EmphasisTypeItalic ">may</em> <em><strong class="EmphasisTypeBoldItalic ">or</strong></em> <em class="EmphasisTypeItalic ">may not</em> coincide with the value of some key from the respective branch (it’s clear that this <em class="EmphasisTypeItalic ">some</em> will be the rightmost key on the left branch or leftmost on the right). Let’s look at these two cases. If the tree balancing maintains the separation key to be independent from other key values, then it’s the <em class="EmphasisTypeItalic ">light</em> mode; if it must coincide with some of them, then it will be called the <em class="EmphasisTypeItalic ">strict</em> mode.</p>
          <p class="Para" id="Par26">In the light separation mode, the insertion and removal operations are a bit faster because they don’t need to care about <span id="ITerm23">separation keys</span> that much. It’s enough if they separate branches, and that’s it. A somewhat worse consequence of the light separation is that separation keys are separate values that may appear in the tree by copying existing keys. If the key is simple, (e.g., an integer), this will likely not cause any trouble. However, if keys are strings or, as in ScyllaDB’s case, database partition or clustering keys, copying it might be both resource consuming and out-of-memory risky.</p>
          <p class="Para" id="Par27">On the other hand, the strict separation mode makes it possible to avoid key copying by implementing separation keys as references on real ones. This would involve some complication of insertion and especially removal operations. In particular, upon real key removal, it will be necessary to find and update the relevant separation keys. Another difficulty to care about is that moving a real key value in memory, if it’s needed (e.g., in ScyllaDB’s case <span id="ITerm24">keys</span> are moved in memory as a part of memory defragmentation hygiene), will also need to update the relevant reference from separation keys. However, it’s possible to show that each real key will be referenced by at most one separation key.</p>
          <div class="Para" id="Par28">Speaking about memory consumption, although large B-trees were shown to consume less memory per-key as they get filled, the real overhead would very likely be larger, since the nodes of the tree will typically be underfilled because of the way the balancing algorithm works. For example, Figures <span class="InternalRef"><a href="#Fig7">4-7</a></span> and <span class="InternalRef"><a href="#Fig8">4-8</a></span> show how nodes look in a randomly filled 4-ary B-tree.<figure class="Figure" id="Fig7"><div class="MediaObject" id="MO7">
              <img alt="" aria-describedby="d65e994" src="../images/541783_1_En_4_Chapter/541783_1_En_4_Fig7_HTML.jpg" style="width:35.4em"/><div class="TextObject" id="d65e994">
                <p class="Para" id="Par37">A Pie chart of the distribution of number of keys in a node for leaf nodes, in percentage. 1. 2 keys, 18.4, 2. 3 keys, 31.6, and 3. 4 keys, 50.</p>
              </div>
              
            </div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Figure 4-7</span>
                <p class="SimplePara">Distribution of number of keys in a node for leaf nodes</p>
              </div></figcaption></figure><figure class="Figure" id="Fig8"><div class="MediaObject" id="MO8">
              <img alt="" aria-describedby="d65e1022" src="../images/541783_1_En_4_Chapter/541783_1_En_4_Fig8_HTML.jpg" style="width:33.02em"/><div class="TextObject" id="d65e1022">
                <p class="Para" id="Par38">A Pie chart of the distribution of number of keys in a node for leaf nodes, in percentage. 1. 2 keys, 34.3, 2. 3 keys, 25.3, and 3. 4 keys, 40.4.</p>
              </div>
              
            </div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Figure 4-8</span>
                <p class="SimplePara">Distribution of number of keys in a node for inner <span id="ITerm25">nodes</span></p>
              </div></figcaption></figure></div>
          <p class="Para" id="Par29">It’s possible to define a compaction operation for a B-tree that will pick several adjacent nodes and squash them together, but this operation has its limitations. First, a certain amount of underoccupied nodes makes it possible to insert a new element into a tree without the need to rebalance, thus saving CPU cycles. Second, since each node cannot contain less than a half of its capacity, squashing two adjacent nodes is impossible. Even if considering three adjacent nodes, then the amount of really squashable nodes would be less than 5 percent of the leaves and less than 1 percent of the inners.</p>
        </section>

        <section class="Section1 RenderAsSection1" id="Sec7">
          <h2 class="Heading">Summary</h2>
          <p class="Para" id="Par30">As extensive as these optimizations might seem, they are really just the tip of the iceberg for this one particular example. Many finer points that matter from an engineering perspective were skipped for brevity (for example, the subtle difference in odd vs even number of keys on a node). For a database user, the key takeaway here is that an excruciating level of design and experimentation often goes into the software for determining how your database stores and retrieves data. You certainly don’t need to be this familiar with every aspect of how your database was engineered. But knowing what algorithmic optimizations your <span id="ITerm26">database</span> has focused on will help you understand why it performs in certain ways under different contexts. And you might discover some impressively engineered capabilities that could help you handle more user requests or shave a few precious milliseconds off your P99 latencies. The next chapter takes you into the inner workings of database drivers and shares tips for getting the most out of a driver, particularly from a performance perspective.</p>
        </section>

      <div class="License LicenseSubType-cc-by"><a href="https://creativecommons.org/licenses/by/4.0"><img alt="Creative Commons" src="../css/cc-by.png"/></a>
            <p class="SimplePara"><strong class="EmphasisTypeBold ">Open Access</strong> This chapter is licensed under the terms of the Creative Commons Attribution 4.0 International License (<span class="ExternalRef"><a href="http://creativecommons.org/licenses/by/4.0/"><span class="RefSource">http://​creativecommons.​org/​licenses/​by/​4.​0/​</span></a></span>), which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license and indicate if changes were made.</p>
            <p class="SimplePara">The images or other third party material in this chapter are included in the chapter's Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the chapter's Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder.</p>
          </div><aside aria-label="Footnotes" class="FootnoteSection" epub:type="footnotes"><div class="Heading">Footnotes</div><div class="Footnote"><span class="FootnoteNumber"><a href="#Fn1_source">1</a></span><div class="FootnoteContent" epub:type="footnote" id="Fn1" role="doc-footnote"><p class="Para" id="Par5">This chapter draws from material originally published on the ScyllaDB blog (<span class="ExternalRef"><a href="http://www.scylladb.com/blog"><span class="RefSource"><span class="EmphasisFontCategoryNonProportional ">www.scylladb.com/blog</span></span></a></span>). It is used here with permission of ScyllaDB.</p></div><div class="ClearBoth"> </div></div><div class="Footnote"><span class="FootnoteNumber"><a href="#Fn2_source">2</a></span><div class="FootnoteContent" epub:type="footnote" id="Fn2" role="doc-footnote"><p class="Para" id="Par11">See Marek Majkowski’s blog, “Branch predictor: How many ‘if’s are too many? Including x86 and M1 benchmarks!” <span class="ExternalRef"><a href="https://blog.cloudflare.com/branch-predictor/"><span class="RefSource"><span class="EmphasisFontCategoryNonProportional ">https://blog.cloudflare.com/branch-predictor/</span></span></a></span>.</p></div><div class="ClearBoth"> </div></div><div class="Footnote"><span class="FootnoteNumber"><a href="#Fn3_source">3</a></span><div class="FootnoteContent" epub:type="footnote" id="Fn3" role="doc-footnote"><p class="Para" id="Par13">See the tutorial, “Eytzinger Binary Search” <span class="ExternalRef"><a href="https://algorithmica.org/en/eytzinger"><span class="RefSource"><span class="EmphasisFontCategoryNonProportional ">https://algorithmica.org/en/eytzinger</span></span></a></span>.</p></div><div class="ClearBoth"> </div></div><div class="Footnote"><span class="FootnoteNumber"><a href="#Fn4_source">4</a></span><div class="FootnoteContent" epub:type="footnote" id="Fn4" role="doc-footnote"><p class="Para" id="Par14">Both are available as open-source software; see <span class="ExternalRef"><a href="https://github.com/scylladb/scylladb"><span class="RefSource"><span class="EmphasisFontCategoryNonProportional ">https://github.com/scylladb/scylladb</span></span></a></span> and <span class="ExternalRef"><a href="https://github.com/tarantool/tarantool"><span class="RefSource"><span class="EmphasisFontCategoryNonProportional ">https://github.com/tarantool/tarantool</span></span></a></span>.</p></div><div class="ClearBoth"> </div></div></aside></div></div></body></html>