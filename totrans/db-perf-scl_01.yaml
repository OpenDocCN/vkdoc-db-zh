- en: 2. Your Project, Through the Lens of Database Performance
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2. 通过数据库性能视角看您的项目
- en: '[Workload Mix (Read/Write Ratio)](#Sec1)[Item Size](#Sec7)[Item Type](#Sec8)[Dataset
    Size](#Sec9)[Throughput Expectations](#Sec10)[Latency Expectations](#Sec11)[Concurrency](#Sec12)[Connected
    Technologies](#Sec13)[Demand Fluctuations](#Sec14)[ACID Transactions](#Sec15)[Consistency
    Expectations](#Sec16)[Geographic Distribution](#Sec17)[High-Availability Expectations](#Sec18)[Summary](#Sec19)'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '[工作负载混合（读写比例）](#Sec1)[项目大小](#Sec7)[项目类型](#Sec8)[数据集大小](#Sec9)[吞吐量预期](#Sec10)[延迟预期](#Sec11)[并发性](#Sec12)[连接技术](#Sec13)[需求波动](#Sec14)[ACID事务](#Sec15)[一致性预期](#Sec16)[地理分布](#Sec17)[高可用性预期](#Sec18)[总结](#Sec19)'
- en: The specific database performance constraints and optimization opportunities
    your team will face vary wildly based on your specific workload, application,
    and business expectations. This chapter is designed to get you and your team talking
    about how much you can feasibly optimize your performance, spotlight some specific
    lessons related to common situations, and also help you set realistic expectations
    if you’re saddled with burdens like large payload sizes and strict consistency
    requirements. The chapter starts by looking at technical factors, such as the
    read/write ratio of your workload, item size/type, and so on. Then, it shifts
    over to business considerations like consistency requirements and high availability
    expectations. Throughout, the chapter talks about database attributes that have
    proven to be helpful—or limiting—in different contexts.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 您的团队将面临的具体数据库性能约束和优化机会，将根据您的具体负载、应用程序和业务预期而大幅变化。本章旨在让您和您的团队讨论您能实际优化性能的程度，突出一些与常见情况相关的具体教训，并帮助您设定现实的目标，如果您面临如大量负载大小和严格一致性要求等负担。本章首先从技术因素开始，例如您的工作负载的读写比例、项目大小/类型等。然后，它转向业务考虑因素，如一致性要求和高可用性预期。在整个过程中，本章讨论了在不同环境中已被证明是有益或有限的数据库属性。
- en: Note
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Since this chapter covers a broad range of scenarios, not everything will be
    applicable to your specific project and workload. Feel free to skim this chapter
    and focus on the sections that seem most relevant.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 由于本章涵盖了广泛的应用场景，并非所有内容都适用于您的特定项目和负载。请随意浏览本章，并关注似乎最相关的部分。
- en: Workload Mix (Read/Write Ratio)
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作负载混合（读写比例）
- en: Whether it’s read-heavy, write-heavy, evenly-mixed, delete-heavy, and so on,
    understanding and accommodating your read/write ratio is a critical but commonly
    overlooked aspect of database performance. Some databases shine with read-heavy
    workloads, others are optimized for write-heavy situations, and some are built
    to accommodate both. Selecting, or sticking with, one that’s a poor fit for your
    current and future situation will be a significant burden that will be difficult
    to overcome, no matter how strategically you optimize everything else.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 不论是读密集型、写密集型、均衡混合型、删除密集型等，理解和适应您的读写比例是数据库性能的关键但常被忽视的方面。一些数据库在处理读密集型负载时表现出色，其他数据库则针对写密集型情况进行了优化，还有一些数据库旨在同时适应这两种情况。选择或坚持使用与您当前和未来情况不匹配的数据库，将是一个重大的负担，无论您如何策略性地优化其他所有方面，都将难以克服。
- en: There’s also a significant impact to cost. That might not seem directly related
    to performance, but if you can’t afford (or get approval for) the infrastructure
    that you truly need to support your workload, this will clearly limit your performance.^([1](#Fn1))
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 成本也会产生重大影响。这可能看起来与性能没有直接关系，但如果您负担不起（或无法获得批准）支持您工作负载所需的基础设施，这将明显限制您的性能。[1](#Fn1)
- en: Tip
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 小贴士
- en: Not sure what your workload looks like? This is one of many situations where
    observability is your friend. If your existing database doesn’t help you profile
    your workload, consider if it’s feasible to try your workloads on a compatible
    database that enables deeper visibility.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 不确定您的工作负载是什么样的？这是许多情况下可观察性成为您朋友的一个例子。如果您的现有数据库无法帮助您分析工作负载，考虑是否可以在兼容的数据库上尝试您的负载，该数据库能够提供更深入的可见性。
- en: Write-Heavy Workloads
  id: totrans-10
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 写密集型工作负载
- en: 'If you have a write-heavy workload, we strongly recommend a database that stores
    data in immutable files (e.g., Cassandra, ScyllaDB, and others that use LSM trees).^([2](#Fn2))
    These databases optimize write speed because: 1) writes are sequential, which
    is faster in terms of disk I/O and 2) writes are performed immediately, without
    first worrying about reading or updating existing values (like databases that
    rely on B-trees do). As a result, you can typically write a lot of data with very
    low latencies.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有一个以写操作为主的负载，我们强烈推荐使用存储在不可变文件中的数据库（例如，Cassandra、ScyllaDB以及其他使用LSM树的数据库）。^([2](#Fn2))
    这些数据库通过以下方式优化写速度：1) 写操作是顺序的，这在磁盘I/O方面更快；2) 写操作立即执行，无需首先担心读取或更新现有值（如依赖于B树的数据库）。因此，你可以通常以非常低的延迟写入大量数据。
- en: However, if you opt for a write-optimized database, be prepared for higher storage
    requirements and the potential for slower reads. When you work with immutable
    files, you’ll need sufficient storage to keep all the immutable files that build
    up until compaction runs.^([3](#Fn3)) You can mitigate the storage needs to some
    extent by choosing compaction strategies carefully. Plus, storage is relatively
    inexpensive these days.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果你选择写入优化的数据库，请做好更高的存储需求和潜在较慢读取的准备。当你与不可变文件一起工作时，你需要足够的存储空间来保存所有积累到压缩运行之前的不可变文件。^([3](#Fn3))
    通过仔细选择压缩策略，你可以在一定程度上减轻存储需求。此外，存储目前相对便宜。
- en: The potential for read amplification is generally a more significant concern
    with write-optimized databases (given all the files to search through, more disk
    reads are required per read request).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 读取放大潜力通常在写入优化的数据库中是一个更重大的担忧（考虑到需要搜索的所有文件，每个读取请求需要更多的磁盘读取）。
- en: But read performance doesn’t necessarily need to suffer. You can often minimize
    this tradeoff with a write-optimized database that implements its own caching
    subsystem (as opposed to those that rely on the operating system’s built-in cache),
    enabling fast reads to coexist alongside extremely fast writes. Bypassing the
    underlying OS with a performance-focused built-in cache should speed up your reads
    nicely, to the point where the latencies are nearly comparable to read-optimized
    databases.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 但读取性能不一定会受到影响。你通常可以通过实现自己的缓存子系统（而不是依赖于操作系统的内置缓存）的写入优化的数据库来最小化这种权衡，使快速读取与极快的写入共存。通过绕过底层操作系统并使用以性能为重点的内置缓存，应该可以很好地加快你的读取速度，使延迟几乎与读取优化的数据库相当。
- en: With a write-heavy workload, it’s also essential to have extremely fast storage,
    such as NVMe drives, if your peak throughput is high. Having a database that can
    *theoretically* store values rapidly ultimately won’t help if the disk itself
    can’t keep pace.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 对于以写操作为主的负载，如果你的峰值吞吐量很高，拥有极快的存储，如NVMe驱动器，也是至关重要的。如果磁盘本身无法跟上，理论上能够快速存储值的数据库最终也不会有帮助。
- en: 'Another consideration: beware that write-heavy workloads can result in surprisingly
    high costs as you scale. Writes cost around five times more than reads under some
    vendors’ pricing models. Before you invest too much effort in performance optimizations,
    and so on, it’s a good idea to price your solution at scale and make sure it’s
    a good long-term fit.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个考虑因素：请注意，以写操作为主的负载在扩展时可能会导致出人意料的成本增加。在某些供应商的定价模型下，写入的成本大约是读取的五倍。在你投入太多精力进行性能优化之前，最好对你的解决方案进行规模定价，并确保它是一个良好的长期解决方案。
- en: Read-Heavy Workloads
  id: totrans-17
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 读取密集型负载
- en: With read-heavy workloads, things change a bit. B-tree databases (such as DynamoDB)
    are optimized for reads (that’s the payoff for the extra time required to update
    values on the write path). However, the advantage that read-optimized databases
    offer for reads is generally not as significant as the advantage that write-optimized
    databases offer for writes, especially if the write-optimized database uses internal
    caching to make up the difference (as noted in the previous section).
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 对于以读操作为主的负载，情况略有不同。B树数据库（如DynamoDB）优化了读取操作（这是在写入路径上更新值所需额外时间的回报）。然而，对于读取优化的数据库在读取方面提供的优势通常不如写入优化的数据库在写入方面提供的优势显著，尤其是如果写入优化的数据库使用内部缓存来弥补差异（如前节所述）。
- en: 'Careful data modeling will pay off in spades for optimizing your reads. So
    will careful selection of read consistency (are eventually consistent reads acceptable
    as opposed to strongly consistent ones?), locating your database near your application,
    and performing a thorough analysis of your query access patterns. Thinking about
    your access patterns is especially crucial for success with a read-heavy workload.
    Consider aspects such as the following:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 仔细的数据建模将为优化你的读取带来巨大的回报。同样，仔细选择读取一致性（最终一致性读取是否可接受，而不是强一致性读取？），将数据库放置在应用程序附近，以及彻底分析你的查询访问模式，都将大有裨益。思考你的访问模式对于成功处理大量读取的工作负载尤为重要。考虑以下方面：
- en: What is the nature of the data that the application will be querying mostly
    frequently? Does it tolerate potentially stale reads or does it require immediate
    consistency?
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用程序将频繁查询的数据的性质是什么？它是否可以容忍可能过时的读取，还是需要立即一致性？
- en: How frequently is it accessed (e.g., is it frequently-accessed “hot” data that
    is likely cached, or is it rarely-accessed “cold” data)?
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它被访问的频率如何（例如，是频繁访问的“热”数据，可能被缓存，还是很少访问的“冷”数据）？
- en: Does it require aggregations, JOINs, and/or querying flexibility on fields that
    are not part of your primary key component?
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 是否需要聚合、JOIN操作和/或对非主键组件字段进行查询的灵活性？
- en: Speaking of primary keys, what is the level of cardinality?
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 说到主键，基数是多少？
- en: For example, assume that your use case requires dynamic querying capabilities
    (such as type-ahead use cases, report-building solutions, etc.) where you frequently
    need to query data from columns other than your primary/hash key component. In
    this case, you might find yourself performing full table scans all too frequently,
    or relying on too many indexes. Both of these, in one way or another, may eventually
    undermine your read performance.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设你的用例需要动态查询功能（例如自动补全用例、报告构建解决方案等），在这种情况下，你经常需要从除了你的主键/哈希键组件之外的列中查询数据。在这种情况下，你可能发现自己过于频繁地进行全表扫描，或者依赖于过多的索引。这两种情况，以某种方式，最终可能会损害你的读取性能。
- en: On the infrastructure side, selecting servers with high memory footprints is
    key for enabling low read latencies if you will mostly serve data that is frequently
    accessed. On the other hand, if your reads mostly hit cold data, you will want
    a nice balance between your storage speeds and memory. In fact, many distributed
    databases typically reserve some memory space specifically for caching indexes;
    this way, reads that inevitably require going to disk won’t waste I/O by scanning
    through irrelevant data.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在基础设施方面，选择具有高内存占用率的服务器对于在主要提供频繁访问的数据时实现低读取延迟至关重要。另一方面，如果你的读取主要针对冷数据，你将需要在存储速度和内存之间找到一个良好的平衡。实际上，许多分布式数据库通常为缓存索引预留一些内存空间；这样，不可避免地需要访问磁盘的读取就不会通过扫描无关数据而浪费I/O。
- en: 'What if the use case requires reading from both hot and cold data at the same
    time? And what if you have different latency requirements for each set of data?
    Or what if you want to mix a real-time workload on top of your analytics workload
    for the very same dataset? Situations like this are quite common. There’s no one-size-fits-all
    answer, but here are a few important tips:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 如果用例需要同时从热数据和冷数据中读取呢？如果你对每组数据有不同的延迟要求呢？或者如果你想在同一个数据集上混合实时工作负载和你的分析工作负载呢？这种情况相当常见。没有一刀切的方法，但以下是一些重要的提示：
- en: Some databases will allow you to read data without polluting your cache (e.g.,
    filling it up with data that is unlikely to be requested again). Using such a
    mechanism is especially important when you’re running large scans while simultaneously
    serving real-time data. If the large scans were allowed to override the previously
    cached entries that the real-time workload required, those reads would have to
    go through disk and get repopulated into the cache again. This would effectively
    waste precious processing time and result in elevated latencies.
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一些数据库允许你在不污染你的缓存的情况下读取数据（例如，用不太可能再次请求的数据填满它）。在同时运行大扫描并实时提供数据时，使用这种机制尤为重要。如果允许大扫描覆盖实时工作负载所需的先前缓存的条目，那么这些读取将不得不通过磁盘进行，并再次填充到缓存中。这实际上会浪费宝贵的处理时间，并导致延迟增加。
- en: For use cases requiring a distinction between hot/cold data storage (for cost
    savings, different latency requirements, or both), then solutions using *tiered
    storage* (a method of prioritizing data storage based on a range of requirements,
    such as performance and costs) are likely a good fit.
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于需要区分热/冷数据存储（为了节省成本、不同的延迟要求或两者兼而有之）的用例，使用*分层存储*（一种基于一系列要求，如性能和成本对数据存储进行优先级排序的方法）的解决方案可能是一个不错的选择。
- en: Some databases will permit you to prioritize some workloads over others. If
    that’s not sufficient, you can go one step further and completely isolate such
    workloads logically.^([4](#Fn4))
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一些数据库允许你优先处理某些工作负载。如果这还不够，你可以进一步采取一步，逻辑上完全隔离这些工作负载。[4](#Fn4)
- en: Note
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'You might not need all your reads. At ScyllaDB, we’ve come across a number
    of cases where teams are performing reads that they don’t really need. For example,
    by using a read-before-write approach to avoid race conditions where multiple
    clients are trying to update the same value with different updates at the same
    time. The details of the solution aren’t relevant here, but it is important to
    note that, by rethinking their approach, they were able to shave latencies off
    their writes as well as speed up the overall response by eliminating the unnecessary
    read. The moral here: Getting new eyes on your existing approaches might surface
    a way to unlock unexpected performance optimizations.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能不需要所有的读取操作。在ScyllaDB，我们遇到过许多案例，其中团队执行了他们实际上并不需要的读取操作。例如，通过使用先读后写的方法来避免多个客户端同时尝试用不同的更新更新相同值而产生的竞争条件。解决方案的细节在这里并不重要，但重要的是要注意，通过重新思考他们的方法，他们能够减少写入的延迟，并通过消除不必要的读取来加快整体响应速度。这里的教训是：用新的视角审视现有的方法可能会发现解锁意外性能优化的方法。
- en: Mixed Workloads
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 混合工作负载
- en: 'More evenly mixed access patterns are generally even more complex to analyze
    and accommodate. In general, the reason that mixed workloads are so complex in
    nature is due to the fact that there are two competing workloads from the database
    perspective. Databases are essentially made for just two things: reading and writing.
    The way that different databases handle a variety of competing workloads is what
    truly differentiates one solution from another. As you test and compare databases,
    experiment with different read/write ratios so you can adequately prepare yourself
    for scenarios when your access patterns may change.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 更均匀的混合访问模式通常更复杂，更难以分析和适应。一般来说，混合工作负载之所以复杂，是因为从数据库的角度来看，存在两个相互竞争的工作负载。数据库本质上是为读取和写入这两件事而设计的。不同数据库处理各种竞争工作负载的方式，真正区分了不同的解决方案。当你测试和比较数据库时，尝试不同的读写比例，以便你能够充分准备应对访问模式可能发生变化的情况。
- en: Be sure to consider nuances like whether your reads are from cold data (data
    not often accessed) or hot data (data that’s accessed often and likely cached).
    Analytics use cases tend to read cold data frequently because they need to process
    large amounts of data. In this case, disk speeds are very important for overall
    performance. Plus, you’ll want a comfortably large amount of memory so that the
    database’s cache can hold the data that you need to process. On the other hand,
    if you frequently access hot data, most of your data will be served from the cache,
    in such a way that the disk speeds become less important (although not negligible).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 一定要考虑细微差别，比如你的读取操作是来自冷数据（不常访问的数据）还是热数据（经常访问且可能已缓存的）。分析用例通常需要频繁读取冷数据，因为它们需要处理大量数据。在这种情况下，磁盘速度对于整体性能非常重要。此外，你还需要一个足够大的内存量，以便数据库的缓存可以存储你需要处理的数据。另一方面，如果你经常访问热数据，大部分数据将来自缓存，这样磁盘速度变得不那么重要（尽管不是可以忽略不计的）。
- en: Tip
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 小贴士
- en: Not sure if your reads are from cold or hot data? Take a look at the ratio of
    cache misses in your monitoring dashboards. For more on monitoring, see Chapter
    [10](541783_1_En_10_Chapter.xhtml).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 不确定你的读取操作是来自冷数据还是热数据？查看你的监控仪表板中缓存未命中的比率。有关监控的更多信息，请参阅第[10](541783_1_En_10_Chapter.xhtml)章。
- en: If your ratio of cache misses is higher than hits, this means that reads need
    to frequently hit the disks in order to look up your data. This may happen because
    your database is underprovisioned in memory space, or simply because the application
    access patterns often read infrequently accessed data. It is important to understand
    the performance implications here. If you’re frequently reading from cold data,
    there’s a risk that I/O will become the bottleneck—for writes as well as reads.
    In that case, if you need to improve performance, adding more nodes or switching
    your storage medium to a faster solution could be helpful.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的缓存未命中率高于命中率，这意味着读取需要频繁地访问磁盘以查找您的数据。这可能是因为您的数据库在内存空间上配置不足，或者简单地因为应用程序访问模式通常读取很少访问的数据。理解这里的性能影响很重要。如果您经常从冷数据中读取，存在I/O成为瓶颈的风险——对于写入和读取都一样。在这种情况下，如果您需要提高性能，增加更多节点或将您的存储介质切换到更快的解决方案可能会有所帮助。
- en: 'As noted earlier, write-optimized databases can improve read latency via internal
    caching, so it’s not uncommon for a team with, say, 60 percent reads and 40 percent
    writes to opt for a write-optimized database. Another option is to boost the latency
    of reads with a write-optimized database: If your database supports it, dedicate
    extra “shares” of resources to the reads so that your read workload is prioritized
    when there is resource contention.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，写入优化型数据库可以通过内部缓存提高读取延迟，因此对于有60%读取和40%写入的团队来说，选择写入优化型数据库并不罕见。另一个选择是使用写入优化型数据库提高读取延迟：如果您的数据库支持，为读取分配额外的“份额”资源，以便在资源竞争时优先处理读取工作负载。
- en: Delete-Heavy Workloads
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 删除密集型工作负载
- en: What about delete-heavy workloads, such as using your database as a durable
    queue (saving data from a producer until the consumer accesses it, deleting it,
    then starting the cycle over and over again)? Here, you generally want to avoid
    databases that store data in immutable files and use tombstones to mark rows and
    columns that are slated for deletion. The most notable examples are Cassandra
    and other Cassandra-compatible databases.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 对于像使用数据库作为持久队列（从生产者保存数据直到消费者访问它，删除它，然后重复此过程）这样的删除密集型工作负载怎么办？在这种情况下，您通常想要避免存储在不可变文件中并使用坟墓标记即将删除的行和列的数据库。最显著的例子是Cassandra和其他兼容Cassandra的数据库。
- en: Tombstones consume cache space and disk resources, and the database needs to
    search through all these tombstones to reach the live data. For many workloads,
    this is not a problem. But for delete-heavy workloads, generating an excessive
    amount of tombstones will, over time, significantly degrade your read latencies.
    There are ways and mechanisms to mitigate the impact of tombstones.^([5](#Fn5))
    However, in general, if you have a delete-heavy workload, it may be best to use
    a different database.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 坟碑消耗缓存空间和磁盘资源，数据库需要搜索所有这些坟墓才能到达活数据。对于许多工作负载来说，这并不是问题。但对于删除密集型工作负载，随着时间的推移，生成过多的坟墓将显著降低您的读取延迟。有方法和机制可以减轻坟墓的影响。[5](#Fn5)
    然而，总的来说，如果您有一个删除密集型工作负载，可能最好使用不同的数据库。
- en: It is important to note that occasional deletes are generally fine on Cassandra
    and Cassandra-compatible databases. Just be aware of the fact that deletes on
    append-only databases result in tombstone writes. As a result, these may incur
    read amplification, elevating your read latencies. Tombstones and data eviction
    in these types of databases are potentially long and complex subjects that perhaps
    could have their own dedicated chapter. However, the high-level recommendation
    is to exercise caution if you have a potentially delete-heavy pattern that you
    might later read from, and be sure to combine it with a compaction strategy tailored
    for efficient data eviction.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要注意，偶尔的删除在Cassandra和兼容Cassandra的数据库上通常是没问题的。只需注意，在只追加数据库上的删除会导致坟墓写入。因此，这可能会导致读取放大，提高您的读取延迟。这些类型数据库的坟墓和数据驱逐可能是长而复杂的话题，也许可以有自己的专门章节。然而，高级建议是，如果您有一个可能删除密集型模式，您可能稍后会读取，请务必谨慎行事，并确保将其与针对高效数据驱逐量身定制的压缩策略相结合。
- en: All that being said, it is interesting to note that some teams have successfully
    implemented delete-heavy workloads on top of Cassandra and Cassandra-like databases.
    The performance overhead carried by tombstones is generally circumvented by a
    combination of data modeling, a careful study of how deletes are performed, avoiding
    reads that potentially scan through a large set of deleted data, and careful tuning
    over the underlying table’s compaction strategy to ensure that tombstones get
    evicted in a timely manner. For example, Tencent Games used the Time Window Compaction
    Strategy to aggressively expire tombstones and use it as the foundation for a
    time series distributed queue.^([6](#Fn6))
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 话虽如此，值得注意的是，一些团队已经在 Cassandra 和类似 Cassandra 的数据库上成功实现了以删除为主的工作负载。由墓碑带来的性能开销通常通过数据建模、仔细研究删除操作的方式、避免读取可能扫描大量已删除数据的读取操作，以及仔细调整底层表的压缩策略来确保墓碑及时被清除来规避。例如，腾讯游戏使用了时间窗口压缩策略来积极过期墓碑，并将其作为时间序列分布式队列的基础。[6](#Fn6)
- en: Competing Workloads (Real-Time vs Batch)
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 竞争工作负载（实时 vs 批量）
- en: If you’re working with two different types of workloads—one more latency-sensitive
    than the other—the ideal solution is to have the database dedicate more resources
    to the more latency-sensitive workloads to keep them from faltering due to insufficient
    resources. This is commonly the case when you are attempting to balance OLTP (real-time)
    workloads, which are user-facing and require low latency responses, with OLAP
    (analytical) workloads, which can be run in batch mode and are more focused on
    throughput (see Figure [2-1](#Fig1)). Or, you can prioritize analytics. Both are
    technically feasible; it just boils down to what’s most important for your use
    case.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正在处理两种不同类型的工作负载——其中一种比另一种更敏感于延迟——理想的解决方案是让数据库为更敏感于延迟的工作负载分配更多资源，以防止它们因资源不足而失败。这通常在你试图平衡
    OLTP（实时）工作负载时发生，这些工作负载面向用户，需要低延迟响应，以及 OLAP（分析）工作负载，这些工作负载可以批量运行，更注重吞吐量（见图 [2-1](#Fig1)）。或者，你可以优先考虑分析。两者在技术上都是可行的；关键在于对你用例来说什么最重要。
- en: '![](../images/541783_1_En_2_Chapter/541783_1_En_2_Fig1_HTML.jpg)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../images/541783_1_En_2_Chapter/541783_1_En_2_Fig1_HTML.jpg)'
- en: A block diagram of O L T P and OLAP. A database cluster sends and receives data
    to and from an O L T P client and an O L A P client.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: O L T P 和 OLAP 的框图。数据库集群向 O L T P 客户端和 O L A P 客户端发送和接收数据。
- en: Figure 2-1
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2-1
- en: OLTP vs OLAP workloads
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: OLTP 与 OLAP 工作负载
- en: 'For example, assume you have a web server database with analytics. It must
    support two workloads:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设你有一个带有分析的 Web 服务器数据库。它必须支持两个工作负载：
- en: The main workload consists of queries triggered by a user clicking or navigating
    on some areas of the web page. Here, users expect high responsiveness, which usually
    translates to requirements for low latency. You need low timeouts with load shedding
    as your overload response, and you would like to have a lot of dedicated resources
    available whenever this workload needs them.
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 主要工作负载由用户点击或导航网页某些区域触发的查询组成。在这里，用户期望高响应性，这通常转化为对低延迟的要求。你需要低超时时间，并使用负载削减作为你的过载响应，你希望在任何需要此工作负载时都有大量可用资源。
- en: A second workload drives analytics being run periodically to collect some statistics
    or to aggregate some information that should be presented to users. This involves
    a series of computations. It’s a lot less sensitive to latency than the main workload;
    it’s more throughput oriented. You can have fairly large timeouts to accommodate
    for always full queues. You would like to throttle requests under load so the
    computation is stable and controllable. And finally, you would like the workload
    to have very few dedicated resources and use mostly unused resources to achieve
    better cluster utilization.
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二个工作负载驱动定期运行的分析，以收集一些应向用户展示的统计数据或汇总一些信息。这涉及一系列计算。它对延迟的敏感性远低于主要工作负载；它更注重吞吐量。你可以设置相当大的超时时间，以适应始终满载的队列。你希望在负载下调节请求，以便计算稳定且可控。最后，你希望工作负载拥有非常少的专用资源，并主要使用未使用的资源来实现更好的集群利用率。
- en: Running on the same cluster, such workloads would be competing for resources.
    As system utilization rises, the database must strictly prioritize which activities
    get what specific share of resources under contention. There are a few different
    ways you can handle this. Physical isolation, logical isolation, and scheduled
    isolation can all be acceptable choices under the right circumstances. Chapter
    [8](541783_1_En_8_Chapter.xhtml) covers these options.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在同一集群上运行，此类工作负载将竞争资源。随着系统利用率上升，数据库必须严格优先考虑哪些活动可以获得在争用中的哪些具体资源份额。有几种不同的方法可以处理这种情况。在适当的情况下，物理隔离、逻辑隔离和计划隔离都可以是可接受的选择。第[8](541783_1_En_8_Chapter.xhtml)章涵盖了这些选项。
- en: Item Size
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 项目大小
- en: The size of the items you are storing in the database (average payload size)
    will dictate whether your workload is CPU bound or storage bound. For example,
    running 100K OPS with an average payload size of 90KB is much different than achieving
    the same throughput with a 1KB payload. Higher payloads require more processing,
    I/O, and network traffic than smaller payloads.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 你在数据库中存储的项目大小（平均有效负载大小）将决定你的工作负载是CPU受限还是存储受限。例如，以90KB的平均有效负载运行100K OPS与以1KB有效负载实现相同的吞吐量有很大不同。较大的有效负载比较小的有效负载需要更多的处理、I/O和网络流量。
- en: Without getting too deep into database internals here, one notable impact is
    on the page cache. Assuming a default page cache size of 4KB, the database would
    have to serve several pages for the largest payload—that’s much more I/O to issue,
    process, merge, and serve back to the application clients. With the 1KB example,
    you could serve it from a single-page cache entry, which is less taxing from a
    compute resource perspective. Conversely, having a large number of smaller-sized
    items may introduce CPU overhead compared to having a smaller number of larger
    items because the database must process each arriving item individually.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 不深入探讨数据库内部结构，一个显著的影响是对页面缓存的影响。假设默认页面缓存大小为4KB，数据库将不得不为最大的有效负载提供几个页面——这需要更多的I/O来发布、处理、合并并返回给应用程序客户端。在1KB的例子中，你可以从单个页面缓存条目中提供它，这从计算资源的角度来看压力较小。相反，拥有大量的小尺寸项目可能比拥有较少的大尺寸项目引入更多的CPU开销，因为数据库必须单独处理每个到达的项目。
- en: In general, the larger the payload gets, the more cache activity you will have.
    Most write-optimized databases will store your writes in memory before persisting
    that information to the disk (in fact, that’s one of the reasons why they are
    write-optimized). Larger payloads deplete the available cache space more frequently,
    and this incurs a higher flushing activity to persist the information on disk
    in order to release space for more incoming writes. Therefore, more disk I/O is
    needed to persist that information. If you don’t size this properly, it can become
    a bottleneck throughout this repetitive process.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，有效负载越大，缓存活动就越多。大多数写入优化的数据库会在将信息持久化到磁盘之前将其写入内存（实际上，这也是它们写入优化的原因之一）。较大的有效负载更频繁地耗尽可用的缓存空间，这需要更高的刷新活动来将信息持久化到磁盘，以便为更多的传入写入释放空间。因此，需要更多的磁盘I/O来持久化这些信息。如果你没有正确地调整大小，它可能会在整个重复过程中成为瓶颈。
- en: 'When you’re working with extremely large payloads, it’s important to set realistic
    latency and throughput expectations. If you need to serve 200KB payloads, it’s
    unlikely that any database will enable you to achieve single-digit millisecond
    latencies. Even if the entire dataset is served from cache, there’s a physical
    barrier between your client and the database: networking. The network between
    them will eventually throttle your transfer speeds, even with an insanely fast
    client and database. Eventually, this will impact throughput as well as latency.
    As your latency increases, your client will eventually throttle down and you won’t
    be able to achieve the same throughput that you could with smaller payload sizes.
    The requests would be stalled, queuing in the network.^([7](#Fn7))'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 当你处理极大规模的有效负载时，设定现实的延迟和吞吐量预期非常重要。如果你需要服务200KB的有效负载，任何数据库都不太可能让你实现个位数的毫秒延迟。即使整个数据集都从缓存中提供，你的客户端和数据库之间也存在一个物理障碍：网络。它们之间的网络最终会限制你的传输速度，即使客户端和数据库都极快。最终，这会影响吞吐量和延迟。随着延迟的增加，你的客户端最终会降低速度，你将无法实现与较小有效负载大小相同的吞吐量。请求将停滞，在网络中排队。[7](#Fn7)
- en: 'Generally speaking, databases should not be used to store large blobs. We’ve
    seen people trying to store gigabytes of data within a single-key in a database—and
    this isn’t a great idea. If your item size is reaching this scale, consider alternative
    solutions. One solution is to use CDNs. Another is to store the largest chunk
    of your payload size in cold storage like Amazon S3 buckets, Google Cloud storage,
    or Azure blob storage. Then, use the database as a metadata lookup: It can read
    the data and fetch an identifier that will help find the data in that cold storage.
    For example, this is the strategy used by a game developer converting extremely
    large (often in the gigabyte range) content to popular gaming platforms. They
    store structured objects with blobs that are referenced by a content hash. The
    largest payload is stored within a cloud vendor Object Storage solution, whereas
    the content hash is stored in a distributed NoSQL database.^([8](#Fn8))'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 通常来说，数据库不应用于存储大型blob。我们见过有人试图在数据库中存储单个键内的数GB数据——这并不是一个好主意。如果您的项目大小达到这个规模，请考虑替代解决方案。一种解决方案是使用CDN。另一种解决方案是将您负载大小的最大块存储在冷存储中，如Amazon
    S3存储桶、Google Cloud存储或Azure blob存储。然后，将数据库用作元数据查找：它可以读取数据并获取一个标识符，这将有助于在冷存储中找到数据。例如，这是由一个游戏开发者采用的策略，将极大型（通常在GB范围内）内容转换为流行的游戏平台。他们存储带有blob的结构化对象，这些blob通过内容哈希进行引用。最大的负载存储在云供应商的对象存储解决方案中，而内容哈希存储在分布式NoSQL数据库中^([8](#Fn8))。
- en: Note that some databases impose hard limits on item size. For example, DynamoDB
    currently has a maximum item size of 400KB. This might not suit your needs. On
    top of that, if you’re using an in-memory solution such as Redis, larger keys
    will quickly deplete your memory. In this case, it might make sense to hash/compress
    such large objects prior to storing them.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，一些数据库对项目大小设置了硬性限制。例如，DynamoDB当前的最大项目大小为400KB。这可能不符合您的需求。此外，如果您使用的是如Redis这样的内存解决方案，较大的键会迅速耗尽您的内存。在这种情况下，在存储之前对这样的大型对象进行哈希/压缩可能是有意义的。
- en: No matter which database you choose, the smaller your payload, the greater your
    chances of introducing memory fragmentation. This might reduce your memory efficiency,
    which might in turn elevate costs because the database won’t be able to fully
    utilize its available memory.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 无论您选择哪种数据库，您的负载越小，引入内存碎片化的可能性就越大。这可能会降低您的内存效率，进而可能提高成本，因为数据库无法充分利用其可用内存。
- en: Item Type
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 项目类型
- en: The item type has a large impact on compression, which in turn impacts your
    storage utilization. If you’re frequently storing text, expect to take advantage
    of a high compression ratio. But, that’s not the case for random and uncommon
    blob sequences. Here, compression is unlikely to make a measurable reduction in
    your storage footprint. If you’re concerned about your use case’s storage utilization,
    using a compression-friendly item type can make a big difference.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 项目类型对压缩有重大影响，这反过来又影响您的存储利用率。如果您经常存储文本，可以期待利用高压缩比。但对于随机和不常见的blob序列来说，情况并非如此。在这里，压缩不太可能显著减少您的存储占用。如果您担心您的用例的存储利用率，使用对压缩友好的项目类型可以带来很大的差异。
- en: If your use case dictates a certain item type, consider databases that are optimized
    for that type. For example, if you need to frequently process JSON data that you
    can’t easily transform, a document database like MongoDB might be a better option
    than a Cassandra-compatible database. If you have JSON with some common fields
    and others that vary based on user input, it might be complicated—though possible—to
    model them in Cassandra. However, you’d incur a penalty from serialization/deserialization
    overhead required on the application side.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的用例指定了某种项目类型，请考虑针对该类型优化的数据库。例如，如果您需要频繁处理无法轻松转换的JSON数据，那么与Cassandra兼容的数据库相比，MongoDB这样的文档数据库可能是一个更好的选择。如果您有一些常见的字段和一些基于用户输入而变化的字段，那么在Cassandra中建模它们可能很复杂——尽管是可能的——您将在应用端承担序列化/反序列化开销的惩罚。
- en: As a general rule of thumb, choose the data type that’s the minimum needed to
    store the type of data you need. For example, you don’t need to store a year as
    a `bigint`. If you define a field as a `bigint`, most databases allocate relevant
    memory address spaces for holding it. If you can get by with a smaller type of
    `int`, do it—you’ll save bytes of memory, which could add up at scale. Even if
    the database you use doesn’t pre-allocate memory address spaces according to data
    types, choosing the correct one is still a nice way to have an organized data
    model—and also to avoid future questions around why a particular data type was
    chosen as opposed to another.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一般规则，选择存储所需数据类型所需的最小数据类型。例如，你不需要将年份存储为`bigint`。如果你将字段定义为`bigint`，大多数数据库都会为其分配相关的内存地址空间来存储它。如果你可以用较小的`int`类型来处理，那就这么做——你将节省内存字节，这在规模上可能会累积起来。即使你使用的数据库不会根据数据类型预先分配内存地址空间，选择正确的数据类型仍然是一种很好的方式来组织数据模型——并且还可以避免未来围绕为什么选择特定数据类型而不是另一个数据类型的问题。
- en: Many databases support additional item types which suit a variety of use cases.
    Collections, for example, allow you to store sets, lists, and maps (key-value
    pairs) under a single column in wide column databases. Such data types are often
    misused, and lead to severe performance problems. In fact, most of the data modeling
    problems we’ve come across involve misuse of collections. Collections are meant
    to store a small amount of information (such as phone numbers of an individual
    or different home/business addresses). However, collections with hundreds of thousands
    of entries are unfortunately not as rare as you might expect. They end up introducing
    a severe de-serialization overhead on the database. At best, this translates to
    higher latencies. At worst, this makes the data entirely unreadable due to the
    latency involved when scanning through the high number of items under such columns.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 许多数据库支持额外的项目类型，这些类型适用于各种用例。例如，集合允许你在宽列数据库的单个列下存储集合、列表和映射（键值对）。这些数据类型通常被误用，并导致严重的性能问题。实际上，我们遇到的大部分数据建模问题都涉及集合的误用。集合旨在存储少量信息（例如个人的电话号码或不同的家庭/商业地址）。然而，拥有数十万个条目的集合并不像你想象的那么罕见。它们最终会在数据库中引入严重的反序列化开销。最好的情况是，这会导致更高的延迟。最坏的情况是，由于扫描此类列下大量项目时涉及的延迟，数据变得完全不可读。
- en: 'Some databases also support user created fields, such as User-Defined Types
    (UDTs) in Cassandra. UDTs can be a great ally for reducing the de-serialization
    overhead when you combine several columns into one. Think about it: Would you
    rather de-serialize four Boolean columns individually or a single column with
    four Boolean values? UDTs will typically shine on deserializing several values
    as a single column, which may give you a nice performance boost.^([9](#Fn9)) Just
    like collections, however, UDTs should not be misused—and misusing UDTs can lead
    to the same severe impacts that are incurred by collections.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 一些数据库也支持用户自定义字段，例如Cassandra中的用户定义类型（UDTs）。当将多个列合并为一个时，UDTs可以成为减少反序列化开销的强大盟友。想想看：你是愿意单独反序列化四个布尔列，还是愿意反序列化一个包含四个布尔值的单列？UDTs通常在将多个值作为单个列反序列化时表现出色，这可能会给你带来性能提升。[9](#Fn9)
    就像集合一样，然而，UDTs也不应该被误用——误用UDTs可能会导致与集合相同的严重后果。
- en: Note
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: UDTs are quite extensively covered in Chapter [6](541783_1_En_6_Chapter.xhtml).
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: UDTs在第六章[6](541783_1_En_6_Chapter.xhtml)中得到了广泛的介绍。
- en: Dataset Size
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据集大小
- en: Knowing your dataset size is important for selecting appropriate infrastructure
    options. For example, AWS cloud instances have a broad array of NVMe storage offerings.
    Having a good grasp of how much storage you need can help you avoid selecting
    an instance that causes performance to suffer (if you end up with insufficient
    storage) or that’s wasteful from a cost perspective (if you overprovision).
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 了解你的数据集大小对于选择适当的基础设施选项很重要。例如，AWS云实例提供了广泛的NVMe存储选项。了解你需要多少存储可以帮助你避免选择会导致性能下降的实例（如果你最终存储不足）或者从成本角度来看浪费的实例（如果你过度配置）。
- en: It’s important to note that your selected storage size should not be equal to
    your total dataset size. You also need to factor in replication and growth—plus
    steer clear of 100 percent storage utilization.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要注意，你选择的存储大小不应等于你的总数据集大小。你还需要考虑复制和增长——并且避免100%的存储利用率。
- en: For example, let’s assume you have 3TB of already compressed data. The bare
    minimum to support a workload is your current dataset size multiplied by your
    anticipated replication. If you have 3TB of data with the common replication factor
    of three, that gives you 9TB. If you naively deployed this on three nodes supporting
    3TB of data each, you’d hit near 100 percent disk utilization which, of course,
    is not optimal.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设你已经有了3TB的已压缩数据。支持工作负载的最低要求是你的当前数据集大小乘以你预期的复制因子。如果你有3TB的数据，并且复制因子为常见的三，那么总共是9TB。如果你天真地将这些数据部署在三个节点上，每个节点支持3TB的数据，那么你会接近100%的磁盘利用率，这当然不是最优的。
- en: 'Instead, if you factor in some free space and minimal room for growth, you’d
    want to start with at least six nodes of that size—each storing only 1.5TB of
    data. This gives you around 50 percent utilization. On the other hand, if your
    database cannot support that much data per node (every database has a limit) or
    if you do not foresee much future data growth, you could have six nodes supporting
    2TB each, which would store approximately 1.5TB per replica under a 75 percent
    utilization. Remember: Factoring in your growth is critical for avoiding unpleasant
    surprises in production, from an operational as well as a budget perspective.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，如果你考虑一些空闲空间和最小的增长空间，你希望从至少六个这种大小的节点开始——每个节点只存储1.5TB的数据。这给你大约50%的利用率。另一方面，如果你的数据库无法支持每个节点那么多的数据（每个数据库都有限制）或者如果你没有预见大量的未来数据增长，你可以有六个节点，每个节点支持2TB，这样在75%的利用率下，每个副本大约存储1.5TB。记住：考虑到你的增长对于避免生产中的不愉快惊喜至关重要，无论是从运营还是预算的角度来看。
- en: Note
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: We very intentionally discussed the dataset size from a *compressed* data standpoint.
    Be aware that some database vendors measure your storage utilization with respect
    to *uncompressed* data. This often leads to confusion. If you’re moving data from
    one database solution to another and your data is uncompressed (or you’re not
    certain it’s compressed), consider loading a small fraction of your total dataset
    beforehand in order to determine its compression ratio. Effective compression
    can dramatically reduce your storage footprint.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我们非常有意地从压缩数据的角度讨论了数据集大小。请注意，一些数据库供应商根据未压缩数据来衡量你的存储利用率。这往往会导致混淆。如果你正在将数据从一个数据库解决方案迁移到另一个，并且你的数据未压缩（或者你不确定它是否已压缩），考虑在之前先加载你总数据集的一小部分，以便确定其压缩率。有效的压缩可以显著减少你的存储足迹。
- en: If you’re working on a very fluid project and can’t define or predict your dataset
    size, a serverless database deployment model might be a good option to provide
    easy flexibility and scaling. But, be aware that rapid increases in overall dataset
    size and/or IOPS (depending on the pricing model) could cause the price to skyrocket
    exponentially. Even if you don’t explicitly pay a penalty for storing a large
    dataset, you might be charged a premium for the many operations that are likely
    associated with that large dataset. Serverless is discussed more in Chapter [7](541783_1_En_7_Chapter.xhtml).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正在处理一个非常灵活的项目，无法定义或预测你的数据集大小，无服务器数据库部署模型可能是一个不错的选择，以提供易于灵活性和扩展。但请注意，整体数据集大小和/或IOPS（取决于定价模型）的快速增加可能会导致价格呈指数级飙升。即使你没有明确为存储大量数据支付罚款，你也可能因为与该大量数据相关的大量操作而支付额外费用。无服务器数据库在第七章[7](541783_1_En_7_Chapter.xhtml)中讨论得更多。
- en: Throughput Expectations
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 吞吐量预期
- en: Your expected throughput and latency should be your “north star” from database
    and infrastructure selection all the way to monitoring. Let’s start with throughput.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 你预期的吞吐量和延迟应该是从数据库和基础设施选择到监控的“北极星”。让我们从吞吐量开始。
- en: If you’re serious about database performance, it’s essential to know what throughput
    you’re trying to achieve—and “high throughput” is not an acceptable answer. Specifically,
    try to get all relevant stakeholders’ agreement on your target number of *peak*
    read operations per second and *peak* write operations per second *for each workload*.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你认真对待数据库性能，了解你试图达到的吞吐量是至关重要的——而“高吞吐量”不是一个可接受的答案。具体来说，尽量争取所有相关利益相关者就每秒的目标峰值读操作数和每秒的目标峰值写操作数达成一致，并且是针对每个工作负载的。
- en: Let’s unravel that a little. First, be sure to separate read throughput vs write
    throughput. A database’s read path is usually quite distinct from its write path.
    It stresses different parts of the infrastructure and taps different database
    internals. And the client/user experience of reads is often quite different than
    that of writes. Lumping them together into a meaningless number won’t help you
    much with respect to performance measurement or optimization. The main use for
    average throughput is in applying Little’s Law (more on that in the “Concurrency”
    section a little later in this chapter).
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们稍微解释一下。首先，确保区分读吞吐量和写吞吐量。数据库的读路径通常与其写路径截然不同。它对基础设施的不同部分施加压力，并触及不同的数据库内部。而且，客户端/用户的读体验通常与写体验大不相同。将它们合并成一个无意义的数值，对性能测量或优化帮助不大。平均吞吐量的主要用途在于应用Little's
    Law（关于这一点，在本章稍后的“并发性”部分将详细介绍）。
- en: 'Another caveat: The same database’s past or current throughput with one use
    case is no guarantee of future results with another—even if it’s the same database
    hosted on identical infrastructure. There are too many different factors at play
    (item size, access patterns, concurrency… all the things in this chapter, really).
    What’s a great fit for one use case could be quite inappropriate for another.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个注意事项：同一个数据库过去或当前的吞吐量，对于另一个用例来说，并不能保证未来的结果——即使它是在相同的基础设施上运行的同一个数据库。影响因素太多（项目大小、访问模式、并发性……本章中提到的所有这些因素）。对某个用例非常适合的，可能对另一个用例来说完全不合适。
- en: Also, note the emphasis on *peak* operations per second. If you build and optimize
    with an average in mind, you likely won’t be able to service beyond the upper
    ranges of that average. Focus on the peak throughput that you need to sustain
    to cover your core needs and business patterns—including surges. Realize that
    databases can often “boost” to sustain short bursts of exceptionally high load.
    However, to be safe, it’s best to plan for your likely peaks and reserve boosting
    for atypical situations.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，请注意对每秒*峰值*操作的强调。如果你以平均值为出发点进行构建和优化，你很可能无法超出这个平均值的上限。关注你需要持续维持的峰值吞吐量，以覆盖你的核心需求和业务模式——包括高峰期。认识到数据库通常可以“提升”以维持短时间内的极高负载。然而，为了安全起见，最好为可能的峰值进行规划，并将提升保留用于非典型情况。
- en: Also, be sure not to confuse concurrency with throughput. *Throughput* is the
    speed at which the database can perform read or write operations; it’s measured
    in the number of read or write operations per second. *Concurrency* is the number
    of requests that the client sends to the database at the same time (which, in
    turn, will eventually translate to a given number of concurrent requests queuing
    at the database for execution). Concurrency is expressed as a hard number, not
    a rate over a period of time. Not every request that is born at the same time
    will be able to be processed by the database at the same time. Your client could
    send 150K requests to the database, all at once. The database might blaze through
    all these concurrent requests if it’s running at 500K OPS. Or, it might take a
    while to process them if the database throughput tops out at 50K OPS.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，务必不要将并发性与吞吐量混淆。*吞吐量*是数据库执行读或写操作的速度；它以每秒读或写操作的数量来衡量。*并发性*是客户端同时发送到数据库的请求数量（这反过来最终会转化为数据库执行时排队等待处理的并发请求数量）。并发性以一个硬数值表示，而不是一段时间内的速率。并不是同时产生的每个请求都能被数据库同时处理。你的客户端可能一次性向数据库发送150K个请求。如果数据库运行在500K
    OPS，它可能会迅速处理所有这些并发请求。或者，如果数据库吞吐量达到50K OPS，它可能需要一段时间来处理这些请求。
- en: 'It is generally possible to increase throughput by increasing your cluster
    size (and/or power). But, you also want to pay special attention to concurrency,
    which will be discussed in more depth later in this chapter as well as in Chapter
    [5](541783_1_En_5_Chapter.xhtml). For the most part, high concurrency is essential
    for achieving impressive performance. But if the clients end up overwhelming the
    database with a concurrency that it can’t handle, throughput will suffer, then
    latency will rise as a side effect. A friendly reminder that transcends the database
    world: No system, distributed or not, supports unlimited concurrency. Period.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 通常情况下，可以通过增加集群大小（和/或功率）来提高吞吐量。但是，你还需要特别注意并发性，这一点将在本章的后面以及第[5](541783_1_En_5_Chapter.xhtml)章中更深入地讨论。在大多数情况下，高并发对于实现令人印象深刻的性能是必不可少的。但如果客户端最终以数据库无法处理的并发性压倒数据库，吞吐量将受到影响，延迟也将作为副作用上升。一个超越数据库世界的友好提醒：没有系统，无论是分布式的还是非分布式的，都支持无限的并发性。这就是了。
- en: Note
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Even though scaling a cluster boosts your database processing capacity, remember
    that the application access patterns directly contribute to how much impact that
    will ultimately make. One situation where scaling a cluster may not provide the
    desired throughput increase is during a *hot partition*^([10](#Fn10)) situation,
    which causes traffic to be primarily targeted to a specific set of replicas. In
    these cases, throttling the access to such hot keys is fundamental for preserving
    the system’s overall performance.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管扩展集群可以提高数据库处理能力，但请记住，应用程序访问模式直接影响到最终会产生多少影响。在一种情况下，扩展集群可能不会提供期望的吞吐量增加，那就是在*热点分区*^([10](#Fn10))情况下，这会导致流量主要针对一组特定的副本。在这些情况下，限制对这类热点键的访问对于保持系统的整体性能至关重要。
- en: Latency Expectations
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 延迟预期
- en: 'Latency is a more complex challenge than throughput: You can increase throughput
    by adding more nodes, but there’s no simple solution for reducing latency. The
    lower the latency you need to achieve, the more important it becomes to understand
    and explore database tradeoffs and internal database optimizations that can help
    you shave milliseconds or microseconds off latencies. Database internals, driver
    optimizations, efficient CPU utilization, sufficient RAM, efficient data modeling…
    everything matters.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 延迟是一个比吞吐量更复杂的挑战：你可以通过添加更多节点来提高吞吐量，但降低延迟没有简单的解决方案。你需要达到的延迟越低，理解和探索数据库权衡以及内部数据库优化就越重要，这些优化可以帮助你从延迟中削减毫秒或微秒。数据库内部，驱动程序优化，高效的CPU利用率，足够的RAM，高效的数据建模……所有这些都很重要。
- en: As with throughput, aim for all relevant stakeholders’ agreement on the acceptable
    latencies. This is usually expressed as latency for a certain percentile of requests.
    For performance-sensitive workloads, tracking at the 99th percentile (P99) is
    common. Some teams go even higher, such as the P9999, which refers to the 99.99th
    percentile.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 与吞吐量一样，目标是让所有相关利益相关者就可接受的延迟达成一致。这通常表示为请求的某个百分比的延迟。对于对性能敏感的工作负载，跟踪第99百分位（P99）是常见的。一些团队甚至更高，比如P9999，它指的是第99.99百分位。
- en: 'As with throughput, avoid focusing on *average* (mean) or median (P50) latency
    measurements. Average latency is a theoretical measurement that is not directly
    correlated to anything systems or users experience in reality. Averages conceal
    outliers: Extreme deviations from the norm that may have a large and unexpected
    impact on overall system performance, and hence on user experience.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 与吞吐量一样，避免只关注*平均*（均值）或中位数（P50）的延迟测量。平均延迟是一个理论测量值，它与系统或用户在现实中体验到的任何东西都没有直接相关性。平均值掩盖了异常值：与正常值有极大偏差的情况，可能会对整体系统性能产生重大且意外的负面影响，从而影响用户体验。
- en: For example, look at the discrepancy between average latencies and P99 latencies
    in Figure [2-2](#Fig2) (different colors represent different database nodes).
    P99 latencies were often double the average for reads, and even worse for writes.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，看看图[2-2](#Fig2)中平均延迟和P99延迟之间的差异（不同颜色代表不同的数据库节点）。P99延迟通常比平均读取延迟高出一倍，对于写入来说情况更糟。
- en: '![](../images/541783_1_En_2_Chapter/541783_1_En_2_Fig2_HTML.jpg)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../images/541783_1_En_2_Chapter/541783_1_En_2_Fig2_HTML.jpg)'
- en: Six database graphs of average read or write latency versus instance. In the
    first graph, average read latency is mostly between 2 and 6 milliseconds.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 六种数据库图显示了平均读写延迟与实例的关系。在第一张图中，平均读取延迟大多在2到6毫秒之间。
- en: Figure 2-2
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 图2-2
- en: A sample database monitoring dashboard. Note the difference between average
    and P99 latencies
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 一个示例数据库监控仪表板。注意平均延迟和P99延迟之间的差异
- en: Note that monitoring systems are sometimes configured in ways that omit outliers.
    For example, if a monitoring system is calibrated to measure latency on a scale
    of 0 to 1000ms, it is going to overlook any larger measurements—thus failing to
    detect the serious issues of query timeouts and retries.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，监控系统有时被配置成忽略异常值。例如，如果一个监控系统被校准为在0到1000毫秒的范围内测量延迟，它将忽略任何更大的测量值——从而未能检测到查询超时和重试的严重问题。
- en: P99 and above percentiles are not perfect.^([11](#Fn11)) But for latency-sensitive
    use cases, they’re the number you’ll want to keep in mind as you are selecting
    your infrastructure, benchmarking, monitoring, and so on.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: P99及以上的百分位数并不完美。[11](#Fn11) 但对于对延迟敏感的使用案例，它们是在你选择基础设施、基准测试、监控等时需要记住的数字。
- en: 'Also, be clear about what exactly is involved in the P99 you are looking to
    achieve. Database latency is the time that elapses between when the database receives
    a request, processes it, and sends back an appropriate response. Client-side latency
    is broader: Here, the measurement starts with the client sending the request and
    ends with the client receiving the database’s response. It includes the network
    time and client-side processing. There can be quite a discrepancy between database
    latency and client-side latency; a ten times higher client-side latency isn’t
    all that uncommon (although clearly not desirable). There could be many culprits
    to blame for a significantly higher client-side latency than database latency:
    excessive concurrency, inefficient application architecture, coding issues, and
    so on. But that’s beyond the scope of this discussion—beyond the scope of this
    book, even.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，要清楚你想要实现的P99具体包括什么。数据库延迟是数据库接收到请求、处理它并发送适当响应所花费的时间。客户端延迟更广泛：在这里，测量从客户端发送请求开始，到客户端接收到数据库的响应结束。它包括网络时间和客户端处理时间。数据库延迟和客户端延迟之间可能存在相当大的差异；十倍高的客户端延迟并不罕见（尽管显然是不希望的）。可能有许多原因可以解释客户端延迟比数据库延迟显著更高的情况：过度的并发、低效的应用程序架构、编码问题等。但这超出了本次讨论的范围——甚至超出了本书的范围。
- en: The key point here is that your team and all the stakeholders need to be on
    the same page regarding what you’re measuring. For example, say you’re given a
    read latency requirement of 15ms. You work hard to get your database to achieve
    that and report that you met the expectation—then you learn that stakeholders
    actually expect 15ms for the full client-side latency. Back to the drawing board.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 这里关键点是，你的团队和所有利益相关者需要就你们要测量的内容达成一致。例如，假设你被分配了一个15毫秒的读取延迟要求。你努力工作以使数据库达到这个目标并报告你已经满足了预期——然后你得知利益相关者实际上期望的是完整的客户端延迟为15毫秒。回到起跑线。
- en: Ultimately, it’s important to track both database latency and client-side latency.
    You can optimize the database all you want, but if the application is introducing
    latency issues from the client side, a fast database won’t have much impact. Without
    visibility into both the database and the client-side latencies, you’re essentially
    flying half blind.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，跟踪数据库延迟和客户端延迟都很重要。你可以尽可能优化数据库，但如果应用程序从客户端引入延迟问题，快速的数据库不会有太大影响。如果没有对数据库和客户端延迟的可见性，你实际上是在半盲状态下操作。
- en: Concurrency
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 并发
- en: What level of concurrency should your database be prepared to handle? Depending
    on the desired qualities of service from the database cluster, concurrency must
    be judiciously balanced to reach appropriate throughput and latency values. Otherwise,
    requests will pile up waiting to be processed—causing latencies to spike, timeouts
    to rise, and the overall user experience to degrade.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 你的数据库应该准备处理多少级别的并发？根据数据库集群期望的服务质量，并发必须谨慎平衡以达到适当的吞吐量和延迟值。否则，请求将堆积等待处理，导致延迟激增，超时增加，整体用户体验下降。
- en: 'Little’s Law establishes that:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: Little定律确立了以下原则：
- en: L=λW
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: L=λW
- en: where λ is the average throughput, W is the average latency, and L represents
    the total number of requests either being processed or on queue at any given moment
    when the cluster reaches steady state. Given that your throughput and latency
    targets are usually fixed, you can use Little’s Law to estimate a realistic concurrency.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 其中λ是平均吞吐量，W是平均延迟，L代表在集群达到稳定状态时，任何给定时刻正在处理或排队等待处理的总请求数。鉴于你的吞吐量和延迟目标通常是固定的，你可以使用Little定律来估算一个现实的并发量。
- en: For example, if you want a system to serve 500,000 requests per second at 2.5ms
    average latency, the best concurrency is around 1,250 in-flight requests. As you
    approach the saturation limit of the system—around 600,000 requests per second
    for read requests—increases in concurrency will keep constant since this is the
    physical limit of the database. Every new in-flight request will only cause increased
    latency. In fact, if you approximate 600,000 requests per second as the physical
    capacity of this database, you can calculate the expected average latency at a
    particular concurrency point. For example, at 6,120 in-flight requests, the average
    latency is expected to be 6120/600,000 = 10ms.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果你希望系统每秒处理500,000个请求，平均延迟为2.5毫秒，最佳并发性约为1,250个正在进行的请求。当你接近系统的饱和限制——大约每秒600,000个读取请求时，并发性的增加将保持恒定，因为这是数据库的物理限制。每个新的正在进行的请求只会导致延迟增加。实际上，如果你将每秒600,000个请求近似为该数据库的物理容量，你可以计算出特定并发点的预期平均延迟。例如，在6,120个正在进行的请求时，预期平均延迟为6120/600,000
    = 10毫秒。
- en: Past the maximum throughput, increasing concurrency will increase latency. Conversely,
    reducing concurrency will reduce latency, provided that this reduction does not
    result in a decrease in throughput.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 超过最大吞吐量后，增加并发性会增加延迟。相反，减少并发性会减少延迟，前提是这种减少不会导致吞吐量下降。
- en: In some use cases, it’s fine for queries to pile up on the client side. But
    many times it’s not. In those cases, you can scale out your cluster or increase
    the concurrency on the application side—at least to the point where the latency
    doesn’t suffer. It’s a delicate balancing act.^([12](#Fn12))
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些用例中，查询在客户端累积是可以接受的。但很多时候并不可以。在这些情况下，你可以扩展你的集群或在应用端增加并发性——至少要达到延迟不受影响的程度。这是一项微妙的平衡行为。[^([12](#Fn12))]
- en: Connected Technologies
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 连接技术
- en: A database can’t rise above the slowest-performing link in your distributed
    data system. Even if your database is processing reads and writes at blazing speeds,
    it won’t ultimately matter much if it interacts with an event-streaming platform
    that’s not optimized for performance or involves transformations from a poorly-configured
    Apache Spark instance, for example.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 数据库无法超越你分布式数据系统中性能最慢的链路。即使你的数据库以极快的速度处理读写操作，如果它与一个未针对性能优化的流式事件平台交互，或者涉及到来自配置不当的Apache
    Spark实例的转换，例如，那么最终这并不会产生太大的影响。
- en: This is just one of many reasons that taking a comprehensive and proactive approach
    to monitoring (more on this in Chapter [10](541783_1_En_10_Chapter.xhtml)) is
    so important. Given the complexity of databases and distributed data systems,
    it’s hard to guess what component is to blame for a problem. Without a window
    into the state of the broader system, you could naively waste amazing amounts
    of time and resources trying to optimize something that won’t make any difference.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 这只是众多原因之一，说明采取全面和主动的监控方法（更多内容请见第[10](541783_1_En_10_Chapter.xhtml)章）非常重要。鉴于数据库和分布式数据系统的复杂性，很难猜测出是哪个组件导致了问题。如果没有对整个系统状态的洞察，你可能会天真地浪费大量时间和资源去优化一些不会产生任何差别的部分。
- en: If you’re looking to optimize an existing data system, don’t overlook the performance
    gains you can achieve by reviewing and tuning its connected components. Or, if
    your monitoring efforts indicate that a certain component is to blame for your
    client-side performance problems but you feel you’ve hit your limit with it, explore
    what’s required to replace it with a more performant alternative. Use benchmarking
    to determine the severity of the impact from a performance perspective.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正在寻求优化现有的数据系统，不要忽视通过审查和调整其连接组件所能实现的性能提升。或者，如果你的监控工作表明某个组件是导致客户端性能问题的罪魁祸首，但你感觉已经对其达到了极限，那么探索替换为更高效的替代方案所需的内容。使用基准测试来确定性能影响程度。
- en: Also, note that some database offerings may have ecosystem limitations. For
    example, if you’re considering a serverless deployment model, be aware that some
    Change Data Capture (CDC) connectors, drivers, and so on, might not be supported.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，请注意，某些数据库产品可能存在生态系统限制。例如，如果你正在考虑无服务器部署模型，请注意，一些更改数据捕获（CDC）连接器、驱动程序等可能不受支持。
- en: Demand Fluctuations
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 需求波动
- en: Databases might experience a variety of different demand fluctuations, ranging
    from predictable moderate fluctuations to unpredictable and dramatic spikes. For
    instance, the world’s most watched sporting event experiences different fluctuations
    than a food delivery service, which experiences different fluctuations than an
    ambulance-tracking service—and all require different strategies and infrastructure.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 数据库可能会经历各种不同的需求波动，从可预测的适度波动到不可预测的剧烈峰值。例如，世界上观看最多的体育赛事的需求波动与食品配送服务不同，食品配送服务的需求波动又与救护车跟踪服务不同——所有这些都需要不同的策略和基础设施。
- en: First, let’s look at the predictable fluctuations. With predictability, it’s
    much easier to get ahead of the issue. If you’re expected to support periodic
    big events that are known in advance (Black Friday, sporting championships, ticket
    on sales, etc.), you should have adequate time to scale up your cluster for each
    anticipated spike. That means you can tailor your normal topology for the typical
    day-in, day-out demands without having to constantly incur the costs and admin
    burden of having that larger scale topology.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们看看可预测的波动。有了可预测性，提前解决问题就更容易了。如果你预计要支持事先已知的周期性大型活动（如黑色星期五、体育锦标赛、票务销售等），你应该有足够的时间为每个预期的峰值扩展你的集群。这意味着你可以在不承担不断产生更大规模拓扑结构成本和管理负担的情况下，为典型的一天调整你的正常拓扑结构。
- en: On the other side of the spikiness spectrum, there’s applications with traffic
    with dramatic peaks and valleys across the course of each day. For example, consider
    food delivery businesses, which face a sudden increase around lunch, followed
    by a few hours of minimal traffic, then a second spike at dinner time (and sometimes
    breakfast the following morning). Expanding the cluster for each spike—even with
    “autoscaling” (more on autoscaling later in this chapter)—is unlikely to deliver
    the necessary performance gain fast enough. In these cases, you should provision
    an infrastructure that supports the peak traffic.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在峰值特性的另一端，有一些应用程序的流量在每天中都有显著的峰值和低谷。例如，考虑食品配送业务，它们在午餐时间突然增加，然后是几小时的最低流量，然后在晚餐时间再次出现峰值（有时第二天早上早餐时也是如此）。即使有“自动扩展”（本章后面将详细介绍自动扩展），为每个峰值扩展集群也不太可能快速提供必要的性能提升。在这些情况下，你应该提供支持峰值流量的基础设施。
- en: But not all spikes are predictable. Certain industries—such as emergency services,
    news, and social media—are susceptible to sudden massive spikes. In this case,
    a good preventative strategy is to control your concurrency on the client side,
    so it doesn’t overwhelm your database. However, controlling concurrency might
    not be an option for use cases with strict end-to-end latency requirements. You
    can also scramble to scale out your clusters as fast as feasible when the spike
    occurs. This is going to be markedly simpler if you’re on the cloud than if you’re
    on-prem. If you can start adding nodes immediately, increase capacity incrementally—with
    a close eye on your monitoring results—and keep going until you’re satisfied with
    the results, or until the peak has subsided. Unfortunately, there is a real risk
    that you won’t be able to sufficiently scale out before the spike ends. Even if
    the ramp up begins immediately, you need to account for the time it takes to get
    data over to add new nodes, stream data to them, and rebalance the cluster.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 但并非所有峰值都是可预测的。某些行业——如紧急服务、新闻和社交媒体——容易受到突然的大规模峰值的影响。在这种情况下，一个良好的预防策略是在客户端控制并发，以免数据库过载。然而，对于具有严格端到端延迟要求的用例，控制并发可能不是一个选择。当峰值发生时，你也可以尽可能快地扩展你的集群。如果你在云上，这将会比在本地要简单得多。如果你可以立即添加节点，可以逐步增加容量——密切关注监控结果——并继续进行，直到你对结果满意，或者直到峰值下降。不幸的是，你可能会在峰值结束之前无法充分扩展。即使提升开始得立即，你也必须考虑到将数据传输到新节点、向它们流数据以及重新平衡集群所需的时间。
- en: If you’re selecting a new database and anticipate frequent and sharp spikes,
    be sure to rigorously test how your top contenders respond under realistic conditions.
    Also, consider the costs of maintaining acceptable performance throughout these
    peaks.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正在选择一个新的数据库，并预计会有频繁且剧烈的峰值，请务必在实际条件下严格测试你的主要候选者如何响应。此外，还应考虑在整个峰值期间维持可接受性能的成本。
- en: Note
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The word “autoscaling” insinuates that your database cluster auto-magically
    expands based on the traffic it is receiving. Not so. It’s simply a robot enabling/disabling
    capacity that’s pre-provisioned for you based on your target table settings. Even
    if you’re not using this capacity, you might be paying for the convenience of
    having it set aside and ready to go. Also, it’s important to realize that it’s
    not instantaneous. It takes upwards of 2.5 hours to go from 0 rps to 40k.^([13](#Fn13))
    This is not ideal for unexpected or extreme spikes.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: “自动扩展”这个词暗示了您的数据库集群会根据接收到的流量自动扩展。并非如此。它只是一个机器人，根据您预定的目标表设置启用/禁用预配置的容量。即使您不使用这个容量，您可能也在为预留和准备就绪的便利性付费。此外，重要的是要认识到，这并不是瞬时的。从0
    rps到40k需要2.5小时以上.^([13](#Fn13)) 这对于意外或极端峰值来说并不理想。
- en: 'Autoscaling is best when:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 自动扩展的最佳时机：
- en: Load changes have high amplitude
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 负载变化具有高振幅
- en: The rate of change is in the magnitude of hours
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 变化率在小时量级
- en: The load peak is narrow relative to the baseline^([14](#Fn14))
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 相对于基线，负载峰值较窄^([14](#Fn14))
- en: ACID Transactions
  id: totrans-127
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ACID事务
- en: Does your use case require you to process a logical unit of work with ACID (atomic,
    consistent, isolated, and durable) properties? These transactions, which are historically
    the domain of RDBMS, bring a severe performance hit.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 您的使用案例是否需要您处理具有ACID（原子性、一致性、隔离性和持久性）属性的逻辑工作单元？这些交易，历史上一直是关系数据库管理系统（RDBMS）的领域，会带来严重的性能影响。
- en: It is true that distributed ACID compliant databases do exist—and that the past
    few years have brought some distinct progress in the effort to minimize the performance
    impact (e.g., through row-level locks or column-level locking and better conflict
    resolution algorithms). However, some level of penalty will still exist.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 确实，存在符合ACID规范的分布式数据库，并且过去几年在最小化性能影响方面取得了一些显著进展（例如，通过行级锁定或列级锁定以及更好的冲突解决算法）。然而，仍然会存在一定程度的惩罚。
- en: As a general guidance, if you have an ACID-compliant use case, pay special attention
    to your master nodes; these can easily become your bottlenecks since they will
    often be your primary query coordinators (more on this in Appendix A). In addition,
    if at all possible, try to ensure that the majority of your transactions are isolated
    to the minimum amount of resources. For example, a transaction spanning a single
    row may involve a specific set of replicas, whereas a transaction involving several
    keys may span your cluster as a whole—inevitably increasing your latency. It is
    therefore important to understand which types of transactions your target database
    supports. Some vendors may support a mix of approaches, while others excel at
    specific ones. For instance, MongoDB introduced multi-document transactions on
    sharded clusters in its version 4.2; prior to that, it supported only multi-document
    transactions on replica sets.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一般指导原则，如果您有一个符合ACID规范的使用案例，请特别注意您的主节点；这些节点很容易成为瓶颈，因为它们通常将是您的首要查询协调器（更多内容请见附录A）。此外，如果可能的话，尽量确保大多数交易都隔离在最小的资源量上。例如，跨越单行的交易可能涉及一组特定的副本，而涉及多个键的交易可能跨越整个集群——不可避免地增加您的延迟。因此，了解您的目标数据库支持哪些类型的交易非常重要。一些供应商可能支持多种方法，而其他供应商可能在特定方法上表现出色。例如，MongoDB在其4.2版本中在分片集群上引入了多文档事务；在此之前，它只支持副本集上的多文档事务。
- en: If it’s critical to support transactions in a more performant manner, sometimes
    it’s possible to rethink your data model and reimplement a use case in a way that
    makes it suitable for a database that’s not ACID compliant. For example, one team
    who started out with Postgres for all their use cases faced skyrocketing business
    growth. This is a very common situation with startups that begin small and then
    suddenly find themselves in a spot where they are unable to handle a spike in
    growth in a cost-effective way. They were able to move their use cases to NoSQL
    by conducting a careful data-modeling analysis and rethinking their use cases,
    access patterns, and the real business need of what truly required ACID and what
    did not. This certainly isn’t a quick fix, but in the right situation, it can
    pay off nicely.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 如果支持事务的性能至关重要，有时重新思考你的数据模型并以适合非ACID兼容数据库的方式重新实现用例是可能的。例如，一个最初为所有用例使用Postgres的团队在面临业务快速增长时遇到了这种情况。这种情况对于从小规模开始，然后突然发现自己无法以经济有效的方式处理增长激增的初创公司来说非常常见。他们通过进行仔细的数据模型分析，重新思考他们的用例、访问模式和真正需要ACID以及不需要ACID的真实业务需求，将他们的用例迁移到了NoSQL。这当然不是快速修复，但在正确的情况下，它可能会带来很好的回报。
- en: 'Another option to consider: Performance-focused NoSQL databases like Cassandra
    aim to support isolated conditional updates with capabilities such as lightweight
    transactions that allow “atomic compare and set” operations. That is, the database
    checks if a condition is true, and if so, it conducts the transaction. If the
    condition is not met, the transaction is not completed. They are named “lightweight”
    since they do not truly lock the database for the transaction. Instead, they use
    a consensus protocol to ensure there is agreement between the nodes to commit
    the change. This capability was introduced by Cassandra and it’s supported in
    several ways across different Cassandra-compatible databases. If this is something
    you expect to use, it’s worth exploring the documentation to understand the differences.^([15](#Fn15))'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个可以考虑的选项：以性能为导向的NoSQL数据库，如Cassandra，旨在通过具有轻量级事务等功能的隔离条件更新来支持。也就是说，数据库检查条件是否为真，如果是，则执行事务。如果条件不满足，则事务不会完成。它们被称为“轻量级”，因为它们实际上不会锁定数据库以进行事务。相反，它们使用共识协议来确保节点之间就提交更改达成一致。这种功能是由Cassandra引入的，并且在不同的Cassandra兼容数据库中以多种方式得到支持。如果你期望使用这项功能，探索文档以了解差异是值得的。[15](#Fn15)
- en: However, it’s important to note that lightweight transactions have their limits.
    They can’t support complex use cases like a retail transaction that updates the
    inventory only after a sale is completed with a successful payment. And just like
    ACID-compliant databases, lightweight transactions have their own performance
    implications. As a result, the choice of whether to use them will greatly depend
    on the amount of ACID compliance that your use case requires.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，需要注意的是，轻量级事务有其局限性。它们无法支持像零售交易这样的复杂用例，这种交易只在销售完成后并成功支付后才更新库存。而且就像ACID兼容的数据库一样，轻量级事务也有它们自己的性能影响。因此，是否使用它们的选择将很大程度上取决于你的用例所需的ACID兼容程度。
- en: 'DynamoDB is a prime example of how the need for transactions will require more
    compute resources (read: money). As a result, use cases relying heavily on ACID
    will fairly often require much more infrastructure power to satisfy heavy usage
    requirements. In the DynamoDB documentation, AWS recommends that you ensure the
    database is configured for auto-scaling or that it has enough read/write capacity
    to account for the additional overhead of transactions.^([16](#Fn16))'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: DynamoDB是需求对事务的需要将需要更多计算资源（即金钱）的一个主要例子。因此，高度依赖ACID的用例通常需要更多的基础设施能力来满足重用要求。在DynamoDB文档中，AWS建议你确保数据库已配置为自动扩展，或者它有足够的读写能力来处理事务的额外开销。[16](#Fn16)
- en: Consistency Expectations
  id: totrans-135
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一致性期望
- en: Most NoSQL databases opt for eventual consistency to gain performance. This
    is in stark contrast to the RDBMS model, where ACID compliance is achieved in
    the form of transactions, and, because everything is in a single node, the effort
    on locking and avoiding concurrency clashes is often minimized. When deciding
    between a database with strong or eventual consistency, you have to make a hard
    choice. Do you want to sacrifice scalability and performance or can you accept
    the risk of sometimes serving stale data?
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数NoSQL数据库选择最终一致性以获得性能。这与RDBMS模型形成鲜明对比，在RDBMS模型中，ACID合规性是通过事务实现的，并且由于所有内容都在单个节点上，锁定和避免并发冲突的努力通常被最小化。在决定使用强一致性或最终一致性的数据库时，你必须做出艰难的选择。你愿意牺牲可扩展性和性能，还是可以接受有时提供陈旧数据的风险？
- en: Can your use case tolerate eventual consistency, or is strong consistency truly
    required? Your choice really boils down to how much risk your application—and
    your business—can tolerate with respect to inconsistency. For example, a retailer
    who (understandably) requires consistent pricing might want to pay the price for
    consistent writes upfront during a weekly catalog update so that they can later
    serve millions of low-latency read requests under more relaxed consistency levels.
    In other cases, it’s more important to ingest data quickly and pay the price for
    consistency later (for example, in the playback tracking use case that’s common
    in streaming platforms—where the database needs to record the last viewing position
    for many users concurrently). Or maybe both are equally important. For example,
    consider a social media platform that offers live chat. Here, you want consistency
    on both writes and reads, but you likely don’t need the highest consistency (the
    impact of an inconsistency here is likely much less than with a financial report).
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 你的用例能否容忍最终一致性，或者强一致性确实是必需的？你的选择实际上取决于你的应用程序——以及你的业务——在一致性方面可以承受多少风险。例如，一个（可以理解地）需要一致定价的零售商可能愿意在每周目录更新期间提前支付一致写入的成本，以便他们可以在更宽松的一致性级别下后来服务数百万的低延迟读取请求。在其他情况下，快速摄取数据可能更重要，并且可以在以后（例如，在流媒体平台中常见的回放跟踪用例中）支付一致性的代价。或者，两者可能同样重要。例如，考虑一个提供实时聊天的社交媒体平台。在这里，你希望在读写上保持一致性，但你可能不需要最高的一致性（不一致性的影响可能远小于财务报告）。
- en: In some cases, “tunable consistency” will help you achieve a balance between
    strong consistency and performance. This gives you the ability to tune the consistency
    at the query level to suit what you’re trying to achieve. You can have some queries
    relying on a quorum of replicas, then have other queries that are much more relaxed.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，“可调一致性”可以帮助你在强一致性和性能之间取得平衡。这让你能够在查询级别调整一致性，以适应你想要实现的目标。你可以有一些查询依赖于副本的多数，然后有其他查询更加宽松。
- en: Regardless of your consistency requirements, you need to be aware of the implications
    involved when selecting a given consistency level. Databases that offer tunable
    consistency may be a blessing or a curse if you don’t know what you are doing.
    Consider a NoSQL deployment spanning three different regions, with three nodes
    each (nine nodes in total). A QUORUM read would essentially have to traverse two
    different regions in order to be acknowledged back to the client. In that sense,
    if your Network Round Trip Time (RTT)^([17](#Fn17)) is 50ms, then it will take
    *at least* this amount of time for the query to be considered successful by the
    database. Similarly, if you were to run operations with the highest possible consistency
    (involving all replicas), then the failure of a single node may bring your entire
    application down.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 无论你的一致性要求如何，你都需要意识到选择特定一致性级别时涉及的潜在影响。如果你不知道自己在做什么，提供可调一致性的数据库可能既是祝福也是诅咒。考虑一个跨越三个不同地区的NoSQL部署，每个地区有三个节点（总共九个节点）。一个QUORUM读取实际上必须跨越两个不同的地区才能被客户端认可。从这个意义上说，如果你的网络往返时间（RTT）为50ms，那么查询被数据库认为是成功的至少需要这么长时间。同样，如果你要运行最高可能的一致性操作（涉及所有副本），那么单个节点的故障可能会使你的整个应用程序崩溃。
- en: Note
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: NoSQL databases fairly often will provide you with ways to confine your queries
    to a specific region to prevent costly network round trips from impacting your
    latency. But again, it all boils down to you what your use case requires.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: NoSQL数据库通常会提供方法来限制你的查询到特定区域，以防止昂贵的网络往返影响你的延迟。但同样，这所有的一切都归结于你的用例需求。
- en: Geographic Distribution
  id: totrans-142
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 地理分布
- en: Does your business need to support a regional or global customer base in the
    near-term future? Where are your users and your application located? The greater
    the distance between your users, your application, and your database, the more
    they’re going to face high latencies that stem from the physical time it takes
    to move data across the network. Knowing this will influence where you locate
    your database and how you design your topology—more on this in Chapters [6](541783_1_En_6_Chapter.xhtml)
    and [8](541783_1_En_8_Chapter.xhtml).
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 你的业务在不久的将来是否需要支持区域或全球客户群？你的用户和你的应用程序在哪里？用户、应用程序和数据库之间的距离越远，他们就越可能面临由于数据通过网络传输所需的时间而产生的较高延迟。了解这一点将影响你放置数据库的位置以及你设计拓扑结构的方式——更多内容请参阅第[6](541783_1_En_6_Chapter.xhtml)章和第[8](541783_1_En_8_Chapter.xhtml)章。
- en: The geographic distribution of your cluster might also be a requirement from
    a disaster recovery perspective. In that sense, the cluster would typically serve
    data primarily from a specific region, but failover to another in the event of
    a disaster (such as a full region outage). These kinds of setups are costly, as
    they will require doubling your infrastructure spend. However, depending on the
    nature of your use case, sometimes it’s required.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 从灾难恢复的角度来看，你的集群的地理分布可能也是一个要求。在这种情况下，集群通常会从特定区域主要提供数据，但在发生灾难（如整个区域中断）的情况下会切换到另一个区域。这类设置成本很高，因为它们将需要加倍你的基础设施支出。然而，根据你的用例性质，有时这是必需的。
- en: Some organizations that invest in a multi-region deployment for the primary
    purpose of disaster recovery end up using them to host isolated use cases. As
    explained in the “Competing Workloads” section of this chapter, companies often
    prefer to physically isolate OLTP from OLAP workloads. Moving some isolated (less
    critical) workloads to remote regions prevents these servers from being “idle”
    most of the time.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 一些组织投资于多区域部署的主要目的是为了灾难恢复，但最终却用它们来托管孤立的使用案例。正如本章“竞争工作负载”部分所解释的，公司通常更喜欢将OLTP（在线事务处理）工作负载与OLAP（在线分析处理）工作负载在物理上隔离。将一些孤立（不那么关键）的工作负载迁移到远程区域，可以防止这些服务器大部分时间处于“闲置”状态。
- en: 'Regardless of the magnitude of compelling reasons that may drive you toward
    a geographically dispersed deployment, here’s some important high-level advice
    from a performance perspective (you’ll learn some more technical tips in Chapter
    [8](541783_1_En_8_Chapter.xhtml)):'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 无论是什么强烈的理由驱使你选择地理分散部署，以下是从性能角度出发的一些重要的高层次建议（你将在第[8](541783_1_En_8_Chapter.xhtml)章中学习更多技术性的小贴士）：
- en: Consider the increased load that your target region or regions will receive
    in the event of a full region outage. For example, assume that you operate globally
    across three regions, and all these three regions serve your end-users. Are the
    two remaining regions able to sustain the load for a long period of time?
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 考虑在区域完全中断的情况下，你的目标区域或区域将承受的增加的负载。例如，假设你在全球范围内运营三个区域，这三个区域都服务于你的最终用户。剩下的两个区域能否长时间承受这种负载？
- en: Recognize that simply having a geographically-dispersed database does *not*
    fully cover you in a disaster recovery situation. You also need to have your application,
    web servers, messaging queue systems, and so on, geographically replicated. If
    the only thing that’s geo-replicated is your database, you won’t be in a great
    position when your primary application goes down.
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 认识到仅仅拥有地理分散的数据库并不能在灾难恢复情况下完全保护你。你还需要将你的应用程序、Web服务器、消息队列系统等地理上复制。如果唯一地理复制的只是你的数据库，那么当你的主要应用程序出现问题时，你将处于不利的位置。
- en: Consider the fact that geo-replicated databases typically require very good
    network links. Especially when crossing large distances, the time to replicate
    your data is crucial to minimize losses in the event of a disaster. If your workload
    has a heavy write throughput, a slow network link may bottleneck the local region
    nodes. This may cause a queue to build up and eventually throttle down your writes.
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 考虑到地理复制数据库通常需要非常好的网络连接。特别是当跨越较大距离时，复制你的数据所需的时间对于在灾难发生时最小化损失至关重要。如果你的工作负载有很高的写入吞吐量，慢速的网络连接可能会成为本地区域节点的瓶颈。这可能会导致队列积压，并最终降低你的写入速度。
- en: High-Availability Expectations
  id: totrans-150
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 高可用性期望
- en: Inevitably, s#*& happens. To prepare for the worst, start by understanding what
    your use case and business can tolerate if a node goes down. Can you accept the
    data loss that could occur if a node storing unreplicated data goes down? Do you
    need to continue buzzing along without a noticeable performance impact even if
    an entire datacenter or availability zone goes down? Or is it okay if things slow
    down a bit from time to time? This will all impact how you architect your topology
    and configure things like replication factor and consistency levels (you’ll learn
    about this more in Chapter [8](541783_1_En_8_Chapter.xhtml)).
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 不可避免地，总会发生一些意外。为了应对最坏的情况，首先了解如果某个节点发生故障，你的用例和业务可以承受什么。你能接受如果存储未复制数据的节点发生故障可能发生的数据丢失吗？你是否需要在数据中心或可用区完全中断的情况下，继续运行而不受明显性能影响？或者，如果偶尔慢一点是可以接受的吗？这些都将会影响你如何设计拓扑结构以及如何配置诸如复制因子和一致性级别（你将在第[8](541783_1_En_8_Chapter.xhtml)章中了解更多）等问题。
- en: It’s important to note that replication and consistency both come at a cost
    to performance. Get a good feel for your business’s risk tolerance and don’t opt
    for more than your business really needs.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，复制和一致性都会对性能造成成本。了解你业务的风险承受能力，不要选择超出你业务实际需要的。
- en: When considering your cluster topology, remember that quite a lot is at risk
    if you get it wrong (and you don’t want to be caught off-guard in the middle of
    the night). For example, the failure of a single node in a three-node cluster
    could make you momentarily lose 33 percent of your processing power. Quite often,
    that’s a significant blow, with discernable business impact. Similarly, the loss
    of a node in a six-node cluster would reduce the blast radius to only 16 percent.
    But there’s always a tradeoff. A sprawling deployment spanning hundreds of nodes
    is not ideal either. The more nodes you have, the more likely you are to experience
    a node failure. Balance is key.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 在考虑集群拓扑时，记住如果你处理不当，风险很大（你也不想在大半夜被惊醒）。例如，一个三节点集群中单个节点的故障可能会让你暂时失去33%的处理能力。这种情况通常会造成重大打击，对业务有可察觉的影响。同样，一个六节点集群中节点的丢失会将影响范围缩小到只有16%。但总有权衡。跨越数百个节点的庞大部署也不是理想的选择。节点越多，发生节点故障的可能性就越大。平衡是关键。
- en: Summary
  id: totrans-154
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: The specific database challenges you encounter, as well as your options for
    addressing them, are highly dependent on your situation. For example, an AdTech
    use case that demands single-digit millisecond P99 latencies for a large dataset
    with small item sizes requires a different treatment than a fraud detection use
    case that prioritizes the ingestion of massive amounts of data as rapidly as possible.
    One of the primary factors influencing how these workloads are handled is how
    your database is architected. That’s the focus for the next two chapters, which
    dive into database internals.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 你遇到的特定数据库挑战以及解决它们的选项，很大程度上取决于你的情况。例如，一个需要为大量数据集中的小项目提供个位数毫秒P99延迟的AdTech用例，与一个优先考虑尽可能快速摄取大量数据的欺诈检测用例相比，需要不同的处理方式。影响这些工作负载处理方式的一个主要因素是数据库的架构。这就是下一章的重点，我们将深入探讨数据库内部结构。
- en: '[![Creative Commons](../css/cc-by.png)](https://creativecommons.org/licenses/by/4.0)'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '[![Creative Commons](../css/cc-by.png)](https://creativecommons.org/licenses/by/4.0)'
- en: '**Open Access** This chapter is licensed under the terms of the Creative Commons
    Attribution 4.0 International License ([http://​creativecommons.​org/​licenses/​by/​4.​0/​](http://creativecommons.org/licenses/by/4.0/)),
    which permits use, sharing, adaptation, distribution and reproduction in any medium
    or format, as long as you give appropriate credit to the original author(s) and
    the source, provide a link to the Creative Commons license and indicate if changes
    were made.'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '**开放获取**本章根据Creative Commons Attribution 4.0 International License（[http://creativecommons.org/licenses/by/4.0/](http://creativecommons.org/licenses/by/4.0/)）的条款进行许可，允许在任何媒介或格式中使用、分享、改编、分发和复制，只要您适当引用原始作者和来源，提供Creative
    Commons许可的链接，并指出是否进行了更改。'
- en: The images or other third party material in this chapter are included in the
    chapter's Creative Commons license, unless indicated otherwise in a credit line
    to the material. If material is not included in the chapter's Creative Commons
    license and your intended use is not permitted by statutory regulation or exceeds
    the permitted use, you will need to obtain permission directly from the copyright
    holder.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中包含的图片或其他第三方材料均包含在章节的Creative Commons许可证中，除非在材料引用行中另有说明。如果材料未包含在章节的Creative
    Commons许可证中，且您的使用意图不受法定法规允许或超出允许的使用范围，您将需要直接从版权持有人处获得许可。
