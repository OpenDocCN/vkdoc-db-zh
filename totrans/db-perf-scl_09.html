<html><head></head><body><div epub:type="chapter" role="doc-chapter"><div class="ChapterContextInformation"><div class="ContextInformation" id="b978-1-4842-9711-7_10"><div class="ChapterCopyright">© The Author(s) 2023</div><span class="ContextInformationAuthorEditorNames">F. C. Mendes et al.</span><span class="ContextInformationBookTitles"><span class="BookTitle">Database Performance at Scale</span></span><span class="ChapterDOI"><a href="https://doi.org/10.1007/978-1-4842-9711-7_10">https://doi.org/10.1007/978-1-4842-9711-7_10</a></span></div></div><!--Begin Abstract--><div class="MainTitleSection"><h1 class="ChapterTitle" lang="en">10. Monitoring</h1></div><div class="AuthorGroup"><div class="AuthorNames"><span class="Author"><span class="AuthorName">Felipe Cardeneti Mendes</span><sup><a href="#Aff5">1</a> <span class="ContactIcon"> </span></sup>, </span><span class="Author"><span class="AuthorName">Piotr Sarna</span><sup><a href="#Aff6">2</a></sup>, </span><span class="Author"><span class="AuthorName">Pavel Emelyanov</span><sup><a href="#Aff7">3</a></sup> and </span><span class="Author"><span class="AuthorName">Cynthia Dunlop</span><sup><a href="#Aff8">4</a></sup></span></div><div class="Affiliations"><div class="Affiliation" id="Aff5"><span class="AffiliationNumber">(1)</span><div class="AffiliationText">São Paulo, São Paulo, Brazil</div></div><div class="Affiliation" id="Aff6"><span class="AffiliationNumber">(2)</span><div class="AffiliationText">Pruszków, Poland</div></div><div class="Affiliation" id="Aff7"><span class="AffiliationNumber">(3)</span><div class="AffiliationText">Moscow, Russia</div></div><div class="Affiliation" id="Aff8"><span class="AffiliationNumber">(4)</span><div class="AffiliationText">Carpinteria, CA, USA</div></div><div class="ClearBoth"> </div></div></div><div class="ArticleOrChapterToc"><div class="TocLine"><a href="#Sec1">Taking a Proactive Approach</a></div><div class="TocLine"><a href="#Sec2">Tracking Core Database KPIs</a></div><div class="TocLine"><a href="#Sec8">Creating Effective Custom Alerts</a></div><div class="TocLine"><a href="#Sec9">Walking Through Sample Scenarios</a></div><div class="TocLine"><a href="#Sec12">Monitoring Options</a></div><div class="TocLine"><a href="#Sec17">Summary</a></div></div><!--End Abstract--><div class="Fulltext">
        <p class="Para" id="Par2">Databases require ongoing care and attention, especially when performance is a priority and the data being stored is growing rapidly and/or changing frequently. Adverse events that could place the business at risk—for example, node failures or a misbehaving client—will inevitably occur. Given the complexity of both databases and data-intensive applications, it’s not a matter of <em class="EmphasisTypeItalic ">if</em> some combination of factors ends up degrading performance, but <em class="EmphasisTypeItalic ">when</em>.</p>
        <p class="Para" id="Par3">Enter observability and monitoring. A <span id="ITerm1">proactive approach</span> is the key to understanding and optimizing your baseline performance, catching emerging issues before your end-users feel the pain, and reacting fast when they do. This chapter helps you determine where to focus your monitoring efforts—with examples from different use cases—offers tips for exploring issues as they emerge, and details how you might proceed when your <span id="ITerm2">key performance indicators (KPIs)</span> are trending in the wrong direction.</p>
        <section class="Section1 RenderAsSection1" id="Sec1">
          <h2 class="Heading">Taking a Proactive Approach</h2>
          <p class="Para" id="Par4">Monitoring often doesn’t become a priority until something goes wrong. Users start complaining about slowness, the system runs out of <span id="ITerm3">space</span>, or your application simply stops responding.</p>
          <p class="Para" id="Par5">At that point, monitoring is a vital tool for digging into the problem, understanding the root cause, and hopefully verifying that your mitigation attempts were successful. Having insightful monitoring and knowing what to look for is invaluable at this point. But what’s even more helpful is the knowledge gained by monitoring performance over time, even when everything was humming along nicely.</p>
          <p class="Para" id="Par6">If you have a good grasp of how your database generally behaves when it works well, it’s much easier to spot the problem when it’s unhealthy. For example, if you see a spike in request concurrency but you know that your system always properly applies a concurrency limiter, then you might focus your investigation on background operations that may be slowing down your database. Or, maybe your application got scaled out to handle more traffic, therefore breaking your previous client-side assumptions.</p>
          <p class="Para" id="Par7">Monitoring trends over time can also help you predict and plan for peaks. For instance, assume you’re a streaming media company. If you know that last year’s version of a big sporting event drew over 25M active users when you had 250M subscribers, you can use that data to make some predictions as to how much traffic you might need to <span id="ITerm4">support</span> this year—now that you have almost twice as many subscribers. It’s a similar case for retail, fraud detection, or any other industry that experiences “Black Friday” surges. One of the best ways to prepare for the next peak is to understand what happened during the previous one.</p>
          <p class="Para" id="Par8">Making monitoring a regular routine rather than an emergency response can also help you spot potential issues as they emerge—and avoid them causing a crisis. For example, one of the most common database mistakes is failing to carefully watch disk utilization. By the time you realize that the system is running out of storage space, it might be too late to respond.</p>
          <p class="Para" id="Par9">As a nice side effect, monitoring can also provide a window into how your data and application usage are evolving. For example, if you note a steady increase in data volume and/or IOPs, you might consider benchmarking your database against what’s feasible in the next year. Maybe you’re already built for that scale, or maybe you need to think about your options for increasing capacity. Additionally, assessing what’s required to achieve the expected latencies at the likely new scale also helps you predict and plan for the associated cost increase.</p>
          <div class="FormalPara FormalParaRenderingStyle1 ParaTypeImportant" id="FPar1">
            <div class="Heading">Note: Do You Need to Monitor a DBaaS?</div>
            <p class="Para FirstParaInFormalPara" id="Par10">You selected a DBaaS because you didn’t want to worry about your database, right? So does that mean you don’t have to worry about monitoring? Yes … and no.</p>
            <p class="Para" id="Par11">You <em class="EmphasisTypeItalic ">should</em> rest assured that your vendor of choice is carefully watching over your instance with a great deal of automation as well as expertise. If you’re not confident that this is the case, you might want to consider rethinking your DBaaS vendor. But even if you <em class="EmphasisTypeItalic ">are</em> confident, it’s still advisable to keep a close eye on database performance. To earn and retain your trust, your DBaaS vendor should offer full transparency into what they’re monitoring. At a minimum, you should understand:</p>
          </div>
          <div class="Para" id="Par12"><div class="UnorderedList"><ul class="UnorderedListMarkBullet"><li>
              <p class="Para ParaTypeImportant" id="Par13">Which KPIs are correlated to your team’s greatest performance concerns</p>
            </li><li>
              <p class="Para ParaTypeImportant" id="Par14">What triggers them to review KPIs, take action internally, and notify you of an issue</p>
            </li><li>
              <p class="Para ParaTypeImportant" id="Par15">What level of effort they make in order to guarantee these KPIs</p>
              <p class="Para ParaTypeImportant" id="Par16">It’s probably overkill to keep a DBaaS monitoring dashboard open on one of your monitors 24/7. But at least know enough for a basic level of confidence that your database—and your DBaaS vendor—are both doing their job.</p>
            </li></ul></div></div>
        </section>

        <section class="Section1 RenderAsSection1" id="Sec2">
          <h2 class="Heading">Tracking Core Database KPIs</h2>
          <p class="Para" id="Par17">Less is more when you’re tracking database KPIs. We recommend zeroing in on a small set of KPIs in each area (cluster, infrastructure, application) that really matter to your business. Then, showcase those core KPIs prominently in a dashboard and set alerts to trigger when they reach levels that you believe warrant an immediate response. Be brutally honest here. It’s much better to have one custom alert you’ll really act on than 30 you’ll ignore. If you won’t address it immediately, it’s “noise” that will desensitize the team to even the most critical issues.</p>
          <p class="Para" id="Par18">What about all other KPIs? They’ll be key when it’s time to a) optimize your baseline performance, b) see what’s needed to maintain that performance at a greater scale, or c) diagnose an emerging performance issue.</p>
          <p class="Para" id="Par19">Rather than try to cover every KPI for every popular <span id="ITerm5">high-performance database</span>, let’s take a critical look at what we’ve found are the most common and critical ones for meeting throughput and latency expectations.</p>
          <section class="Section2 RenderAsSection2" id="Sec3">
            <h3 class="Heading">Database Cluster KPIs</h3>
            <p class="Para" id="Par20">These are metrics that provide insight into a <span id="ITerm6">database cluster’s</span> health. This bucket might cover things like <span id="ITerm7">I/O queues</span>, task groups, internal errors, reads/writes, timeouts and errors, replicas, cache, and change data capture.</p>
            <div class="Para" id="Par21">The ultimate goal of monitoring a cluster is to ensure a steady state “healthy system.” Before looking at specific KPIs, consider what an ideal cluster state looks like for your database. For example, with a wide <span id="ITerm8">column database</span> like <span id="ITerm9">ScyllaDB</span> or Cassandra, your target might be:<div class="UnorderedList"><ul class="UnorderedListMarkBullet"><li>
                <p class="Para" id="Par22">All nodes are up and running</p>
              </li><li>
                <p class="Para" id="Par23">There are no alerts indicating that a KPI you care about has exceeded the acceptable threshold</p>
              </li><li>
                <div class="Para" id="Par24">Clients are driving traffic to all nodes and shards in a balanced manner<div class="UnorderedList"><ul class="UnorderedListMarkBullet"><li>
                    <p class="Para" id="Par25">Connections are balanced (your driver might balance them automatically)</p>
                  </li><li>
                    <p class="Para" id="Par26">The amount of traffic to the various shards is roughly the same</p>
                  </li><li>
                    <p class="Para" id="Par27">The queries are spread out across the shards</p>
                  </li></ul></div></div>
              </li><li>
                <p class="Para" id="Par28">Requests for a partition/row are balanced (e.g., you don’t have a “hot partition” with 50 percent of read requests going to a single partition)</p>
              </li><li>
                <p class="Para" id="Par29">Partitions are balanced (e.g., you don’t have an average partition size of .5 MB and a few partitions that are 10GB)</p>
              </li><li>
                <p class="Para" id="Par30">The cache hit rate (rows read from the cache) follows a specific distribution pattern</p>
              </li><li>
                <p class="Para" id="Par31">Disk utilization has enough room to accommodate growth and other background <span id="ITerm10">operations</span>, such as compactions</p>
              </li></ul></div></div>
            <div class="Para" id="Par32">Here are some specific KPIs to look into regarding your cluster health:<div class="UnorderedList"><ul class="UnorderedListMarkBullet"><li>
                <p class="Para" id="Par33"><span id="ITerm11"><strong class="EmphasisTypeBold ">Node availability</strong></span>: Indicates if a node is online and responding through liveness checks. This can be used to assess whether the node is available on the network and to the rest of the cluster. If the cluster has one or more nodes that are unavailable, this means that the cluster has fewer resources to process its workload, which could result in increased latencies. Note that just because a node is available does not necessarily mean it is healthy.</p>
              </li><li>
                <p class="Para" id="Par34"><strong class="EmphasisTypeBold ">Average read/write latencies</strong>: Tells you the average latencies per operation type. This is a good way of knowing how your cluster delivers part of the <span id="ITerm12">requests</span>, but there is more than meets the eye when you inspect it closely (for example, P99 latencies).</p>
              </li><li>
                <p class="Para" id="Par35"><strong class="EmphasisTypeBold ">P99 read/write latencies</strong>: Provides insight into the latency of the 99th percentile of requests in your cluster. Most performance-sensitive use cases aim at keeping P99 latencies (and sometimes P999 latencies) within acceptable ranges for the business case.</p>
              </li><li>
                <p class="Para" id="Par36"><strong class="EmphasisTypeBold ">Requests per second</strong>: Specifies how many <span id="ITerm13">operations per second</span> your database is processing. This KPI, along with latency, is crucial to assess how the cluster processes the intended workloads. A sudden drop in throughput might indicate a network failure, misbehaving clients, or simply when a given high throughput workload processing finished.</p>
              </li><li>
                <p class="Para" id="Par37"><strong class="EmphasisTypeBold ">Timeouts</strong>: Reveals if any timeouts have recently occurred on the cluster. A timeout is not a bad sign per <span id="ITerm14">se</span>. But the team might want to consider how to tackle them from the application side and how to stop timeouts from becoming common on a busy system. A cluster’s timeout rates will usually spike when it is malfunctioning.</p>
              </li><li>
                <p class="Para" id="Par38"><strong class="EmphasisTypeBold ">Caching</strong>: This can vary from how much data your cache contains to how much <span id="ITerm15">data</span> is being read from the cache (as opposed to the disk). The latter measurement will help you assess how the database is using its caching system and if any tuning is required for it. It could also explain some latency spikes, which would be correlated to reads primarily hitting the disk.</p>
              </li><li>
                <p class="Para" id="Par39"><strong class="EmphasisTypeBold ">Connections</strong>: It is crucial to understand how your database is being accessed over the network. Knowing how many connections are currently active on the database can help you gauge application connectivity issues and understand if connections are balanced throughout the cluster (to catch whether a node is malfunctioning or overloaded).</p>
              </li><li>
                <p class="Para" id="Par40"><span id="ITerm16"><strong class="EmphasisTypeBold ">Garbage Collector (GC)</strong></span><span id="ITerm17"/> <strong class="EmphasisTypeBold ">pauses</strong>: If you’re using a database that requires GC pauses to purge unused memory objects, pay close attention to how GC pauses may be affecting your latencies and throughput. In general, a GC pause is a small fraction of time when a database is unavailable to process its work. That means that long GC pauses may be wasting resources and hurting your workload.</p>
              </li></ul></div></div>
            <section class="Section3 RenderAsSection3" id="Sec4">
              <h4 class="Heading">What to Look for at Different Levels (Datacenter, Node, CPU/Shard)</h4>
              <p class="Para" id="Par41">Monitoring solutions will typically provide different views of your distributed topology. For example, a global view of your P99 latencies within a multi-regional active-active deployment will quickly help you identify whether your entire infrastructure is stable and operational. However, when things go wrong, you may need a different level of granularity in order to identify the culprit.</p>
              <p class="Para" id="Par42">The higher the level of detail you choose, the more data points and information you will have. However, it is not always a good idea to navigate through your monitoring solution with a high level of detail until you identify possible suspects.</p>
              <p class="Para" id="Par43">When investigating an unknown problem, we recommend that you initiate your research with the datacenter-level view if you have a multi-regional topology. This allows you to isolate whether a problem is specifically confined to a single region or whether the problem in question affects all regions.</p>
              <p class="Para" id="Par44">Once you have isolated the impacted location, the next step is to look into the data points on a per-node level. This will reveal whether any specific replica may be misbehaving, receiving more requests, experiencing an imbalance, or suffering from higher latencies than the others.</p>
              <p class="Para" id="Par45">For most databases, a per-node view is the lowest possible level. However, databases with a shard-per-core architecture offer an additional granularity: the CPU level. Switching your observability to the <span id="ITerm18">CPU level</span> makes sense once you have identified the main suspects of your performance problem. Otherwise, it will simply show you too many data points that might look unintelligible at first glance. However, when used properly, a per-CPU level view can greatly empower your observability and troubleshooting skills.</p>
            </section>

            <section class="Section3 RenderAsSection3" id="Sec5">
              <h4 class="Heading">Three Industry-Specific Examples</h4>
              <div class="Para" id="Par46">Here are a few examples of how cluster monitoring approaches vary across industries and use <span id="ITerm19">cases</span>:<div class="UnorderedList"><ul class="UnorderedListMarkBullet"><li>
                  <p class="Para" id="Par47"><strong class="EmphasisTypeBold ">AdTech</strong>: <span id="ITerm20">AdTech</span> is one of the most recognizable use cases that relies heavily on sub-millisecond latencies. For example, in real-time bidding, a single millisecond spike might be all it takes to miss a targeted ad opportunity. As a result, these use cases often monitor P99, P999, and even P9999 latencies and set up very aggressive custom alerting thresholds so that spikes can be identified and addressed immediately.</p>
                </li><li>
                  <p class="Para" id="Par48"><strong class="EmphasisTypeBold ">Streaming media</strong>: <span id="ITerm21">Streaming media</span> use cases typically serve several distinct media types across several tenants, often through different regions. At a region, data balancing is critical since a single bottlenecked shard can introduce a widespread impact.</p>
                </li><li>
                  <p class="Para" id="Par49"><strong class="EmphasisTypeBold ">Blockchain</strong>: <span id="ITerm22">Blockchain</span><span id="ITerm23"/> solutions are typically required to store, compute, and analyze large amounts of data. As the blockchain in question grows, tracking the history of transactions at fast speeds may become very challenging. This specific use case focuses on two main drivers: storage growth and disk I/O performance.</p>
                </li></ul></div></div>
            </section>

          </section>

          <section class="Section2 RenderAsSection2" id="Sec6">
            <h3 class="Heading">Application KPIs</h3>
            <p class="Para" id="Par50">Your distributed database is the single most important stateful component in your <span id="ITerm24">infrastructure</span>. It is therefore no surprise that many database vendors invest a lot of time and effort into improving and bundling observability capabilities within their products. However, monitoring a database alone can only do so much. There will always be an application (or an entire infrastructure) behind it which, if not observed properly, may cause important business impacts. Application KPIs are the key to exposing things like query issues, poor data models, and unexpected driver behavior.</p>
            <div class="Para" id="Par51">Here are some important KPIs to look into regarding your application (client side):<div class="UnorderedList"><ul class="UnorderedListMarkBullet"><li>
                <p class="Para" id="Par52"><strong class="EmphasisTypeBold ">Latency</strong>: High P99 latency on your client side does not necessarily mean that there’s a problem with your database latency. Client-side latencies will typically be slightly higher than your database latencies due to the natural network round-trip delays involved when communicating to and from your database. However, this metric alone does not help you identify the actual <span id="ITerm25">culprit</span>. Look at whether your application is behaving erratically or whether it is simply bottlenecked (in which case, you can scale it out as necessary).</p>
              </li><li>
                <p class="Para" id="Par53"><strong class="EmphasisTypeBold ">CPU consumption</strong>: High CPU consumption could stem from several causes. Maybe your client is simply overwhelmed, unable to keep up with the pace of incoming requests. Maybe your request balancing is not appropriate. Maybe a “noisy neighbor” is stealing your CPU capacity, among other things. In general, if you suspect that the root cause of the high CPU consumption is due to an inefficiency in your code, you could collect tracepoints on your code or use advanced Heat Map profiling tools, such as perf.<sup><a epub:type="noteref" href="#Fn1" id="Fn1_source" role="doc-noteref">1</a></sup> Otherwise, simply scaling out your application deployments or moving the application to another host might be enough to resolve the problem.</p>
              </li><li>
                <p class="Para" id="Par55"><strong class="EmphasisTypeBold ">Network IRQs</strong>: Applications that need to achieve a high throughput with low latencies can be rather network intensive. As a result, a high network IRQ consumption may prevent your application from fully maximizing the intended rate of requests you initially projected. Use low-level CPU observability tools to check your softirq <span id="ITerm26">consumption</span>, such as the <span class="EmphasisFontCategoryNonProportional ">top</span> and <span class="EmphasisFontCategoryNonProportional ">htop</span> commands available in most Linux platforms. Another mechanism employed to stop IRQs from undermining your performance involves CPU-pinning or simply scaling out your application to run on different host machines.</p>
              </li><li>
                <p class="Para" id="Par56"><strong class="EmphasisTypeBold ">Readiness/liveness</strong>: Any application is prone to bugs and infrastructure failures. Readiness and liveness probes will help you identify when a specific set of your distributed application may start to misbehave and—in many situations—will automatically redeploy or restart the faulty client. Readiness and liveness probes are standard for Kubernetes stateless applications. Whenever your application pods start to misbehave, your Kubernetes controller will typically take action to move it back into a healthy state. Applications that frequently restart due to readiness or liveness problems may indicate problematic logic, a memory leak, or other issues. Check your application or Kubernetes logs for more details on the actual cause of such events.</p>
              </li><li>
                <p class="Para" id="Par57"><strong class="EmphasisTypeBold ">GC pauses</strong>: Many applications are developed in programming languages that experience garbage collection pauses while freeing up memory. Depending on its aggressiveness, it can cause CPU spikes (preventing your application from keeping up with its incoming rate) or introduce severe latency spikes. It indicates either a problematic memory <span id="ITerm27">management</span> algorithm, or an inefficiency with your garbage collector overall. Consider spreading out your application to run with more independent clients and see if that improves the situation.</p>
              </li></ul></div></div>
          </section>

          <section class="Section2 RenderAsSection2" id="Sec7">
            <h3 class="Heading">Infrastructure/Hardware KPIs</h3>
            <p class="Para" id="Par58">Keeping an eye on the database and application sounds reasonable, but what about the underlying hardware and infrastructure? Keeping it all healthy and humming is the top priority of infrastructure teams. After all, what good does tuning and monitoring a database do if the server that powers it goes offline due to a weeks-long malfunction that went unnoticed?</p>
            <div class="Para" id="Par59">Here are the top <span id="ITerm28">infrastructure/hardware</span> KPIs that are relevant from a database perspective:<div class="UnorderedList"><ul class="UnorderedListMarkBullet"><li>
                <p class="Para" id="Par60"><strong class="EmphasisTypeBold ">Disk space utilization</strong>: A database, being a stateful application, certainly has disk space utilization as a top priority KPI. It’s extremely dangerous to have disks reaching full capacity because the database has no option other than to shed requests. A database might even shut itself down to avoid unintentional data loss. Keeping disk utilization well under control is crucial to a healthy, performant database.</p>
              </li><li>
                <p class="Para" id="Par61"><strong class="EmphasisTypeBold ">Disk bandwidth utilization</strong>: Apart from the disk space utilization, monitor how disks are being actively used and performing. In a world of multi-gigabyte RAM, disk bandwidth cannot fall behind; otherwise, you might risk increased <span id="ITerm29">latencies</span> or even a complete failure due to disks being unable to attend to requests within acceptable timeframes.</p>
              </li><li>
                <p class="Para" id="Par62"><strong class="EmphasisTypeBold ">CPU utilization</strong>: This is the one and only metric that counts…or is it? CPU utilization can be looked at from different perspectives. On the one hand, the OS might say that a CPU is 100 percent busy and therefore it has certainly reached its limit and cannot possibly accept more work. Right? Wrong! A busy CPU does not always mean that the system has reached its limits. Databases such as ScyllaDB have internal mechanisms to prioritize user workloads over background internal processes such as compactions and repairs. In such a system, it is actually expected to see CPU utilization at 100 percent most of the time—and it does not mean that the system has reached its limits!</p>
              </li><li>
                <p class="Para" id="Par63"><strong class="EmphasisTypeBold ">Memory utilization</strong>: No one wants to see a database swapping to disk since it can become very detrimental to performance. Heavy memory pressure can trigger your database to crash (or get its process killed) if the underlying operating system runs out of memory. In general, database nodes should be the only memory-hungry resource running on a given server and the system must be configured to avoid swapping unless strictly necessary.</p>
              </li><li>
                <p class="Para" id="Par64"><strong class="EmphasisTypeBold ">Network availability</strong>: A distributed database heavily relies on networking in order to communicate with other nodes to replicate your data, liveness <span id="ITerm30">information</span>, and—at the same time—serve your application queries. Network failures may introduce a split-brain situation, or make node(s) completely inaccessible momentarily, whereas hitting network bandwidth limits may result in additional latency to your workloads.</p>
              </li></ul></div></div>
          </section>

        </section>

        <section class="Section1 RenderAsSection1" id="Sec8">
          <h2 class="Heading">Creating Effective Custom Alerts</h2>
          <p class="Para" id="Par65">Most tools you use to monitor databases provide built-in alerting systems with predefined rules that should meet most users’ needs. But what if you’d sleep better with more specialized monitoring rules and alerts in place?</p>
          <p class="Para" id="Par66">First, start by understanding what you want to monitor, then see how that can be achieved using existing metrics (or a combination of them). After selecting the metric(s) that will drive the custom alert, think about the frequency of <span id="ITerm31">checks</span> and set a threshold for the possible values. For instance, maybe you think that a workload crossing its expected peak for one minute is acceptable, three minutes should trigger warnings, and five minutes indicates something is definitely wrong. Set your monitoring system accordingly and bind the appropriate alerting channels for each type of alert.</p>
          <p class="Para" id="Par67">Also, make good use of alerting channels! Be sure to tag and appropriately direct each level of alert to its own set of target channels. You don’t want the alerting system automation to silently drop a message on a random Slack channel in the middle of the night if the production system is down.</p>
        </section>

        <section class="Section1 RenderAsSection1" id="Sec9">
          <h2 class="Heading">Walking Through Sample Scenarios</h2>
          <p class="Para" id="Par68">To help you see how these principles translate into practice, here are two <span id="ITerm32">sample scenarios</span>.</p>
          <section class="Section2 RenderAsSection2" id="Sec10">
            <h3 class="Heading">One Replica Is Lagging in Acknowledging Requests</h3>
            <div class="Para" id="Par69">Assume that you’re looking at the dashboard in Figure <span class="InternalRef"><a href="#Fig1">10-1</a></span> and notice that one replica is taking much longer than all the others to acknowledge requests. Since the application’s incoming request rate is <span id="ITerm33">constant</span> (you’re not throttling requests), the other replicas will also start suffering after some time.<figure class="Figure" id="Fig1"><div class="MediaObject" id="MO1">
                <img alt="" aria-describedby="d65e1033" src="../images/541783_1_En_10_Chapter/541783_1_En_10_Fig1_HTML.jpg" style="width:42.98em"/><div class="TextObject" id="d65e1033">
                  <p class="Para" id="Par90">A graph of writes per second versus instance. The writes per second range between 14 an d 23.</p>
                </div>
                
              </div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Figure 10-1</span>
                  <p class="SimplePara">One replica taking much longer than all the others to acknowledge requests</p>
                </div></figcaption></figure></div>
            <p class="Para" id="Par70">To see what’s going on here, let’s look at the foreground and background write queues. But first: what’s a foreground and background queue? Foreground queues are requests that the application directed to the specified node, but were not yet acknowledged back to the client. That is, the requests were received, but are waiting to be processed because the database is currently busy serving other requests. Background queues are application requests that were already acknowledged back to the application, but still require additional work in the database before they can be considered done. Delays replicating data across nodes are typically the reason for high background queues. High foreground and background queues both correlate with high latencies.</p>
            <div class="Para" id="Par71">So what’s the true problem here? Figure <span class="InternalRef"><a href="#Fig2">10-2</a></span> indicates that the application is overloading the system. It’s sending more requests than the database can handle. And since the running time of a single task in a distributed system is governed by the slowest node, the entire system will throttle down to the speed of that slow node.<figure class="Figure" id="Fig2"><div class="MediaObject" id="MO2">
                <img alt="" aria-describedby="d65e1065" src="../images/541783_1_En_10_Chapter/541783_1_En_10_Fig2_HTML.jpg" style="width:42.82em"/><div class="TextObject" id="d65e1065">
                  <p class="Para" id="Par91">A line graph of foreground writes per instance from 0 to 200 versus time from 18 : 30 hours to 19 : 55 hours. Most of the lines are below 40 writes per instance.</p>
                </div>
                
              </div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Figure 10-2</span>
                  <p class="SimplePara">Foreground writes per shard</p>
                </div></figcaption></figure></div>
            <div class="Para" id="Par72">Figure <span class="InternalRef"><a href="#Fig3">10-3</a></span> shows that the background queues in other nodes start climbing right <span id="ITerm34">after</span> one node gets overwhelmed with requests it can’t handle. This makes sense, because the busy node is clearly taking longer to acknowledge requests sent to it.<figure class="Figure" id="Fig3"><div class="MediaObject" id="MO3">
                <img alt="" aria-describedby="d65e1099" src="../images/541783_1_En_10_Chapter/541783_1_En_10_Fig3_HTML.jpg" style="width:42.82em"/><div class="TextObject" id="d65e1099">
                  <p class="Para" id="Par92">A line graph of background writes per instance from 0 to 17.5 versus time from 18 : 30 hours to 19 : 55 hours. Most of the lines are below 15 writes per instance.</p>
                </div>
                
              </div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Figure 10-3</span>
                  <p class="SimplePara">Background writes per shard</p>
                </div></figcaption></figure></div>
            <p class="Para" id="Par73">There are a couple of options for resolving this. First, consider modifying the application to throttle requests. If you can’t do that, then scale out the cluster to give it more capacity.</p>
          </section>

          <section class="Section2 RenderAsSection2" id="Sec11">
            <h3 class="Heading">Disappointing P99 Read Latencies</h3>
            <div class="Para" id="Par74">Assume that you’re looking at the dashboard shown in Figure <span class="InternalRef"><a href="#Fig4">10-4</a></span> and notice that the read latencies seem disappointing. The <span id="ITerm35">P99 read latency</span><span id="ITerm36"/> is 40ms most of the time, with a spike above 100ms under some circumstances. What’s going on here?<figure class="Figure" id="Fig4"><div class="MediaObject" id="MO4">
                <img alt="" aria-describedby="d65e1144" src="../images/541783_1_En_10_Chapter/541783_1_En_10_Fig4_HTML.jpg" style="width:42.82em"/><div class="TextObject" id="d65e1144">
                  <p class="Para" id="Par93">A line graph of read latency by instance from 0 to 120 milliseconds versus time from 20 : 05 hours to 21 : 05 hours. The highest latency is 112 at around 20 : 48 hours.</p>
                </div>
                
              </div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Figure 10-4</span>
                  <p class="SimplePara">Disappointing P99 read latencies</p>
                </div></figcaption></figure></div>
            <div class="Para" id="Par75">To analyze this, let’s look at the internal cache metrics. The Reads with Misses graph in Figure <span class="InternalRef"><a href="#Fig5">10-5</a></span> shows that the <span id="ITerm37">reads</span> aren’t hitting the cache—they’re all going to disk instead. Fetching information from the disk is an order of magnitude slower than doing so from memory. At this point, you know something weird is going on.<figure class="Figure" id="Fig5"><div class="MediaObject" id="MO5">
                <img alt="" aria-describedby="d65e1183" src="../images/541783_1_En_10_Chapter/541783_1_En_10_Fig5_HTML.jpg" style="width:42.82em"/><div class="TextObject" id="d65e1183">
                  <p class="Para" id="Par94">A line graph of reads with misses from 0 to 70 versus time from 20 : 05 hours to 21 : 05 hours. It starts from 0 then rises to around 65, becomes almost flat till 21 : 05 hours and then drops to 0.</p>
                </div>
                
              </div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Figure 10-5</span>
                  <p class="SimplePara">Database reads with cache misses; reads are going to disk instead of <span id="ITerm38">cache</span></p>
                </div></figcaption></figure></div>
            <div class="Para" id="Par76">Similarly, Figure <span class="InternalRef"><a href="#Fig6">10-6</a></span> shows the cache hits. You can see that almost no requests are being served by the cache. This is a likely indication that the workload in question heavily relies on reading cold (uncached<span id="ITerm39"/>) data.<figure class="Figure" id="Fig6"><div class="MediaObject" id="MO6">
                <img alt="" aria-describedby="d65e1216" src="../images/541783_1_En_10_Chapter/541783_1_En_10_Fig6_HTML.jpg" style="width:42.82em"/><div class="TextObject" id="d65e1216">
                  <p class="Para" id="Par95">A line graph of reads with no misses from 0 to 500 versus time from 20 : 05 hours to 21 : 05 hours. It starts from around 10 then rises sharply to around 500, and then drops sharply to around 10.</p>
                </div>
                
              </div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Figure 10-6</span>
                  <p class="SimplePara">Database reads with cache hits</p>
                </div></figcaption></figure></div>
            <div class="Para" id="Par77">To investigate further, look at the Active SSTable Reads graph in Figure <span class="InternalRef"><a href="#Fig7">10-7</a></span>. Here, you can see that the amount of active read requests going to the disk is quite high.<figure class="Figure" id="Fig7"><div class="MediaObject" id="MO7">
                <img alt="" aria-describedby="d65e1250" src="../images/541783_1_En_10_Chapter/541783_1_En_10_Fig7_HTML.jpg" style="width:42.82em"/><div class="TextObject" id="d65e1250">
                  <p class="Para" id="Par96">A line graph of active S S table reads from 0 to 200 versus time from 20 : 05 hours to 21 : 05 hours. Most of the reads are between 30 and 150.</p>
                </div>
                
              </div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Figure 10-7</span>
                  <p class="SimplePara">Active SSTable Reads graph showing that the amount of active read requests going to the disk is quite <span id="ITerm40">high</span></p>
                </div></figcaption></figure></div>
            <div class="Para" id="Par78">On the Queued Reads graph in Figure <span class="InternalRef"><a href="#Fig8">10-8</a></span>, you can see there’s a bit of queuing. This queuing means that the underlying storage system can’t keep up with the request rate. Requests need to wait longer before being served—and latency <span id="ITerm41">increases</span>.<figure class="Figure" id="Fig8"><div class="MediaObject" id="MO8">
                <img alt="" aria-describedby="d65e1285" src="../images/541783_1_En_10_Chapter/541783_1_En_10_Fig8_HTML.jpg" style="width:42.82em"/><div class="TextObject" id="d65e1285">
                  <p class="Para" id="Par97">A line graph of queued reads from 0 to 3.5 versus time from 20 : 05 hours to 21 : 05 hours. Most of the reads are between 0 and 1.</p>
                </div>
                
              </div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Figure 10-8</span>
                  <p class="SimplePara">Queued Reads graph demonstrates that several requests are getting queued</p>
                </div></figcaption></figure></div>
            <p class="Para" id="Par79">How do you resolve this? Review your queries and access patterns to use the cache more efficiently. This is where query analysis is helpful. For example, with CQL, you could look at the distribution of inserts, reads, deletes, and updates, the number of connections per node or <span id="ITerm42">shard</span>, and how many rows you’re currently reading. If available, also check whether your queries are following the relevant best practices (for CQL, this could be using prepared statements, token-aware queries, paged queries, and so on).</p>
            <div class="Para" id="Par80">Also, watch out for queries that require nodes across datacenters to participate before requests are considered successful. Cross-datacenter traffic is usually more expensive in terms of latencies and actual cost. Figure <span class="InternalRef"><a href="#Fig9">10-9</a></span> shows an example of how to identify queries traversing to remote regions.<figure class="Figure" id="Fig9"><div class="MediaObject" id="MO9">
                <img alt="" aria-describedby="d65e1327" src="../images/541783_1_En_10_Chapter/541783_1_En_10_Fig9_HTML.jpg" style="width:42.82em"/><div class="TextObject" id="d65e1327">
                  <p class="Para" id="Par98">A graph of cross data center queries per second versus time from 20 : 05 hours to 21 : 05 hours. The cross data line starts from 0, rises sharply to around 32, becomes stable till 21 : 00 hours and then drops sharply to 0.</p>
                </div>
                
              </div><figcaption class="Caption" lang="en"><div class="CaptionContent"><span class="CaptionNumber">Figure 10-9</span>
                  <p class="SimplePara">Tracking cross-datacenter traffic, which is usually more expensive in terms of latencies and <span id="ITerm43">cost</span></p>
                </div></figcaption></figure></div>
          </section>

        </section>

        <section class="Section1 RenderAsSection1" id="Sec12">
          <h2 class="Heading">Monitoring Options</h2>
          <p class="Para" id="Par81">Once you have a good grasp of what you’re looking for, how do you find it? There are a number of tools and technologies available; here’s a quick rundown of the pros and cons of common options.</p>
          <section class="Section2 RenderAsSection2" id="Sec13">
            <h3 class="Heading">The Database Vendor’s Monitoring Stack</h3>
            <p class="Para" id="Par82">Under most <span id="ITerm44">circumstances</span>, your database’s bundled monitoring solution should be sufficient for gaining insight into how the database is performing. It is typically the recommended solution for a number of reasons. Since it was engineered by your vendor, it likely contains many of the details you should care about the most. Moreover, if you turn to your vendor with a performance problem that you’re unable to diagnose on your own, the vendor is likely to request visibility through their provided solution. For that reason, we recommend that you always deploy your vendor’s monitoring stack—even if you plan to use another solution you prefer.</p>
          </section>

          <section class="Section2 RenderAsSection2" id="Sec14">
            <h3 class="Heading">Build Your Own Dashboards and Alerting (Grafana, Grafana Loki)</h3>
            <p class="Para" id="Par83">What if the vendor-provided monitoring stack doesn’t allow you customization options and the ability to create additional monitors that could yield additional insight into your use case, application, or database? In this case, it’s great to have the flexibility of going open-source to build your own monitoring <span id="ITerm45">stack</span> by stitching together every monitor and chart that you need.</p>
            <p class="Para" id="Par84">Just keep in mind that a vendor’s monitoring system is usually tuned to provide valuable metrics that are commonly used during troubleshooting. It’s still important to keep that foundation operational alongside the additional monitoring options you and your team decide to use.</p>
          </section>

          <section class="Section2 RenderAsSection2" id="Sec15">
            <h3 class="Heading">Third-Party Database Monitoring Tools</h3>
            <p class="Para" id="Par85">Some teams might already be using a <span id="ITerm46">database monitoring tool</span> that’s built and maintained by someone other than their database vendor. If it’s a tool you’re already familiar with, you get the benefit of working with a familiar solution that’s probably already integrated into your existing monitoring framework. However, you might need to manually build and track all the relevant dashboards you want, which can be tedious and time-consuming. Other potential drawbacks of implementing a third-party monitoring tool can be the lack of vendor support and the risk of your dashboards becoming obsolete whenever your vendor implements a new metric or changes the meaning of a metric.</p>
          </section>

          <section class="Section2 RenderAsSection2" id="Sec16">
            <h3 class="Heading">Full Stack Application Performance Monitoring (APM) Tool</h3>
            <p class="Para" id="Par86">A <span id="ITerm47">full-stack APM system</span><span id="ITerm48"/> collects remote metrics and aggregates them in a central solution that provides insight across different types of services and products. An organization might use an APM tool for a global view of all assets, services, and nodes across a portfolio. It is the preferred way for larger companies to manage infrastructure, and it certainly has its benefits. It’s usually serverless and only a client is required to push information to the centralized service.</p>
            <p class="Para" id="Par87">However, a centralized solution requires a subscription and constant internet access. You might also be charged per device and have less flexibility on how to customize metrics collection, create panels and alerts, and so on. APM platforms usually offer a wide range of plugins that can be tailor-made to monitor products. But not all of them are created the same, so your mileage may vary.</p>
            <p class="Para" id="Par88">Teams often ask if their favorite observability solution can impact their performance. Yes, it can. We have learned from experience that some observability or monitoring solutions, especially those that require an agent to be installed on top of your database <span id="ITerm49">nodes</span>, may introduce performance problems. In one extreme example, we saw an agent totally hanging the database process, introducing a real business outage. Whenever installing third-party solutions that could directly interact with your database process, ensure that you first consult with your vendor about its compatibility and support.</p>
          </section>

        </section>

        <section class="Section1 RenderAsSection1" id="Sec17">
          <h2 class="Heading">Summary</h2>
          <p class="Para" id="Par89">This chapter began by recommending that you make monitoring a regular habit so that you’re well-prepared to spot emerging issues and effectively diagnose the problem when something goes wrong. It outlined a number of KPIs that have proven helpful for tracking business-critical enterprise deployments. For each KPI, it explained what to look for and offered some tips for how to react when the trends indicate a problem. The chapter offered some high-level guidelines for creating custom alerts. Finally, we walked through two sample monitoring scenarios and shared our take on the pros and cons of different monitoring platform options. The next (and final) chapter looks at the performance impacts of common admin operations and offers some tips on how you might mitigate them.</p>
        </section>

      <div class="License LicenseSubType-cc-by"><a href="https://creativecommons.org/licenses/by/4.0"><img alt="Creative Commons" src="../css/cc-by.png"/></a>
            <p class="SimplePara"><strong class="EmphasisTypeBold ">Open Access</strong> This chapter is licensed under the terms of the Creative Commons Attribution 4.0 International License (<span class="ExternalRef"><a href="http://creativecommons.org/licenses/by/4.0/"><span class="RefSource">http://​creativecommons.​org/​licenses/​by/​4.​0/​</span></a></span>), which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license and indicate if changes were made.</p>
            <p class="SimplePara">The images or other third party material in this chapter are included in the chapter's Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the chapter's Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder.</p>
          </div><aside aria-label="Footnotes" class="FootnoteSection" epub:type="footnotes"><div class="Heading">Footnotes</div><div class="Footnote"><span class="FootnoteNumber"><a href="#Fn1_source">1</a></span><div class="FootnoteContent" epub:type="footnote" id="Fn1" role="doc-footnote"><p class="Para" id="Par54">See <span class="ExternalRef"><a href="http://www.brendangregg.com/blog/2014-07-01/perf-heat-maps.html"><span class="RefSource"><span class="EmphasisFontCategoryNonProportional ">www.brendangregg.com/blog/2014-07-01/perf-heat-maps.html</span></span></a></span>.</p></div><div class="ClearBoth"> </div></div></aside></div></div></body></html>