- en: 5. Database Drivers
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 5. 数据库驱动程序
- en: '[Relationship Between Clients and Servers](#Sec1)[Timeouts](#Sec7)[Contextual
    Awareness](#Sec11)[Query Locality](#Sec15)[Retries](#Sec16)[Paging](#Sec20)[Concurrency](#Sec21)[What
    to Look for When Selecting a Driver](#Sec24)[Summary](#Sec25)'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '[客户端与服务器之间的关系](#Sec1)[超时](#Sec7)[上下文感知](#Sec11)[查询局部性](#Sec15)[重试](#Sec16)[分页](#Sec20)[并发](#Sec21)[选择驱动程序时要注意的事项](#Sec24)[总结](#Sec25)'
- en: Databases usually expose a specific communication protocol for their users.
    This protocol is the foundation of communication between clients and servers,
    so it’s often well-documented and has a formal specification. Some databases,
    like PostgreSQL, implement their own binary format on top of the TCP/IP stack.^([1](#Fn1))
    Others, like Amazon DynamoDB,^([2](#Fn2)) build theirs on top of HTTP, which is
    a little more verbose, but also more versatile and compatible with web browsers.
    It’s also not uncommon to see a database exposing a protocol based on gRPC^([3](#Fn3))
    or any other well-established framework.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 数据库通常为用户提供特定的通信协议。这个协议是客户端和服务器之间通信的基础，因此它通常有很好的文档记录和正式规范。一些数据库，如PostgreSQL，在TCP/IP堆栈之上实现自己的二进制格式。[1](#Fn1)
    其他数据库，如Amazon DynamoDB，[2](#Fn2) 则在其之上构建，基于HTTP，这比HTTP更冗长，但更灵活，也与网络浏览器兼容。也可以看到数据库公开基于gRPC[3](#Fn3)
    或任何其他已建立框架的协议。
- en: Regardless of the implementation details, users seldom use the bare protocol
    themselves because it’s usually a fairly low-level API. What’s used instead is
    a *driver*—a programming interface written in a particular language, implementing
    a higher-level abstraction for communicating with the database. Drivers hide all
    the nitty-gritty details behind a convenient interface, which saves users from
    having to manually handle connection management, parsing, validation, handshakes,
    authentication, timeouts, retries, and so on.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 无论实现细节如何，用户很少直接使用裸协议，因为这通常是一个相当低级的API。取而代之的是使用一个**驱动程序**——用特定语言编写的编程接口，它实现了与数据库通信的高级抽象。驱动程序隐藏了所有繁琐的细节，通过一个方便的接口提供给用户，从而节省了用户手动处理连接管理、解析、验证、握手、身份验证、超时、重试等工作。
- en: In a distributed environment (which a scalable database cluster usually is),
    clients, and therefore drivers, are an extremely important part of the ecosystem.
    The clients are usually the most numerous group of actors in the system, and they
    are also very heterogeneous in nature, as visualized in Figure [5-1](#Fig1). Some
    clients are connected via local network interfaces, other ones connect via a questionable
    Wi-Fi hotspot on another continent and thus have vastly different latency characteristics
    and error rates. Some might run on microcontrollers with 1MiB of random access
    memory, while others utilize 128-core bare metal machines from a cloud provider.
    Due to this diversity, it’s very important to take drivers into consideration
    when thinking about performance, scalability, and resilience to failures. Ultimately
    it’s the drivers that generate traffic and its concurrency, so cooperation between
    them and database nodes is crucial for the whole system to be healthy and efficient.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在分布式环境中（可扩展的数据库集群通常是这样的），客户端和因此驱动程序是生态系统中的极其重要的一部分。客户端通常是系统中数量最多的参与者群体，它们在本质上也非常异质，如图[5-1](#Fig1)所示。一些客户端通过本地网络接口连接，其他一些通过另一个大陆上的可疑Wi-Fi热点连接，因此具有截然不同的延迟特性和错误率。一些可能在具有1MiB随机存取内存的微控制器上运行，而其他一些则利用云提供商的128核心裸机。由于这种多样性，在考虑性能、可扩展性和对失败的恢复能力时，考虑驱动程序非常重要。最终，是驱动程序生成流量及其并发性，因此它们与数据库节点之间的合作对于整个系统保持健康和高效至关重要。
- en: Note
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: As a reminder, *concurrency*, in the context of this book, is the measure of
    how many operations are performed at the same point in time. It’s conceptually
    similar to parallelism. With concurrency, the operations occur physically at the
    same time (e.g. on multiple CPU cores or multiple machines). Parallelism does
    not specify that; the operations might just as well be executed in small steps
    on a single machine. Nowadays, distributed systems must rely on providing high
    concurrency in order to remain competitive and catch up with ever-developing technology.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 作为提醒，本书中提到的**并发**是指在同一时间点执行的操作数量。从概念上讲，它与并行性相似。在并发的情况下，操作在物理上是同时发生的（例如，在多个CPU核心或多台机器上）。并行性并不指定这一点；操作也可以在单台机器上以小步骤执行。如今，分布式系统必须依赖提供高并发性以保持竞争力并赶上不断发展的技术。
- en: This chapter takes a look at how drivers impact performance—through the eyes
    of someone who has engineered drivers for performance. It provides insight into
    various ways that drivers can support efficient client-server interactions and
    shares tips for getting the most out of a driver, particularly from the performance
    perspective. Finally, the chapter wraps up with several considerations to keep
    in mind as you’re selecting a driver.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 本章探讨了驱动程序如何影响性能——通过那些为性能而设计驱动程序的人的眼睛。它提供了关于驱动程序如何支持高效的客户端-服务器交互的见解，并分享了如何充分利用驱动程序的建议，尤其是从性能的角度来看。最后，本章总结了在选择驱动程序时需要考虑的几个要点。
- en: Relationship Between Clients and Servers
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 客户端与服务器之间的关系
- en: Scalability is a measure of how well your system reacts to increased load. This
    load is usually generated by clients using their drivers, so keeping the relationship
    between your clients and servers sound is an important matter. The more you know
    about your workloads, your clients’ behavior, and their usage patterns, the better
    you’re prepared to handle both sudden spikes in traffic and sustained, long-term
    growth in usage.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 可扩展性是衡量你的系统对增加负载反应能力的指标。这种负载通常由客户端使用他们的驱动程序生成，因此保持你的客户端和服务器之间的关系良好是一个重要的问题。你对工作负载、客户端行为及其使用模式了解得越多，你就越能准备好处理突然的交通高峰和持续的长期增长。
- en: Each client is different and should be treated as such. The differences come
    both from clients’ characteristics, like their number and volume, and from their
    requirements. Some clients have strict latency guarantees, even at the cost of
    higher error rates. Others do not particularly care about the latency of any single
    database query, but just want a steady pace of progress in their long-standing
    queries. Some databases target specific types of clients (e.g., analytical databases
    which expect clients processing large aggregate queries operating on huge volumes
    of historical data). Other ones strive to be universal, handling all kinds of
    clients and balancing the load so that everyone is happy (or, more precisely,
    “happy enough”).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 每个客户端都是不同的，应该这样对待。差异既来自客户端的特征，如它们的数量和体积，也来自它们的需求。一些客户端有严格的延迟保证，即使是以更高的错误率为代价。其他客户端并不特别关心单个数据库查询的延迟，只是希望他们的长期查询能够保持稳定的进度。一些数据库针对特定类型的客户端（例如，分析型数据库，它期望客户端处理大量聚合查询，操作大量历史数据）。其他数据库则力求通用，处理所有类型的客户端，并平衡负载，使每个人都满意（或者更准确地说，“足够满意”）。
- en: '![](../images/541783_1_En_5_Chapter/541783_1_En_5_Fig1_HTML.jpg)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![图5-1](../images/541783_1_En_5_Chapter/541783_1_En_5_Fig1_HTML.jpg)'
- en: An illustration in which two clients interact with 3 database servers that mutually
    interacts, and are connected to seven clients.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 一个图示，其中两个客户端与三个相互交互的数据库服务器交互，并且连接到七个客户端。
- en: Figure 5-1
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 图5-1
- en: Visualization of clients and servers in a distributed system
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式系统中客户端和服务器可视化
- en: Workload Types
  id: totrans-15
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 工作负载类型
- en: There are multiple ways of classifying database clients. One particularly interesting
    way is to delineate between clients processing interactive and batch (e.g., analytical)
    workloads, also known as OLTP (online transaction processing) vs OLAP (online
    analytical processing)—see Figure [5-2](#Fig2).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 对数据库客户端进行分类有多种方式。一种特别有趣的方式是区分处理交互式和批量（例如，分析型）工作负载的客户端，也称为OLTP（在线事务处理）与OLAP（在线分析处理）——参见图[5-2](#Fig2)。
- en: '![](../images/541783_1_En_5_Chapter/541783_1_En_5_Fig2_HTML.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![图5-2](../images/541783_1_En_5_Chapter/541783_1_En_5_Fig2_HTML.png)'
- en: Two illustrations. 1\. Title is Interactive. Three database servers interact
    with four clients individually. 2\. Title is batch. Three database servers interact
    with four clients as a whole.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 两个图示。1. 标题是交互式。三个数据库服务器分别与四个客户端交互。2. 标题是批量。三个数据库服务器作为一个整体与四个客户端交互。
- en: Figure 5-2
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 图5-2
- en: Difference between interactive and batch (analytical) workloads
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 交互式和批量（分析型）工作负载之间的区别
- en: Interactive Workloads
  id: totrans-21
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 交互式工作负载
- en: A client processing an interactive workload typically wants certain latency
    guarantees. Receiving a response fast is more important than ensuring that the
    query succeeded. In other words, it’s better to return an error in a timely manner
    than make the client indefinitely wait for the correct response. Such workloads
    are often characterized by unbounded concurrency, which means that the number
    of in-progress operations is hard to predict.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 处理交互式工作负载的客户端通常希望获得一定的延迟保证。快速收到响应比确保查询成功更重要。换句话说，及时返回错误比让客户端无限期地等待正确响应要好。这类工作负载通常以无界并发为特征，这意味着正在进行的操作数量难以预测。
- en: A prime example of an interactive workload is a server handling requests from
    web browsers. Imagine an online game, where players interact with the system straight
    from their favorite browsers. High latency for such a player means a poor user
    experience because people tend to despise waiting for online content for more
    than a few hundred milliseconds; with multi-second delays, most will just ditch
    the game as unusable and try something else. It’s therefore particularly important
    to be as interactive as possible and return the results quickly—even if the result
    happens to be a temporary error. In such a scenario, the concurrency of clients
    varies and is out of control for the database. Sometimes there might be a large
    influx of players, and the database might need to refuse some of them to avoid
    overload.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 一个交互式工作负载的典型例子是服务器处理来自网页浏览器的请求。想象一下一个在线游戏，玩家可以直接从他们最喜欢的浏览器与系统互动。对于这样的玩家来说，高延迟意味着糟糕的用户体验，因为人们往往讨厌等待在线内容超过几百毫秒；如果延迟达到几秒，大多数人会放弃游戏，认为它无法使用，并尝试其他东西。因此，尽可能实现交互性并快速返回结果尤为重要——即使结果可能是一个临时错误。在这种情况下，客户端的并发性变化无常，对于数据库来说难以控制。有时可能会有大量玩家涌入，数据库可能需要拒绝其中一些玩家以避免过载。
- en: Batch (Analytical) Workloads
  id: totrans-24
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 批量（分析）工作负载
- en: A batch (analytical) workload is the conceptual opposite of an interactive one.
    With such workloads, it doesn’t matter whether any single request is processed
    in a few milliseconds or hours. The important thing is that the processing makes
    steady progress with a satisfactory error rate, which is ideally zero. Batch workloads
    tend to have fixed concurrency, which makes it easier for the database to keep
    the load under control.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 批量（分析）工作负载是交互式工作负载的概念对立面。对于这类工作负载来说，单个请求是否在几毫秒或几小时内处理并不重要。重要的是处理过程以令人满意的错误率稳步进行，理想情况下错误率为零。批量工作负载通常具有固定的并发性，这使得数据库更容易控制负载。
- en: A good example of a batch workload is an Apache Spark^([4](#Fn4)) job performing
    analytics on a big dataset (think terabytes). There are only a few connections
    established to the database, and they continuously send requests in order to fetch
    data for long computations. Because the concurrency is predictable, the database
    can easily respond to an increased load by applying backpressure (e.g., by delaying
    the responses a little bit). The analytical processing will simply slow down,
    adjusting its speed according to the speed at which the database can consume queries.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 批量工作负载的一个好例子是Apache Spark^([4](#Fn4))在大型数据集（如TB级）上执行分析作业。与数据库建立的连接只有几个，它们持续发送请求以获取用于长时间计算的数据。由于并发性可预测，数据库可以很容易地通过应用背压（例如，稍微延迟响应）来应对增加的负载。分析处理将简单地减慢速度，根据数据库消耗查询的速度调整其速度。
- en: Mixed Workloads
  id: totrans-27
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 混合工作负载
- en: Certain workloads cannot be easily qualified as fully interactive or fully batch.
    The clients are free to intermix their requirements, concurrency, and load however
    they please—so the databases should also be ready for surprises. For example,
    a batch workload might suddenly experience a giant temporary spike in concurrency.
    Databases should, on the one hand, maintain a level of trust in the workload’s
    typical patterns, but on the other hand anticipate that workloads can simply change
    over time—due to bugs, hardware changes, or simply because the use case has diverged
    from its original goal.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 某些工作负载难以完全归类为完全交互式或完全批量。客户端可以自由地混合他们的需求、并发性和负载，因此数据库也应该为意外情况做好准备。例如，批量工作负载可能会突然经历并发性的巨大临时峰值。数据库一方面应保持对工作负载典型模式的信任，另一方面应预料到工作负载可能会随着时间的推移而改变——由于错误、硬件变化，或者仅仅是因为用例已经偏离了其原始目标。
- en: Throughput vs Goodput
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 吞吐量与有效吞吐量
- en: A healthy distributed database cluster is characterized by stable goodput, not
    throughput. *Goodput* is an interesting portmanteau of good + throughput, and
    it’s a measure of *useful* data being transferred between clients and servers
    over the network, as opposed to just any data. Goodput disregards errors and other
    churn-like redundant retries, and is used to judge how effective the communication
    actually is.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 一个健康的分布式数据库集群的特点是稳定的良好吞吐量，而不是吞吐量。*良好吞吐量*是*良好*和*吞吐量*的有趣组合，它是衡量客户端和服务器之间通过网络传输的*有用*数据的度量，而不是任何数据。良好吞吐量忽略了错误和其他类似冗余重试的
    churn，用于判断通信的实际效果。
- en: This distinction is important.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这种区别很重要。
- en: Imagine an extreme case of an overloaded node that keeps returning errors for
    each incoming request. Even though stable and sustainable throughput can be observed,
    this database brings no value to the end-user. Thus, it’s essential to track how
    much useful data can be delivered in an acceptable time. For example, this can
    be achieved by tracking both the total throughput and throughput spent on sending
    back error messages and then subtracting one from another to see how much valid
    data was transferred (see Figure [5-3](#Fig3)).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一个极端情况，一个过载的节点持续对每个进入的请求返回错误。即使可以观察到稳定和可持续的吞吐量，这个数据库对最终用户来说也没有任何价值。因此，跟踪在可接受的时间内可以传输多少有效数据是至关重要的。例如，这可以通过跟踪总吞吐量和用于发送错误信息的吞吐量，然后从另一个中减去以查看传输了多少有效数据来实现（见图
    [5-3](#Fig3))。
- en: '![](../images/541783_1_En_5_Chapter/541783_1_En_5_Fig3_HTML.jpg)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../images/541783_1_En_5_Chapter/541783_1_En_5_Fig3_HTML.jpg)'
- en: Two graphs. 1\. The graph title is, Client Received Requests. There are two
    oscillating lines at 100 kilobytes per second, and 60 kilobytes per second. 2\.
    The graph title is, Write Timeouts per seconds. There are spikes at 7 p m for
    14 writers per second, and at 9 p m for 10 writers per second.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 两个图表。1. 图表标题是“客户端接收请求”。有两条每秒 100 千字节和 60 千字节的振荡线。2. 图表标题是“每秒写入超时”。在晚上 7 点有每秒
    14 个写入者的峰值，在晚上 9 点有每秒 10 个写入者的峰值。
- en: Figure 5-3
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5-3
- en: Note how a fraction of the throughput times out, effectively requiring more
    work from clients to achieve goodput
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 注意吞吐量的一部分超时，这实际上需要客户端做更多的工作以实现良好的吞吐量
- en: 'Maximizing goodput is a delicate operation and it heavily depends on the infrastructure,
    workload type, clients’ behavior, and many other factors. In some cases, the database
    shedding load might be beneficial for the entire system. *Shedding* is a rather
    radical measure of dealing with overload: Requests qualified as “risky” are simply
    ignored by the server, or immediately terminated with an error. This type of overload
    protection is especially useful against issues induced by interactive workloads
    with unbounded concurrency (there’s not much a database can do to protect itself
    except drop some of the incoming requests early).'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 最大化良好吞吐量是一项微妙的工作，它严重依赖于基础设施、工作负载类型、客户端行为以及许多其他因素。在某些情况下，数据库卸载负载可能对整个系统有益。*卸载*是处理过载的一种相当激进的措施：将“风险”请求简单地由服务器忽略，或者立即以错误终止。这种类型的过载保护特别适用于由无界并发交互式工作负载引起的问题（数据库除了在早期丢弃一些传入请求外，几乎没有其他方法来保护自己）。
- en: 'The database server isn’t an oracle; it can’t accurately predict whether a
    request is going to fail due to overload, so it must guess. Fortunately, there
    are quite a few ways of making that guess educated:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 数据库服务器不是先知；它无法准确预测请求是否会因为过载而失败，因此必须猜测。幸运的是，有相当多的方法可以使这种猜测变得有根据：
- en: Shedding load if X requests are already being processed, where X is the estimated
    maximum a database node can handle.
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果已经处理了 X 个请求，则卸载负载，其中 X 是数据库节点可以处理的估计最大值。
- en: Refusing a request if its estimated memory usage is larger than the database
    could handle at the moment.
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果请求的估计内存使用量大于数据库当前可以处理的量，则拒绝该请求。
- en: Probabilistically refusing a request if Y requests are already being processed,
    where Y is a percentage of the maximum a database node can handle, with the probability
    raising to 100 percent once a certain threshold is reached.
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果已经处理了 Y 个请求，则概率性地拒绝请求，其中 Y 是数据库节点可以处理的估计最大值的百分比，一旦达到某个阈值，概率将上升到 100%。
- en: Refusing a request if its estimated execution time indicates that it’s not going
    to finish in time, and instead it is likely to time out anyway.
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果请求的估计执行时间表明它不会及时完成，而是很可能超时，则拒绝该请求。
- en: While refusing clients’ requests is detrimental to user experience, sometimes
    it’s simply the lesser of two evils. If dropping a number of requests allows even
    more requests to successfully finish in time, it increases the cluster’s goodput.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然拒绝客户端请求会损害用户体验，但有时这可能是两个恶中较小的一个。如果放弃一些请求可以让更多的请求及时成功完成，这会增加集群的吞吐量。
- en: Clients can help the database maximize goodput and keep the latency low by declaring
    for how long the request is considered valid. For instance, in high frequency
    trading, a request that takes more than a couple of milliseconds is just as good
    as a request that failed. By letting the database know that’s the case, you can
    allow it to retire some requests early, leaving valuable resources for other requests
    which still have a chance to be successful. Proper timeout management is a broad
    topic and it deserves a separate section.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 客户端可以通过声明请求被认为是有效的时间长度来帮助数据库最大化吞吐量和保持低延迟。例如，在高频交易中，耗时超过几毫秒的请求与失败的请求一样好。通过让数据库知道这一点，你可以允许它提前终止一些请求，为其他仍有成功机会的请求留下宝贵的资源。适当的超时管理是一个广泛的话题，它值得单独一节来讨论。
- en: Timeouts
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 超时
- en: 'In a distributed system, there are two fundamental types of timeouts that influence
    one another: client-side timeouts and server-side timeouts. While both are conceptually
    similar, they have different characteristics. It’s vital to properly configure
    both of them to prevent problems like data races and consistency issues.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在分布式系统中，有两种基本类型的时间超时相互影响：客户端超时和服务器端超时。虽然两者在概念上相似，但它们有不同的特性。正确配置两者对于防止数据竞争和一致性问题是至关重要的。
- en: Client-Side Timeouts
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 客户端超时
- en: 'This type of timeout is generally configured in the database driver. It signifies
    how long it takes for a driver to decide that a response from a server is not
    likely to arrive. In a perfect world built on top of a perfect network, all parties
    always respond to their requests. However, in practice, there are numerous causes
    for a response to either be late or lost:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这种类型的超时通常在数据库驱动程序中配置。它表示驱动程序决定服务器响应不太可能到达所需的时间。在一个建立在完美网络之上的理想世界中，所有各方总是对其请求做出响应。然而，在实践中，有许多原因可能导致响应延迟或丢失：
- en: The recipient died
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 收件人死亡
- en: The recipient is busy with other tasks
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 收件人正忙于其他任务
- en: The network failed, maybe due to hardware malfunction
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网络失败，可能是由于硬件故障
- en: The network has a significant delay because packets get stuck in an intermediate
    router
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网络有显著的延迟，因为数据包卡在中间路由器中
- en: A software bug caused the packet to be lost
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 软件错误导致数据包丢失
- en: And so on
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 等等
- en: Since in a distributed environment it’s usually impossible to guess what happened,
    the client must sometimes decide that a request is lost. The alternative is to
    wait indefinitely. That might work for a select set of use cases, but it’s often
    simply unacceptable. If a single failed request holds a resource for an unspecified
    time, the system is eventually doomed to fail. Hence, client-side timeouts are
    used as a mechanism to make sure that the system can operate even in the event
    of communication issues.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 由于在分布式环境中通常无法猜测发生了什么，客户端有时必须决定请求已丢失。另一种选择是无限制地等待。这可能适用于一些特定的用例，但通常是不被接受的。如果单个失败的请求在不确定的时间内占用资源，系统最终注定要失败。因此，客户端超时被用作确保系统即使在通信问题发生时也能运行的机制。
- en: 'A unique characteristic of a client-side timeout is that the decision to give
    up on a request is made solely by the client, in the absence of any feedback from
    the server. It’s entirely possible that the request in question is still being
    processed and utilizes the server’s resources. And, worst of all, the unaware
    server can happily return the response to the client after it’s done processing,
    even though nobody’s interested in this stale data anymore! That presents another
    aspect of error handling: Drivers must be ready to handle stray, expired responses
    correctly.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 客户端超时的一个独特特性是，放弃请求的决定完全由客户端做出，而不考虑来自服务器的任何反馈。完全有可能的情况是，相关的请求仍在处理中，并正在使用服务器的资源。而且，最糟糕的是，无意识的服务器在处理完毕后可能会愉快地向客户端返回响应，尽管此时没有人对这过时的数据感兴趣！这又提出了错误处理的一个方面：驱动程序必须准备好正确处理这些意外的、过期的响应。
- en: Server-Side Timeouts
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 服务器端超时
- en: A server-side timeout determines when a database node should start considering
    a particular request as expired. Once this point in time has passed, there is
    no reason to continue processing the query. (Doing so would waste resources which
    could have otherwise been used for serving other queries that still have a chance
    to succeed.) When the specified time has elapsed, databases often return an error
    indicating that the request took too long.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 服务器端超时确定数据库节点何时应开始考虑特定请求已过期。一旦这个时间点过去，就没有理由继续处理查询。（这样做会浪费资源，这些资源本可以用于服务其他仍有成功机会的查询。）当指定的时间过去后，数据库通常会返回一个错误，表明请求耗时过长。
- en: Using reasonable values for server-side timeouts helps the database manage its
    priorities in a more precise way, allocating CPU, memory and other scarce resources
    on queries likely to succeed in a timely manner. Drivers that receive an error
    indicating that a server-side timeout has occurred should also act accordingly—perhaps
    by reducing the pressure on a particular node or retrying on another node that
    hasn’t experienced timeouts lately.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 使用合理的服务器端超时值有助于数据库更精确地管理其优先级，为可能及时成功查询分配CPU、内存和其他稀缺资源。收到指示服务器端超时发生的错误的通知器也应该相应地采取行动——可能通过减轻特定节点的压力或在最近没有超时的其他节点上重试。
- en: A Cautionary Tale
  id: totrans-60
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 一个警告故事
- en: The CQL protocol, which specifies the communication layer in Apache Cassandra
    and ScyllaDB, comes with built-in support for concurrency. Namely, each request
    is assigned a stream ID, unique for each connection. This stream ID is encoded
    as a 16-bit integer with the first bit being reserved by the protocol, which leaves
    the drivers 32768 unique values for handling in-flight requests per single connection.
    This stream ID is later used to match an incoming response with its original request.
    That’s not a particularly large number, given that modern systems are known to
    handle millions of requests per second. Thus, drivers need to eventually reuse
    previously assigned stream IDs.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: CQL协议，它指定了Apache Cassandra和ScyllaDB的通信层，内置了对并发的支持。具体来说，每个请求都被分配一个流ID，每个连接都是唯一的。这个流ID被编码为一个16位的整数，其中协议保留第一个位，这为驱动程序留下了32768个唯一的值来处理每个连接的单个连接中的飞行请求。这个流ID随后被用来匹配一个传入的响应与其原始请求。考虑到现代系统通常每秒处理数百万个请求，这并不是一个特别大的数字。因此，驱动程序最终需要重用之前分配的流ID。
- en: But the CQL driver for Python had a bug.^([5](#Fn5)) In the event of a client-side
    timeout, it assumed that the stream ID of an expired request was immediately free
    to reuse. While the assumption holds true if the server dies, it is incorrect
    if processing simply takes longer than expected. It was therefore possible that
    once a response with a given stream ID arrived, another request had already reused
    the stream ID, and the driver would mistakenly match the response with the new
    request. If the user was lucky, they would simply receive garbage data that did
    not pass validation. Unfortunately, data from the mismatched response might appear
    correct, even though it originates from a totally different request. This is the
    kind of bug that looks innocent at first glance, but may cause people to log in
    to other people’s bank accounts and wreak havoc on their lives.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 但Python的CQL驱动程序有一个错误.^([5](#Fn5)) 在客户端超时的情况下，它假设已过期的请求的流ID立即可以重用。如果服务器崩溃，这个假设是正确的，但如果处理时间比预期长，则是不正确的。因此，一旦带有给定流ID的响应到达，另一个请求可能已经重用了该流ID，并且驱动程序会错误地将响应与新的请求匹配。如果用户运气好，他们只会收到未通过验证的垃圾数据。不幸的是，来自不匹配响应的数据可能看起来是正确的，即使它来自一个完全不同的请求。这种看起来无害的bug，可能会造成人们登录到他人的银行账户，并对其生活造成破坏。
- en: A rule of thumb for client-side timeouts is to make sure that a server-side
    timeout also exists and is strictly shorter than the client-side one. It should
    take into account clock synchronization between clients and servers (or lack thereof),
    as well as estimated network latency. Such a procedure minimizes the chances for
    a late response to arrive at all, and thus removes the root cause of many issues
    and vulnerabilities.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 客户端超时的一个经验法则是要确保服务器端超时也存在，并且比客户端超时严格短。它应该考虑到客户端和服务器之间的时钟同步（或缺乏同步），以及估计的网络延迟。这样的程序可以最大限度地减少晚响应到达的机会，从而消除许多问题和漏洞的根本原因。
- en: Contextual Awareness
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 上下文感知
- en: At this point it should be clear that both servers and clients can make better,
    more educated, and mutually beneficial decisions if they know more about each
    other. Exchanging timeout information is important, but drivers and servers can
    do even more to keep each other up to date.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，应该很清楚，如果服务器和客户端了解彼此更多，它们可以做出更好、更明智且互惠互利的决策。交换超时信息很重要，但驱动程序和服务器可以做得更多，以保持彼此的最新状态。
- en: Topology and Metadata
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 拓扑和元数据
- en: Database servers are often combined into intricate topologies where certain
    nodes are grouped in a single geographical location, others are used only as a
    fast cache layer, and yet others store seldom accessed cold data in a cheap place,
    for emergency purposes only.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 数据库服务器通常组合成复杂的拓扑结构，其中某些节点被分组在单个地理位置，其他节点仅用作快速缓存层，而还有一些节点将很少访问的冷数据存储在便宜的地方，仅用于应急。
- en: 'Not every database exposes its topology to the end-user. For example, DynamoDB
    takes that burden off of its clients and exposes only a single endpoint, taking
    care of load balancing, overload prevention, and retry mechanisms on its own.
    On the other hand, a fair share of popular databases (including ScyllaDB, Cassandra,
    and ArangoDB) rely on the drivers to connect to each node, decide how many connections
    to keep, when to speculatively retry, and when to close connections if they are
    suspected of malfunctioning. In the ScyllaDB case, sharing up-to-date topology
    information with the drivers helps them make the right decisions. This data can
    be shared in multiple ways:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 并非每个数据库都会向最终用户暴露其拓扑结构。例如，DynamoDB 从客户端卸下了这个负担，只暴露一个单一端点，并自行处理负载均衡、过载预防和重试机制。另一方面，相当一部分流行的数据库（包括
    ScyllaDB、Cassandra 和 ArangoDB）依赖于驱动程序来连接到每个节点，决定保持多少个连接，何时进行推测性重试，以及何时关闭疑似故障的连接。在
    ScyllaDB 的情况下，与驱动程序共享最新的拓扑信息有助于它们做出正确的决策。这些数据可以通过多种方式共享：
- en: Clients periodically fetching topology information from the servers
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定期从服务器获取拓扑信息的客户端
- en: Clients subscribing to events sent by the servers
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 订阅服务器发送事件的客户端
- en: Clients taking an active part in one of the information exchange protocols (e.g.,
    gossip^([6](#Fn6)))
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参与信息交换协议（例如，八卦^([6](#Fn6)))的客户端
- en: Any combination of these
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些方式的任何组合
- en: Depending on the database model, another valuable piece of information often
    cached client-side is metadata—a prime example of which is database schema. SQL
    databases, as well as many NoSQL ones, keep the data at least partially structured.
    A schema defines the shape of a database row (or column), the kinds of data types
    stored in different columns, and various other characteristics (e.g., how long
    a database row is supposed to live before it’s garbage-collected). Based on up-to-date
    schemas, drivers can perform additional validation, making sure that data sent
    to the server has a proper type and adheres to any constraints required by the
    database. On the other hand, when a driver-side cache for schemas gets out of
    sync, clients can experience their queries failing for no apparent reason.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 根据数据库模型，客户端通常还会缓存另一项有价值的信息——元数据——其中最重要的例子是数据库模式。SQL 数据库以及许多 NoSQL 数据库至少部分地保持数据结构化。模式定义了数据库行（或列）的形状，不同列中存储的数据类型，以及各种其他特性（例如，数据库行在垃圾回收之前应该存活多长时间）。基于最新的模式，驱动程序可以执行额外的验证，确保发送到服务器的数据具有正确的类型，并遵守数据库要求的任何约束。另一方面，当模式缓存与驱动程序不同步时，客户端可能会遇到查询无端失败的情况。
- en: Synchronizing full schema information can be costly in terms of performance,
    and finding a good compromise in how often to update highly depends on the use
    case. A rule of thumb is to update only as often as needed to ensure that the
    traffic induced by metadata exchange never negatively impacts the user experience.
    It’s also worth noting that in a distributed database, clients are not always
    up to date with the latest schema information, and the system as a whole should
    be prepared to handle it and provide tactics for dealing with such inconsistencies.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 同步完整的模式信息在性能上可能代价高昂，如何找到更新频率的良好折衷方案高度依赖于用例。一个经验法则是仅更新到确保元数据交换引起的流量不会对用户体验产生负面影响为止。还值得注意的是，在分布式数据库中，客户端并不总是与最新的模式信息保持同步，整个系统应该准备好处理这种情况，并提供处理此类不一致的策略。
- en: Current Load
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 当前负载
- en: Overload protection and request latency optimization are tedious tasks, but
    they can be substantially facilitated by exchanging as much context as possible
    between interested parties.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 过载保护和请求延迟优化是繁琐的任务，但通过在相关方之间尽可能多地交换上下文可以大大简化这些任务。
- en: 'The following methods can be applied to distribute the load evenly across the
    distributed system and prevent unwanted spikes:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 以下方法可以应用于在分布式系统中均匀分配负载并防止不必要的峰值：
- en: 'Gathering latency statistics per each database connection in the drivers:'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在驱动程序中收集每个数据库连接的延迟统计信息：
- en: What’s the average latency for this connection?
  id: totrans-79
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这个连接的平均延迟是多少？
- en: What’s the 99th percentile latency?
  id: totrans-80
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 99 分位数的延迟是多少？
- en: What’s the maximum latency experienced in a recent time frame?
  id: totrans-81
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在最近一段时间内，体验到的最大延迟是多少？
- en: 'Exchanging information about server-side caches:'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 交换有关服务器端缓存的：
- en: Is the cache full?
  id: totrans-83
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 缓存是否已满？
- en: Is the cache warm (i.e., filled with useful data)?
  id: totrans-84
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 缓存是否已预热（即填充了有用的数据）？
- en: Are certain items experiencing elevated traffic and/or latency?
  id: totrans-85
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 是否有某些项目经历了高流量和/或延迟？
- en: 'Interpreting server events:'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解释服务器事件：
- en: Has the server started replying with “overload errors”?
  id: totrans-87
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 服务器是否已经开始回复“过载错误”？
- en: How often do requests for this server time out?
  id: totrans-88
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这个服务器的请求超时频率是多少？
- en: What is the general rate of errors for this server?
  id: totrans-89
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这个服务器的错误一般速率是多少？
- en: What is the measured goodput from this server?
  id: totrans-90
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这个服务器测量的良好吞吐量是多少？
- en: Based on these indicators, drivers should try to amend the amount of data they
    send, the concurrency, and the rate of retries as well as speculative execution,
    which can keep the whole distributed system in a healthy, balanced state. It’s
    ultimately in the driver’s interest to ease the pressure on nodes that start showing
    symptoms of getting overloaded, be it by reducing the concurrency of operations,
    limiting the frequency and number of retries, temporarily giving up on speculatively
    sent requests, and so on. Otherwise, if the database servers get overloaded, all
    clients may experience symptoms like failed requests, timeouts, increased latency,
    and so on.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 根据这些指标，驱动程序应尝试调整发送的数据量、并发性和重试速率，以及推测性执行，这可以使整个分布式系统保持健康、平衡的状态。最终，减轻开始显示过载症状的节点压力是驱动程序的利益所在，无论是通过减少操作并发性、限制重试频率和次数、暂时放弃推测性发送的请求等等。否则，如果数据库服务器过载，所有客户端可能会经历失败请求、超时、延迟增加等症状。
- en: Request Caching
  id: totrans-92
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 请求缓存
- en: Many database management systems, ranging from SQLite, MySQL, and Postgres to
    NoSQL databases, implement an optimization technique called *prepared statements**.*
    While the language used to communicate with the database is usually human-readable
    (or at least developer-readable), it is not the most efficient way of transferring
    data from one computer to another.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 许多数据库管理系统，从 SQLite、MySQL 和 Postgres 到 NoSQL 数据库，都实现了一种称为 *预编译语句* 的优化技术。虽然与数据库通信使用的语言通常是可读的（或者至少是开发者可读的），但这并不是从一台计算机传输数据到另一台计算机的最有效方式。
- en: Let’s take a look at the (simplified) lifecycle of an unprepared statement once
    it’s sent from a ScyllaDB driver to the database and back. This is illustrated
    in Figure [5-4](#Fig4).
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看一个未准备好的语句在被 ScyllaDB 驱动程序发送到数据库并返回后的（简化版）生命周期。这如图 [5-4](#Fig4) 所示。
- en: '![](../images/541783_1_En_5_Chapter/541783_1_En_5_Fig4_HTML.jpg)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](../images/541783_1_En_5_Chapter/541783_1_En_5_Fig4_HTML.jpg)'
- en: A lifecycle of an unprepared statement which consists of, 1\. A query string,
    2\. The string is packed into a C Q L frame by the driver, 3\. The CQL frame is
    sent over the network, 4\. The database parses the string to validate its content,
    and 5\. Database processing.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 未准备语句的生命周期包括，1. 一个查询字符串，2. 驱动程序将字符串打包到 CQL 框架中，3. CQL 框架通过网络发送，4. 数据库解析字符串以验证其内容，5.
    数据库处理。
- en: Figure 5-4
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5-4
- en: Lifecycle of an unprepared statement
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 未准备语句的生命周期
- en: 'A query string is created:'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个查询字符串：
- en: '`INSERT INTO my_table(id, descr) VALUES (42, ''forty two'');`'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`INSERT INTO my_table(id, descr) VALUES (42, ''forty two'');`'
- en: The string is packed into a CQL frame by the driver. Each CQL frame consists
    of a header, which describes the purpose of a particular frame. Following the
    header, a specific payload may be sent as well. The full protocol specification
    is available at [`https://github.com/apache/cassandra/blob/trunk/doc/native_protocol_v4.spec`](https://github.com/apache/cassandra/blob/trunk/doc/native_protocol_v4.spec).
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 驱动程序会将字符串打包成一个CQL帧。每个CQL帧都包含一个头部，用于描述该帧的目的。在头部之后，还可以发送特定的有效载荷。完整的协议规范可在[https://github.com/apache/cassandra/blob/trunk/doc/native_protocol_v4.spec](https://github.com/apache/cassandra/blob/trunk/doc/native_protocol_v4.spec)找到。
- en: The CQL frame is sent over the network.
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: CQL帧通过网络发送。
- en: The frame is received by the database.
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据库接收该帧。
- en: Once the frame is received, the database interprets the frame header and then
    starts parsing the payload. If there’s an unprepared statement, the payload is
    represented simply as a string, as seen in Step 1.
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦接收到帧，数据库将解释帧头部，然后开始解析有效载荷。如果有未准备好的语句，有效载荷将简单地表示为一个字符串，如步骤1所示。
- en: 'The database parses the string in order to validate its contents and interpret
    what kind of an operation is requested: is it an insertion, an update, a deletion,
    a selection?'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据库解析该字符串以验证其内容并解释请求的操作类型：是插入、更新、删除、选择？
- en: Once the statement is parsed, the database can continue processing it (e.g.,
    by persisting data on disk, fetching whatever’s necessary, etc.).
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦解析了语句，数据库就可以继续处理它（例如，在磁盘上持久化数据、获取所需的数据等）。
- en: Now, imagine that a user wants to perform a hundred million operations on the
    database in quick succession because the data is migrated from another system.
    Even if parsing the query strings is a relatively fast operation and takes 50
    microseconds, the total time spent on parsing strings will take over an hour of
    CPU time. Sounds like an obvious target for optimization.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，假设用户想要在数据库上快速连续执行一亿个操作，因为数据是从另一个系统迁移过来的。即使解析查询字符串是一个相对较快的操作，耗时50微秒，但解析字符串的总时间将超过一个小时的CPU时间。听起来这是一个明显的优化目标。
- en: 'The key observation is that operations performed on a database are usually
    similar to one another and follow a certain pattern. For instance, migrating a
    table from one system to another may mean sending lots of requests with the following
    schema:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 关键观察结果是，在数据库上执行的操作通常彼此相似，并遵循某种模式。例如，将表从一个系统迁移到另一个系统可能意味着发送大量具有以下模式的请求：
- en: '[PRE0]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: where `?` denotes the only part of the string that varies between requests.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 其中`?`表示字符串中唯一在请求之间变化的部分。
- en: This query string with question marks instead of real values is actually also
    valid CQL! While it can’t be executed as is (because some of the values are not
    known), it can be prepared.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 这个用问号代替实际值的查询字符串实际上也是有效的CQL！虽然它不能直接执行（因为一些值是未知的），但它可以被准备。
- en: Preparing such a statement means that the database will meticulously analyze
    the string, parse it, and create an internal representation of the statement in
    its own memory. Once done, a unique identifier is generated and sent back to the
    driver. The client can now execute the statement by providing only its identifier
    (which is a 128-bit UUID^([7](#Fn7)) in ScyllaDB) and all the values missing from
    the prepared query string. The process of replacing question marks with actual
    values is called *binding* and it’s the only thing that the database needs to
    do instead of launching a CQL parser, which offers a significant speedup.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 准备这样的语句意味着数据库将仔细分析字符串，解析它，并在自己的内存中创建语句的内部表示。完成后，将生成一个唯一的标识符并将其发送回驱动程序。客户端现在可以通过仅提供其标识符（在ScyllaDB中是一个128位的UUID^([7](#Fn7)))以及从准备好的查询字符串中缺失的所有值来执行语句。将问号替换为实际值的过程称为*绑定*，这是数据库需要做的唯一事情，而不是启动CQL解析器，这可以显著提高速度。
- en: 'Preparing statements without care can also be detrimental to overall cluster
    performance though. When a statement gets prepared, the database needs to keep
    a certain amount of information about it in memory, which is hardly a limitless
    resource. Caches for prepared statements are usually relatively small, under the
    assumption that the driver’s users (app developers) are kind and only prepare
    queries that are used frequently. If, on the other hand, a user were to prepare
    lots of unique statements that aren’t going to be reused any time soon, the database
    cache might invalidate existing entries for frequently used queries. The exact
    heuristics of how entries are invalidated depends on the algorithm used in the
    cache, but a naive LRU (least recently used) eviction policy is susceptible to
    this problem. Therefore, other cache algorithms resilient to such edge cases should
    be considered when designing a cache without full information about expected usage
    patterns. Some notable examples include the following:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 不加注意地准备语句也可能对整体集群性能产生不利影响。当语句被准备时，数据库需要在内存中保留一定量的关于它的信息，这几乎不是一种无限资源。准备语句的缓存通常相对较小，假设驱动程序的用户（应用程序开发者）是友好的，并且只准备经常使用的查询。另一方面，如果用户准备了许多独特且不太可能很快被重用的语句，数据库缓存可能会使频繁使用的查询的现有条目失效。条目如何失效的确切启发式方法取决于缓存中使用的算法，但简单的LRU（最近最少使用）淘汰策略容易受到这个问题的影响。因此，在设计缓存时，如果没有关于预期使用模式的完整信息，应考虑其他对这种边缘情况具有弹性的缓存算法。以下是一些值得注意的例子：
- en: '**LFU (least frequently used)**'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**LFU（最少使用频率）**'
- en: Aside from keeping track of which item was most recently accessed, LFU also
    counts how many times it was needed in a given time period, and tries to keep
    frequently used items in the cache.
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 除了跟踪最近访问过的项目外，LFU（最少使用频率）还会计算在给定时间段内需要它的次数，并尝试将频繁使用的项目保留在缓存中。
- en: '**LRU with two pools**'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**LRU（最近最少使用）与两个池**'
- en: One probationary pool for new entries, and another, usually larger, pool for
    frequently used items. This algorithm avoids cache thrashing when lots of one-time
    entries are inserted in the cache, because they only evict other items from the
    probationary pool, while more frequently accessed entries are safe in the main
    pool.
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一个用于新条目的试用期池，另一个通常更大的池用于频繁使用的项目。此算法避免了当大量一次性条目被插入缓存时发生缓存抖动，因为它们只会从试用期池中淘汰其他项目，而更频繁访问的条目在主池中是安全的。
- en: Finally, regardless of the algorithm used for cache eviction implemented server-side,
    drivers should take care not to prepare queries too aggressively, especially if
    it happens automatically, which is often the case in ORMs (object-relational mappings).
    Making an interface convenient for the user may sound tempting, and developer
    experience is indeed an important factor when designing a driver, but being too
    eager with reserving precious database resources may be disadvantageous in the
    long term.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，无论服务器端实现缓存淘汰所使用的算法是什么，驱动程序都应该注意不要过于积极地准备查询，尤其是如果它是自动发生的，这在对象关系映射（ORMs）中通常是情况。使接口对用户方便听起来可能很有吸引力，开发者的体验确实在设计驱动程序时是一个重要的因素，但过于急切地预留宝贵的数据库资源可能在长期内是不利的。
- en: Query Locality
  id: totrans-119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 查询局部性
- en: In distributed systems, any kind of locality is welcome because it reduces the
    chances of failure, keeps the latency low, and generally prevents many undesirable
    events. While database clients, and thus also drivers, do not usually share the
    same machines with the database cluster, it is possible to keep the distance between
    them short. “Distance” might mean either a physical measure or the number of intermediary
    devices in the network topology. Either way, for latency’s sake, it’s good to
    minimize it between parties that need to communicate with each other frequently.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在分布式系统中，任何类型的局部性都是受欢迎的，因为它减少了失败的可能性，保持了低延迟，并且通常防止了许多不希望发生的事件。虽然数据库客户端以及驱动程序通常不与数据库集群位于同一台机器上，但有可能缩短它们之间的距离。“距离”可能意味着物理测量或网络拓扑中的中间设备数量。无论如何，为了延迟，最好在需要频繁互相通信的各方之间最小化它。
- en: Many database management systems allow their clients to announce their “location,”
    for example, by declaring which datacenter is their local, default one. Drivers
    should take that information into account when communicating with the database
    nodes. As long as all consistency requirements are fulfilled, it’s usually better
    to send data directly to a nearby node, under the assumption that it will spend
    less time in transit. Short routes also usually imply fewer middlemen, and that
    in turn translates to fewer potential points of failure.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 许多数据库管理系统允许他们的客户端宣布他们的“位置”，例如，通过声明哪个数据中心是他们的本地默认数据中心。驱动器在与其他数据库节点通信时应考虑这些信息。只要所有一致性要求都得到满足，通常最好直接将数据发送到附近的节点，假设它将在传输中花费更少的时间。短路径通常也意味着中间人更少，这反过来又意味着潜在的故障点更少。
- en: Drivers can make much more educated choices though. Quite a few NoSQL databases
    can be described as “distributed hash tables” because they partition their data
    and spread it across multiple nodes which own a particular set of hashes. If the
    hashing algorithm is well known and deterministic, drivers can leverage that fact
    to try to optimize the queries even further—sending data directly to the appropriate
    node, or even the appropriate CPU core.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 驱动器可以做出更加明智的选择。许多NoSQL数据库可以被描述为“分布式哈希表”，因为它们将数据分区并分散到拥有特定哈希集的多台节点上。如果哈希算法是众所周知的且确定性的，驱动器可以利用这一事实来进一步优化查询——直接将数据发送到适当的节点，甚至直接发送到处理它的单个CPU核心。
- en: 'ScyllaDB, Cassandra, and other NoSQL databases apply a concept of token^([8](#Fn8))
    awareness (see Figures [5-5](#Fig5), [5-6](#Fig6), and [5-7](#Fig7)):'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: ScyllaDB、Cassandra和其他NoSQL数据库应用了一个令牌意识的概念（参见图[5-5](#Fig5)、[5-6](#Fig6)和[5-7](#Fig7)）：
- en: A request arrives.
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个请求到达。
- en: The receiving node computes the hash of the given input.
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接收节点计算给定输入的哈希值。
- en: Based on the value of this hash, it computes which database nodes are responsible
    for this particular value.
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据这个哈希值的值，它计算出哪些数据库节点负责这个特定的值。
- en: Finally, it forwards the request directly to the owning nodes.
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，它将请求直接转发到拥有节点。
- en: '![](../images/541783_1_En_5_Chapter/541783_1_En_5_Fig5_HTML.jpg)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../images/541783_1_En_5_Chapter/541783_1_En_5_Fig5_HTML.jpg)'
- en: A Naive client interacts with Coordinator node, which in turn interacts with
    Data replicas.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 一个简单的客户端与协调节点交互，该节点随后与数据副本交互。
- en: Figure 5-5
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 图5-5
- en: Naive clients route queries to any node (coordinator)
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 简单客户端将查询路由到任何节点（协调器）
- en: However, in certain cases, the driver can compute the token locally on its own,
    and then use the cluster topology information to route the request straight to
    the owning node. This local node-level routing saves at least one network round-trip
    as well as the CPU time of some of the nodes.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在某些情况下，驱动器可以在本地自行计算令牌，然后使用集群拓扑信息将请求直接路由到拥有节点。这种本地节点级路由至少节省了一个网络往返以及一些节点的CPU时间。
- en: '![](../images/541783_1_En_5_Chapter/541783_1_En_5_Fig6_HTML.jpg)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../images/541783_1_En_5_Chapter/541783_1_En_5_Fig6_HTML.jpg)'
- en: A Token aware client interacts with Coordinator plus data replica, which in
    turn interacts with Data replicas.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 一个具有令牌意识的客户端与协调节点和数据副本交互，该节点随后与数据副本交互。
- en: Figure 5-6
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 图5-6
- en: Token-aware clients route queries to the right node(s)
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 令牌意识客户端将查询路由到正确的节点
- en: In the Cassandra/ScyllaDB case, this is possible because each table has a well-defined
    “partitioner,” which simply means a hash function implementation. The default
    choice—used in Cassandra—is murmur3,^([9](#Fn9)) which returns a 64-bit hash value,
    has satisfying distribution, and is relatively cheap to compute. ScyllaDB takes
    it one step further and allows the drivers to calculate which CPU core of which
    database node owns a particular datum. When a driver is cooperative and proactively
    establishes a separate connection per each core of each machine, it can send the
    data not only to the right node, but also straight to the single CPU core responsible
    for handling it. This not only saves network bandwidth, but is also very friendly
    to CPU caches.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在Cassandra/ScyllaDB的情况下，这是可能的，因为每个表都有一个定义良好的“分区器”，这仅仅意味着一个哈希函数实现。默认选择——在Cassandra中使用——是murmur3，^([9](#Fn9))，它返回一个64位的哈希值，具有令人满意的分布，并且计算相对便宜。ScyllaDB更进一步，允许驱动器计算哪个数据库节点的哪个CPU核心拥有特定的数据。当驱动器是协作的并且主动为每台机器的每个核心建立单独的连接时，它不仅可以发送到正确的节点，还可以直接发送到处理它的单个CPU核心。这不仅节省了网络带宽，而且对CPU缓存非常友好。
- en: '![](../images/541783_1_En_5_Chapter/541783_1_En_5_Fig7_HTML.jpg)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../images/541783_1_En_5_Chapter/541783_1_En_5_Fig7_HTML.jpg)'
- en: A shard aware client interacts with Coordinator plus data replica, which in
    turn interacts with Data replicas.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 分片感知客户端与协调器加数据副本交互，而数据副本反过来与数据副本交互。
- en: Figure 5-7
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 图5-7
- en: Shard-aware clients route queries to the correct node(s) + core
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 分片感知客户端将查询路由到正确的节点（+核心）
- en: Retries
  id: totrans-142
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 重试
- en: In a perfect system, no request ever fails and logic implemented in the drivers
    can be kept clean and minimal. In the real world, failures happen disturbingly
    often, so the drivers should also be ready to deal with them. One such mechanism
    for failure tolerance is a driver’s retry policy. A retry policy’s job is to decide
    whether a request should be sent again because it failed (or at least the driver
    strongly suspects that it did).
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个完美的系统中，没有任何请求会失败，并且驱动程序中实现的逻辑可以保持简洁和最小化。在现实世界中，失败发生得令人不安地频繁，因此驱动程序也应该准备好处理它们。一种用于容错性的机制是驱动程序的重试策略。重试策略的职责是决定是否因为失败（或者至少驱动程序强烈怀疑它失败了）而再次发送请求。
- en: Error Categories
  id: totrans-144
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 错误类别
- en: 'Before diving into techniques for retrying requests in a smart way, there’s
    a more fundamental question to consider: does a retry even make sense? The answer
    is not that obvious and it depends on many internal and external factors. When
    a request fails, the error can fall into the following categories, presented with
    a few examples:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入研究智能重试请求的技术之前，有一个更基本的问题需要考虑：重试是否真的有意义？答案并不明显，并且取决于许多内部和外部因素。当请求失败时，错误可以归入以下类别，以下是一些示例：
- en: Timeouts
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 超时
- en: Read timeouts
  id: totrans-147
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 读取超时
- en: Write timeouts
  id: totrans-148
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 写入超时
- en: Temporary errors
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 临时错误
- en: Database node overload
  id: totrans-150
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据库节点过载
- en: Dead target node
  id: totrans-151
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 目标节点已死亡
- en: Temporary schema mismatch
  id: totrans-152
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 临时模式不匹配
- en: Permanent errors
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 永久性错误
- en: Incorrect query syntax
  id: totrans-154
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 不正确的查询语法
- en: Authentication error
  id: totrans-155
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 认证错误
- en: Insufficient permissions
  id: totrans-156
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 权限不足
- en: Depending on the category, the retry decision may be vastly different. For instance,
    it makes absolutely no sense to retry a request that has incorrect syntax. It
    will not magically start being correct, and such a retry attempt would only waste
    bandwidth and database resources.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 根据类别，重试决策可能会有很大差异。例如，重试具有不正确语法的请求完全没有意义。它不会神奇地变得正确，这样的重试尝试只会浪费带宽和数据库资源。
- en: Idempotence
  id: totrans-158
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 幂等性
- en: 'Error categories aside, retry policy must also consider one important trait
    of the request itself: its *idempotence*. An idempotent request can be safely
    applied multiple times, and the result will be indistinguishable from applying
    it just once.'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 除了错误类别之外，重试策略还必须考虑请求本身的一个重要特性：其*幂等性*。幂等请求可以安全地多次应用，其结果将与应用一次无法区分。
- en: 'Why does this need to be taken into account at all? For certain classes of
    errors, the driver cannot be sure whether the request actually succeeded. A prime
    example of such error is a timeout. The fact that the driver did not manage to
    get a response in time does not mean that the server did not successfully process
    the request. It’s a similar situation if the network connection goes down: The
    driver won’t know if the database server actually managed to apply the request.'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么需要考虑这一点？对于某些错误类别，驱动程序不能确定请求是否实际上成功了。这类错误的典型例子是超时。驱动程序未能及时获得响应并不意味着服务器没有成功处理请求。如果网络连接中断，情况也类似：驱动程序将不知道数据库服务器是否实际上成功应用了请求。
- en: 'When in doubt, the driver should make an educated guess in order to ensure
    consistency. Imagine a request that withdraws $100 from somebody’s bank account.
    You certainly don’t want to retry the same request again if you’re not absolutely
    sure that it failed; otherwise, the bank customer might become a bit resentful.
    This is a perfect example of a non-idempotent request: Applying it multiple times
    changes the ultimate outcome.'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 当不确定时，驱动程序应该做出明智的猜测，以确保一致性。想象一下，一个从某人的银行账户中提取100美元的请求。如果你不是绝对确定它失败了，你当然不希望再次执行相同的请求；否则，银行客户可能会有些怨恨。这是一个非幂等请求的完美例子：多次应用它改变了最终结果。
- en: 'Fortunately, there’s a large subset of idempotent queries that can be safely
    retried, even when it’s unclear whether they already succeeded:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，存在大量幂等查询可以安全重试，即使不清楚它们是否已经成功：
- en: '**Read-only requests**'
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**只读请求**'
- en: Since they do not modify any data, they won’t have any side effects, no matter
    how often they’re retried.
  id: totrans-164
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 由于它们不修改任何数据，无论重试多少次，都不会有任何副作用。
- en: '**Certain conditional requests that have compare-and-set characteristics**
    (e.g., “bump the value by 1 if the previous value is 42”)'
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**具有比较和设置特性的某些条件请求**（例如，“如果前一个值是42，则增加值1”）'
- en: Depending on the use case, such a condition may be enough to guarantee idempotence.
    Once this request is applied, applying it again would have no effect since the
    previous value would then be 43.
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 根据用例，这样的条件可能足以保证幂等性。一旦这个请求被应用，再次应用它将不会有任何效果，因为之前的值将是43。
- en: '**Requests with unique timestamps**'
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**具有唯一时间戳的请求**'
- en: When each request has a unique timestamp (represented in wall clock time or
    based on a logical clock^([10](#Fn10))), applying it multiple times can be idempotent.
    A retry attempt will contain a timestamp identical to the original request, so
    it will only overwrite data identified by this particular timestamp. If newer
    data arrives in-between with a newer timestamp, it will not be overwritten by
    a retry attempt with an older timestamp.
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 当每个请求都有一个唯一的时间戳（以墙钟时间表示或基于逻辑时钟^([10](#Fn10)))时，应用多次可以是幂等的。重试尝试将包含与原始请求相同的时间戳，因此它将只覆盖由这个特定时间戳标识的数据。如果在之间有带有较新时间戳的新数据到达，它不会被带有较旧时间戳的重试尝试覆盖。
- en: 'In general, it’s a good idea for drivers to give users an opportunity to declare
    their requests’ idempotence explicitly. Some queries can be trivially deduced
    to be idempotent by the driver (e.g., when it’s a read-only `SELECT` statement
    in the database world), but others may be less obvious. For example, the conditional
    example from the previous Step 2 is idempotent if the value is never decremented,
    but not in the general case. Imagine the following counter-example:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，让驱动程序给用户提供一个明确声明请求幂等性的机会是个好主意。一些查询可以通过驱动程序简单地推断为幂等（例如，当它是数据库世界中的只读`SELECT`语句时），但其他可能不那么明显。例如，前一步第2步的条件示例，如果值从未减少，则是幂等的，但在一般情况下则不是。想象以下反例：
- en: The current value is 42.
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当前值为42。
- en: A request “bump the value by 1 if the previous value is 42” is sent.
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 发送一个“如果前一个值是42，则增加值1”的请求。
- en: A request “bump the value by 1 if the previous value is 42” is retried.
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重试一个“如果前一个值是42，则增加值1”的请求。
- en: Another request, “decrement the value by 1,” is sent.
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 发送另一个请求，“将值减1”。
- en: The request from Step 2 arrives and is applied—changing the value to 43.
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第2步的请求到达并被应用——将值更改为43。
- en: The request from Step 4 arrives and is applied—changing the value to 42.
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第4步的请求到达并被应用——将值更改为42。
- en: The retry from Step 3 is applied—changing the value back to 43 and interfering
    with the effect of the query from Step 4\. This wasn’t idempotent after all!
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第3步的重试被应用——将值改回43，并干扰第4步查询的效果。最终，它根本不是幂等的！
- en: Since it’s often impossible to guess if a request is idempotent just by analyzing
    its contents, it’s best for drivers to have a `set_idempotent()` function exposed
    in their API. It allows the users to explicitly mark some queries as idempotent,
    and then the logic implemented in the driver can assume that it’s safe to retry
    such a request when the need arises.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 由于仅通过分析其内容通常无法猜测请求是否幂等，因此最好让驱动程序在其API中公开一个`set_idempotent()`函数。它允许用户明确标记一些查询为幂等，然后驱动程序中实现的逻辑可以假设在需要时安全地重试此类请求。
- en: Retry Policies
  id: totrans-178
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 重试策略
- en: 'Finally, there’s enough context to discuss actual retry policies that a database
    driver could implement. The sole job of a retry policy is to analyze a failed
    query and return a decision. This decision depends on the database system and
    its intrinsics, but it’s often one of the following (see Figure [5-8](#Fig8)):'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，有足够的上下文来讨论数据库驱动程序可以实施的实际重试策略。重试策略的唯一任务是分析失败的查询并返回一个决策。这个决策取决于数据库系统和其固有特性，但通常是以下之一（见图[5-8](#Fig8)）：
- en: '![](../images/541783_1_En_5_Chapter/541783_1_En_5_Fig8_HTML.jpg)'
  id: totrans-180
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../images/541783_1_En_5_Chapter/541783_1_En_5_Fig8_HTML.jpg)'
- en: Three illustrations of decision graph for retrying a query. 1\. A box with label,
    Idempotent and a question mark, leading to another box named, Safe, if yes. 2\.
    A box with label, Definite failure and a question mark, leading to another box
    named, Safe, if yes. 3\. A box with label, Ok to write twice and a question mark,
    leading to another box named, Safe, if yes, and leading to another box named,
    Not safe, if No.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 决策图的三个重试查询示例。1. 带有标签“幂等”和问号的框，如果回答是，则指向另一个名为“安全”的框。2. 带有标签“确定失败”和问号的框，如果回答是，则指向另一个名为“安全”的框。3.
    带有标签“可以写两次”和问号的框，如果回答是，则指向另一个名为“安全”的框，如果回答否，则指向另一个名为“不安全”的框。
- en: Figure 5-8
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 图5-8
- en: Decision graph for retrying a query
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 重试查询的决策图
- en: Do not retry
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不重试
- en: Retry on the same database node
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在同一数据库节点上重试
- en: Retry, but on a different node
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重试，但在不同的节点上
- en: Retry, but not immediately—apply some delay
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重试，但不是立即——应用一些延迟
- en: Deciding not to retry is often a decent choice—it’s the only correct one when
    the driver isn’t certain whether an idempotent query really failed or just timed
    out. It’s also the obvious choice for permanent errors; there’s no point in retrying
    a request that was previously refused due to incorrect syntax. And whenever the
    system is overloaded, the “do not retry” approach might help the entire cluster.
    Although the immediate effect (preventing a user’s request from being driven to
    completion) is not desirable, it provides a level of overload protection that
    might pay off in the future. It prevents the overload condition from continuing
    to escalate. Once a node gets too much traffic, it refuses more requests, which
    increases the rate of retries, and ends up in a vicious circle.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 不重试通常是一个不错的选择——当驱动程序不确定幂等查询是否真的失败或只是超时时，这是唯一正确的选择。对于永久性错误来说，这也是一个明显的选择；由于语法错误而之前被拒绝的请求重试是没有意义的。而且，每当系统过载时，“不重试”的方法可能有助于整个集群。虽然立即效果（阻止用户的请求被驱动完成）是不希望的，但它提供了一种过载保护水平，这可能在将来得到回报。它防止过载条件继续升级。一旦节点流量过多，它就会拒绝更多请求，这会增加重试率，最终陷入恶性循环。
- en: Retrying on the same database node is generally a good option for timeouts.
    Assuming that the request is idempotent, the same node can probably resolve potential
    conflicts faster. Retrying on a different node is a good idea if the previous
    node showed symptoms of overload, or had an input/output error that indicated
    a temporary issue.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 在同一数据库节点上重试通常是一个好的选择，对于超时来说尤其如此。假设请求是幂等的，相同的节点可能更快地解决潜在冲突。如果前一个节点显示出过载的迹象，或者有输入/输出错误表明是暂时性问题，那么在不同的节点上重试是个好主意。
- en: Finally, in certain cases, it’s a good idea to delay the retry instead of firing
    it off immediately (see Figure [5-9](#Fig9)).
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在某些情况下，延迟重试而不是立即执行是一个好主意（见图 [5-9](#Fig9)）。
- en: '![](../images/541783_1_En_5_Chapter/541783_1_En_5_Fig9_HTML.jpg)'
  id: totrans-191
  prefs: []
  type: TYPE_IMG
  zh: '![图](../images/541783_1_En_5_Chapter/541783_1_En_5_Fig9_HTML.jpg)'
- en: An illustration with three lines named, bottom to top, End user, App and Cluster.
    Attempt 1 just goes beyond App and ends. Attempt 2 reaches up to cluster and bounces
    back. Attempt 3 reaches up to cluster, bounces back to app and then to end user.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 一幅带有三条线（从下到上分别为：终端用户、应用和集群）的插图。尝试 1 仅超出应用并结束。尝试 2 达到集群并弹回。尝试 3 达到集群，弹回到应用，然后到终端用户。
- en: Figure 5-9
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5-9
- en: Retry attempts eventually resulting in a successful query
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 最终导致成功查询的重试尝试
- en: 'When the whole cluster shows the symptoms of overload—be it high reported CPU
    usage or perceived increased latency—retrying immediately after a request failed
    may only exacerbate the problem. What a driver can do instead is apply a gentle
    backoff algorithm, giving the database cluster time to recover. Remember that
    even a failed retry costs resources: networking, CPU, and memory. Therefore, it’s
    better to balance the costs and chances for success in a reasonable manner.'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 当整个集群显示出过载的迹象——无论是高报告的 CPU 使用率还是感知到的延迟增加——请求失败后立即重试可能会加剧问题。驱动程序可以做的另一件事是应用一个温和的退避算法，给数据库集群恢复的时间。记住，即使是失败的重试也会消耗资源：网络、CPU
    和内存。因此，以合理的方式平衡成本和成功的机会会更好。
- en: The three most common backoff strategies are constant, linear, and exponential
    backoff, as visualized in Figure [5-10](#Fig10).
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 三种最常见的退避策略是常数、线性以及指数退避，如图 [5-10](#Fig10) 所示。
- en: '![](../images/541783_1_En_5_Chapter/541783_1_En_5_Fig10_HTML.jpg)'
  id: totrans-197
  prefs: []
  type: TYPE_IMG
  zh: '![图](../images/541783_1_En_5_Chapter/541783_1_En_5_Fig10_HTML.jpg)'
- en: Three lines. 1\. An exponential line with dots at 1, 2, 7, 16, and 32, 2\. A
    linear line with dots at 1, 2, 3, 6, 10, 16, 23, and 32, 3\. A constant line with
    dots from 1 to 32.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 三条线。1. 一个指数线，点在 1, 2, 7, 16 和 32，2. 一个线性线，点在 1, 2, 3, 6, 10, 16, 23 和 32，3.
    一个常数线，点从 1 到 32。
- en: Figure 5-10
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5-10
- en: Constant, linear, and exponential backoffs
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 常数、线性以及指数退避
- en: The first type (constant) simply waits a certain predefined amount of time before
    retrying. Linear backoff increases the time between attempts in a linear fashion;
    it could wait one second before the first attempt, two seconds before the second
    one, and so forth. Finally, exponential backoff, arguably the most commonly used
    method, increases the delay by multiplying it by a constant each time. Usually
    it just doubles it—because both processors and developers love multiplying and
    dividing by two (the latter ones mostly just to show off their intricate knowledge
    of the bitwise shift operator). Exponential backoff has especially nice characteristics
    for overload prevention. The retry rate drops exponentially, and so does the pressure
    that the driver places on the database cluster.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 第一种类型（恒定）简单地在重试之前等待一个预定义的固定时间。线性退避以线性方式增加尝试之间的时间；它可能在第一次尝试前等待一秒钟，第二次尝试前等待两秒钟，以此类推。最后，指数退避，可以说是最常用的方法，通过每次乘以一个常数来增加延迟。通常它只是将其翻倍——因为处理器和开发者都喜欢乘以和除以二（后者大多只是为了炫耀他们对位运算符的复杂知识的了解）。指数退避在防止过载方面具有特别好的特性。重试率呈指数下降，因此对数据库集群的压力也相应减少。
- en: Paging
  id: totrans-202
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分页
- en: Databases usually store amounts of data that are orders of magnitude larger
    than a single client machine could handle. If you fetch all available records,
    the result is unlikely to fit into your local disks, not to mention your available
    RAM. Nonetheless, there are many valid cases for processing large amounts of data,
    such as analyzing logs or searching for specific documents. It is quite acceptable
    to ask the database to serve up all the data it has—but you probably want it to
    deliver that data in smaller bits.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 数据库通常存储的数据量比单个客户端机器能够处理的数据量大得多。如果你获取所有可用的记录，结果很可能无法适应你的本地磁盘，更不用说你的可用RAM了。尽管如此，处理大量数据的许多情况都是有效的，例如分析日志或搜索特定文档。要求数据库提供所有数据是完全可接受的——但你可能希望它以较小的数据块提供这些数据。
- en: That technique is customarily called *paging*, and it is ubiquitous. It’s exactly
    what you’ve experienced when browsing through page 17 of Google search results
    in futile search for an answer to a question that was asked only on an inactive
    forum seven years ago—or getting all the way to page 24 of eBay listings, hunting
    for that single perfect offer. Databases and their drivers also implement paging
    as a mechanism beneficial for both parties. Drivers get their data in smaller
    chunks, which can be done with lower latency. And databases receive smaller queries,
    which helps with cache management, workload prioritization, memory usage, and
    so on.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 那种技术通常被称为*分页*，它无处不在。这正是你在浏览谷歌搜索结果的第17页，徒劳地寻找一个只在七年前的非活跃论坛上提出的问题的答案时所经历的——或者到达eBay列表的第24页，寻找那个完美的单一报价。数据库及其驱动程序也将分页作为一种对双方都有益的机制实现。驱动程序以较小的数据块获取数据，这可以以较低的延迟完成。数据库接收到的查询也更小，这有助于缓存管理、工作负载优先级、内存使用等。
- en: 'Different database models may have a different view of exactly what paging
    involves and how you interface with it. Some systems may offer fine-grained control,
    which allows you to ask for “page 16” of your data. Others are “forward-only”:
    They reduce the user-facing interface to “here’s the current page—you can ask
    for the next page if you want.” Your ability to control the page size also varies.
    Sometimes it’s possible to specify the size in terms of a number of database records
    or bytes. In other cases, the page size is fixed.'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 不同的数据库模型可能对分页的具体内容和如何与之交互有不同的看法。一些系统可能提供细粒度控制，允许你请求“数据第16页”。其他系统则是“单向前进”：它们将用户界面简化为“这是当前页——如果你想的话可以请求下一页。”你控制页面大小的能力也各不相同。有时可以指定大小为数据库记录数或字节数。在其他情况下，页面大小是固定的。
- en: On top of a minimal interface that allows paging to be requested, drivers can
    offer many interesting features and optimizations related to paging. One of them
    is *readahead*—which usually means that the driver transparently and speculatively
    fetches new pages before you actually ask for them to be read. A readahead is
    a classic example of a double-edged sword. On the one hand, it makes certain read
    operations faster, especially if the workload consists of large consecutive reads.
    On the other, it may cause prohibitive overhead, especially if the workload is
    based on small random reads.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 在允许请求分页的最小界面之上，驱动程序可以提供许多与分页相关的有趣功能和优化。其中之一是*预读*——这通常意味着在您实际请求读取之前，驱动程序透明地、推测性地获取新的页面。预读是双刃剑的经典例子。一方面，它使得某些读取操作更快，特别是如果工作负载由大连续读取组成。另一方面，它可能造成过高的开销，特别是如果工作负载基于小随机读取。
- en: 'Although most drivers support paging, it’s important to check whether the feature
    is opt-in or opt-out and consciously decide what’s best for a specific workload.
    In particular, pay attention to the following aspects:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管大多数驱动程序支持分页，但检查该功能是默认开启还是关闭，并自觉地决定对特定工作负载最好的做法是很重要的。特别是要注意以下方面：
- en: What’s the default behavior (would a read query be paged or unpaged)?
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 默认行为是什么（读取查询会被分页还是未分页）？
- en: What’s the default page size and is it configurable? If so, in what units can
    a size be specified? Bytes? Number of records?
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 默认的分页大小是什么，并且是否可配置？如果是，大小可以用什么单位指定？字节？记录数？
- en: Is readahead on by default? Can it be turned on/off?
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 预读是否默认开启？能否开启/关闭？
- en: Can readahead be configured further? For example, can you specify how many pages
    to fetch or when to decide to start fetching (e.g., “When at least three consecutive
    read requests already occurred”)?
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 预读是否可以进一步配置？例如，您能否指定要获取多少页面或何时决定开始获取（例如，“当至少有三个连续的读取请求已经发生”）？
- en: Setting up paging properly is important because a single unpaged response can
    be large enough to be problematic for both the database servers forced to produce
    it, and for the client trying to receive it. On the other hand, too granular paging
    can lead to unnecessary overhead (just imagine trying to read a billion records
    row-by-row, due to the default page size of “1 row”). Finally, readahead can be
    a fantastic optimization technique—but it can also be entirely redundant, fetching
    unwanted pages that cost memory, CPU time, and throughput, as well as confuse
    the metrics and logs. With paging configuration, it’s best to be as explicit as
    possible.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 正确设置分页非常重要，因为单个未分页的响应可能足够大，对被迫产生它的数据库服务器和试图接收它的客户端都可能是问题。另一方面，过于细粒度的分页可能导致不必要的开销（只需想象尝试逐行读取十亿条记录，因为默认的分页大小为“1行”）。最后，预读可以是一种出色的优化技术——但它也可能完全多余，获取不需要的页面，消耗内存、CPU时间、吞吐量，并混淆指标和日志。在分页配置中，最好尽可能明确。
- en: Concurrency
  id: totrans-213
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 并发
- en: In many cases, the only way to utilize a database to the fullest—and achieve
    optimal performance—is to also achieve high concurrency. That often requires the
    drivers to perform many I/O operations at the same time, and that’s in turn customarily
    achieved by issuing asynchronous tasks. That being said, let’s take quite a few
    steps back to explain what that really means and what’s involved in achieving
    that from both a hardware and software perspective.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多情况下，要充分利用数据库并实现最佳性能，通常需要驱动程序同时执行许多I/O操作。这反过来又通常通过发布异步任务来实现。话虽如此，让我们退后几步来解释这究竟意味着什么，以及从硬件和软件的角度实现这一点涉及哪些内容。
- en: Note
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: High concurrency is not a silver bullet. When it’s too high, it’s easy to overload
    the system and ruin the quality of service for other users—see Figure [5-11](#Fig11)
    for its effect on latency. Chapter [1](541783_1_En_1_Chapter.xhtml) includes a
    cautionary tale on what can happen when concurrency gets out of bounds and Chapter
    [2](541783_1_En_2_Chapter.xhtml) also touches on the dangers of unbounded concurrency.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 高并发并不是万能的。当它过高时，很容易超载系统并破坏其他用户的服务质量——参见图[5-11](#Fig11)以了解其对延迟的影响。第[1](541783_1_En_1_Chapter.xhtml)章包括一个关于并发超出界限可能发生什么的警告故事，第[2](541783_1_En_2_Chapter.xhtml)章也提到了无界并发的危险。
- en: Modern Hardware
  id: totrans-217
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 现代硬件
- en: Back in the old days, making decisions around I/O concurrency was easy because
    magnetic storage drives (HDD) had an effective concurrency of 1\. There was (usually)
    only a single actuator arm used to navigate the platters, so only a single sector
    of data could have been read at once. Then, an SSD revolution happened. Suddenly,
    disks could read from multiple offsets concurrently. Moreover, it became next
    to impossible to fully utilize the disk (i.e., to read and write with the speeds
    advertised in shiny numbers printed on their labels) without actually asking for
    multiple operations to be performed concurrently. Now, with enterprise-grade NVMe
    drives and inventions like Intel Optane,^([11](#Fn11)) concurrency is a major
    factor when benchmarking input/output devices. See Figure [5-11](#Fig11).
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去，关于I/O并发的决策很容易，因为磁存储驱动器（HDD）的有效并发性为1。通常只有一个执行器臂用于导航盘片，因此一次只能读取一个数据扇区。然后，发生了SSD革命。突然之间，磁盘可以并发地从多个偏移量读取。此外，如果不实际请求并发执行多个操作，几乎不可能充分利用磁盘（即以标签上印制的闪亮数字的速度读取和写入），现在，随着企业级NVMe驱动器和英特尔Optane等发明，^([11](#Fn11))
    并发性在基准测试输入/输出设备时成为一个主要因素。见图[5-11](#Fig11)。
- en: '![](../images/541783_1_En_5_Chapter/541783_1_En_5_Fig11_HTML.jpg)'
  id: totrans-219
  prefs: []
  type: TYPE_IMG
  zh: '![](../images/541783_1_En_5_Chapter/541783_1_En_5_Fig11_HTML.jpg)'
- en: A line graph between latency and concurrency. A solid line begins at the bottom
    left, remains almost flat and rises gradually after x-axis value of 5, to reach
    the top right. Another line is present at y-axis value of 3\. Values are estimated.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 一条表示延迟与并发的折线图。一条实线从左下角开始，几乎保持平坦，在x轴值为5之后逐渐上升，达到右上角。在y轴值为3的位置还有另一条线。数值为估算值。
- en: Figure 5-11
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 图5-11
- en: Relationship between the system’s concurrency and latency
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 系统并发与延迟之间的关系
- en: Networking technology is not lagging behind either. Modern networking cards
    have multiple independent queues, which, with the help of receive-side scaling
    (RSS^([12](#Fn12))), enable previously unimaginable levels of performance, with
    throughput measured in Tbps.^([13](#Fn13)) With such advanced hardware, achieving
    high concurrency in software is required to simply utilize the available capabilities.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 网络技术也没有落后。现代网卡拥有多个独立的队列，借助接收端扩展（RSS^([12](#Fn12)）），实现了以前难以想象的高性能水平，吞吐量以Tbps计算.^([13](#Fn13))
    在这样先进的硬件支持下，软件实现高并发只需要简单地利用现有能力。
- en: CPU cores obviously deserve to be mentioned here as well. That’s the part of
    computer infrastructure that’s undoubtedly most commonly associated with concurrency.
    Buying a 64-core consumer-grade processor is just a matter of going to the hardware
    store next door, and the assortment of professional servers is even more plentiful.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，CPU核心也值得在这里提及。这是与并发最常相关的一部分计算机基础设施。购买64核心的消费级处理器只需去隔壁的硬件店，而专业服务器的种类则更加丰富。
- en: Operating systems focus on facilitating highly concurrent programs too. io_uring^([14](#Fn14))
    by Jens Axboe is a novel addition to the Linux kernel. As noted in Chapter [3](541783_1_En_3_Chapter.xhtml),
    it was developed for asynchronous I/O, which in turn plays a major part in allowing
    high concurrency in software to become the new standard. Some database drivers
    already utilize io_uring underneath, and many more put the integration very high
    in the list of priorities.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 操作系统也专注于促进高度并发的程序。Jens Axboe的io_uring^([14](#Fn14))是Linux内核的一个新功能。如第[3](541783_1_En_3_Chapter.xhtml)章所述，它是为异步I/O开发的，而异步I/O又对软件实现高并发成为新标准起到了重要作用。一些数据库驱动程序已经在底层使用io_uring，而更多的则将集成放在优先级列表中的很高位置。
- en: Modern Software
  id: totrans-226
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 现代软件
- en: How could modern software adapt to the new, highly concurrent era? Historically,
    a popular model of ensuring that multiple operations can be performed at the same
    time was to keep a pool of operating system threads, with each thread having its
    own queue of tasks. That only scales in a limited way though, so now the industry
    leans toward so-called “green threads,” which are conceptually similar to their
    operating system namesakes, but are instead implemented in userspace, in a much
    more lightweight manner.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 现代软件如何适应这个高度并发的时代呢？从历史上看，确保多个操作可以同时执行的一个流行模型是保持一个操作系统的线程池，每个线程都有自己的任务队列。但这只能以有限的方式扩展，因此现在业界倾向于所谓的“绿色线程”，它们在概念上与操作系统的同名线程相似，但它们是在用户空间中以更轻量级的方式实现的。
- en: For example, in Seastar (a high-performance asynchronous framework implemented
    in C++ and based on a future-promise model^([15](#Fn15))^), there are quite a
    few ways of expressing a single flow of execution, which could be called a green
    thread. A fiber of execution can be created by chaining futures, and you can also
    use the C++ coroutines mechanism to build asynchronous programs in a clean way,
    with the compiler assisting in making the code async-friendly.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在 Seastar（一个基于未来-承诺模型并在 C++ 中实现的高性能异步框架^([15](#Fn15))^）中，有相当多的方式来表达单个执行流程，这可以称为绿色线程。可以通过链式连接未来（futures）来创建执行纤维，您还可以使用
    C++ 协程机制以干净的方式构建异步程序，编译器将协助使代码更易于异步化。
- en: In the Rust language, the asynchronous model is quite unique. There, a future
    represents the computation, and it’s the programmer’s responsibility to advance
    the state of this asynchronous state machine. Other languages, like JavaScript,
    Go, and Java, also come with well-defined and standardized support for asynchronous
    programming.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Rust 语言中，异步模型非常独特。在那里，一个未来（future）代表计算过程，而推进这个异步状态机的状态则是程序员的职责。其他语言，如 JavaScript、Go
    和 Java，也提供了对异步编程的明确和标准化的支持。
- en: This async programming support is good, because database drivers are prime examples
    of software that should support asynchronous operations from day one. Drivers
    are generally responsible for communicating over the network with highly specialized
    database clusters, capable of performing lots of I/O operations at the same time.
    We can’t emphasize enough that high concurrency is the only way to utilize the
    database to the fullest. Asynchronous code makes that substantially easier because
    it allows high levels of concurrency to be achieved without straining the local
    resources. Green threads are lightweight and there can be thousands of them even
    on a consumer-grade laptop. Asynchronous I/O is a perfect fit for this use case
    as well because it allows efficiently sending thousands of requests over the network
    in parallel, without blocking the CPU and forcing it to wait for any of the operations
    to complete, which was a known bottleneck in the legacy threadpool model.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 这种异步编程支持是好的，因为数据库驱动器是应该从第一天起就支持异步操作的软件的典型例子。驱动器通常负责与高度专业化的数据库集群进行网络通信，这些集群能够同时执行大量的
    I/O 操作。我们无法强调得更多，高并发是充分利用数据库的唯一途径。异步代码使这一点变得容易得多，因为它允许在不耗尽本地资源的情况下实现高并发级别。绿色线程轻量级，即使在消费级笔记本电脑上也可以有成千上万个。异步
    I/O 也非常适合这种用例，因为它允许在并行发送数千个请求到网络的同时，不阻塞 CPU 并迫使它等待任何操作完成，这在传统的线程池模型中是一个已知的瓶颈。
- en: Note
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The future-promise model and asynchronous I/O are introduced in Chapter [3](541783_1_En_3_Chapter.xhtml).
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 未来-承诺模型和异步 I/O 在第 [3](541783_1_En_3_Chapter.xhtml) 章中介绍。
- en: What to Look for When Selecting a Driver
  id: totrans-233
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 选择驱动器时需要注意的事项
- en: 'Database drivers are commonly available as open-source software. It’s a great
    model that allows people to contribute and also makes the software easily accessible,
    ergo popular (precisely what database vendors want). Drivers can be developed
    either by the vendor, or another company, or simply your next door open-source
    contributor. This kind of competition is very healthy for the entire system, but
    it also forces the users to make a choice: which driver to use? For instance,
    at the time of this writing, the official PostgreSQL documentation lists six drivers
    for C/C++ alone, with the complete list being much longer.^([16](#Fn16))'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 数据库驱动器通常作为开源软件提供。这是一个很好的模式，它允许人们做出贡献，同时也使得软件易于访问，因此受到欢迎（这正是数据库供应商所希望的）。驱动器可以由供应商、另一家公司或简单地由您隔壁的开源贡献者开发。这种竞争对整个系统非常有益，但也迫使用户做出选择：使用哪个驱动器？例如，在撰写本文时，官方
    PostgreSQL 文档仅列出六个 C/C++ 驱动器，完整的列表要长得多.^([16](#Fn16))
- en: 'Choosing a driver should be a very deliberate decision, tailored to your unique
    situation and preceded by tests, benchmarks, and evaluations. Nevertheless, there
    are some general rules of thumb that can help guide you:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 选择驱动器应该是一个非常谨慎的决定，需要根据您独特的状况进行定制，并在测试、基准测试和评估之后进行。尽管如此，还有一些一般性的经验法则可以帮助您进行指导：
- en: '**Clear documentation**'
  id: totrans-236
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**清晰的文档**'
- en: Clear documentation is often initially underestimated by database drivers’ users
    and developers alike. However, in the long term, it’s the most important repository
    of knowledge for everyone, where implementation details, good practices, and hidden
    assumptions can be thoroughly explained. Choosing an undocumented driver is a
    lottery—buying a pig in a poke. Don’t get distracted by shiny benchmarks on the
    front page; the really valuable part is thorough documentation. Note that it does
    not have to be a voluminous book. On the contrary—concise, straight-to-the-point
    docs with clear, working examples are even better.
  id: totrans-237
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 清晰的文档通常最初被数据库驱动程序的用户和开发者低估。然而，从长远来看，它是每个人最重要的知识库，其中可以详细解释实现细节、最佳实践和隐藏的假设。选择一个未记录的驱动程序就像买了一只猪在袋子里一样。不要被首页上闪亮的基准测试所分散注意力；真正有价值的是详尽的文档。请注意，它不必是一本厚重的书。相反——简洁、直截了当的文档，以及清晰、可工作的示例甚至更好。
- en: '**Long-term support and active maintainership**'
  id: totrans-238
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**长期支持和活跃维护**'
- en: 'Officially supported drivers are often maintained by their vendors, get released
    regularly, and have their security vulnerabilities fixed faster. External open-source
    drivers might look appealing at first, easily winning in their self-presented
    benchmarks, but it’s important to research how often they get released, how often
    bugs are fixed, and how likely they are to be maintained in the foreseeable future.
    On the other hand, sometimes the situation is reversed: The most modern, efficient
    code can be found in an open-source driver, while the official one is hardly maintained
    at all!'
  id: totrans-239
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 官方支持的驱动程序通常由其供应商维护，定期发布，并且其安全漏洞得到更快的修复。外部开源驱动程序可能一开始看起来很有吸引力，在它们自己展示的基准测试中轻易获胜，但重要的是要研究它们发布的频率、修复错误的频率以及它们在未来可预见的时期内被维护的可能性。另一方面，有时情况相反：最现代、最有效的代码可以在开源驱动程序中找到，而官方的一个几乎没有得到维护！
- en: '**Asynchronous API**'
  id: totrans-240
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**异步API**'
- en: Your code is eventually going to need high concurrency, so it’s better to bet
    on an async-friendly driver, even if you’re not ready to take advantage of that
    quite yet. The decision will likely pay off later. While it’s easy to use an asynchronous
    driver in a synchronous manner, the opposite is not true.
  id: totrans-241
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你的代码最终将需要高并发性，因此最好选择一个异步友好的驱动程序，即使你现在还没有准备好充分利用这一点。这个决定很可能会在以后得到回报。虽然使用异步驱动程序以同步方式操作很容易，但反过来则不然。
- en: '**Decent test coverage**'
  id: totrans-242
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**合理的测试覆盖率**'
- en: Testing is extremely important not only for the database nodes, but also for
    the drivers. They are the first proxy between the users and the database cluster,
    and any error in the driver can quickly propagate to the whole system. If the
    driver corrupts outgoing data, it may get persisted on the database, eventually
    making the whole cluster unusable. If the driver incorrectly interprets incoming
    data, its users will have a false picture of the database state. And if it produces
    data based on this false picture, it can just as well corrupt the entire database
    cluster. A driver that cannot properly handle its load balancing and retry policy
    can inadvertently overload a database node with excess requests, which is detrimental
    to the whole system. If the driver is at least properly tested, users can assume
    a higher level of trust in it.
  id: totrans-243
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 测试对于数据库节点和驱动程序都极其重要。它们是用户和数据库集群之间的第一个代理，任何驱动程序中的错误都可能迅速传播到整个系统。如果驱动程序破坏了输出的数据，它可能会在数据库中持久化，最终使整个集群无法使用。如果驱动程序错误地解释了输入的数据，它的用户将有一个错误的数据库状态图景。如果它基于这个错误的图景产生数据，它同样可能破坏整个数据库集群。一个无法正确处理其负载均衡和重试策略的驱动程序可能会无意中用过多的请求超载数据库节点，这对整个系统是有害的。如果驱动程序至少得到了适当的测试，用户可以对其有更高的信任度。
- en: '**Database-specific optimizations**'
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**数据库特定优化**'
- en: A good driver should cooperate with its database. The more context it gathers
    from the cluster, the more educated decisions it can make. Remember that clients,
    and therefore drivers, are often the most ubiquitous group of agents in distributed
    systems, directly contributing to the cluster-wide concurrency. That makes it
    especially important for them to be cooperative.
  id: totrans-245
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一个好的驱动程序应该与它的数据库协作。它从集群中收集的上下文越多，它就能做出越明智的决定。记住，客户端，以及因此驱动程序，通常是分布式系统中最普遍的代理组，直接贡献于集群范围内的并发性。这使得它们特别重要，需要它们具有协作性。
- en: Summary
  id: totrans-246
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: 'This chapter provided insights into how the choice of a database driver impacts
    performance and highlighted considerations to keep in mind when selecting a driver.
    Drivers are often an overlooked part of a distributed system. That’s a shame because
    drivers are so close to database users, both physically and figuratively! Proximity
    is an extremely important factor in all networked systems because it directly
    translates to latency. The next chapter ponders proximity from a subtly different
    point of view: How to get the data itself closer to the application users.'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 本章节探讨了数据库驱动程序选择对性能的影响，并强调了在选择驱动程序时需要考虑的因素。驱动程序通常是分布式系统中被忽视的部分。这很遗憾，因为驱动程序与数据库用户在物理上和比喻上都非常接近！在所有网络化系统中，邻近性是一个极其重要的因素，因为它直接转化为延迟。下一章将从略微不同的角度探讨邻近性：如何将数据本身更靠近应用程序用户。
- en: '[![Creative Commons](../css/cc-by.png)](https://creativecommons.org/licenses/by/4.0)'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: '[![Creative Commons](../css/cc-by.png)](https://creativecommons.org/licenses/by/4.0)'
- en: '**Open Access** This chapter is licensed under the terms of the Creative Commons
    Attribution 4.0 International License ([http://​creativecommons.​org/​licenses/​by/​4.​0/​](http://creativecommons.org/licenses/by/4.0/)),
    which permits use, sharing, adaptation, distribution and reproduction in any medium
    or format, as long as you give appropriate credit to the original author(s) and
    the source, provide a link to the Creative Commons license and indicate if changes
    were made.'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: '**开放获取** 本章节根据Creative Commons Attribution 4.0 International License（[http://creativecommons.org/licenses/by/4.0/](http://creativecommons.org/licenses/by/4.0/)）的条款进行许可，允许在任何媒介或格式中使用、分享、改编、分发和复制，只要您适当引用原始作者和来源，提供Creative
    Commons许可的链接，并指出是否进行了修改。'
- en: The images or other third party material in this chapter are included in the
    chapter's Creative Commons license, unless indicated otherwise in a credit line
    to the material. If material is not included in the chapter's Creative Commons
    license and your intended use is not permitted by statutory regulation or exceeds
    the permitted use, you will need to obtain permission directly from the copyright
    holder.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 本章节中的图像或其他第三方材料包含在本章节的Creative Commons许可中，除非在材料引用行中另有说明。如果材料未包含在本章节的Creative
    Commons许可中，且您的使用未得到法定规定的许可或超出了许可的使用范围，您将需要直接从版权持有人处获得许可。
